start	end	text
0	10480	Hello and welcome to In Control, the first podcast on control theory.
10480	21240	Here we discuss the science of feedback, decision making, artificial intelligence and much more.
21240	25040	I'm your host Alberto Padoan, live from our recording studio in Lausanne.
25040	29540	Again we're here in the beautiful French speaking side of Switzerland for a nice event which
29540	33980	brought together some of the most brilliant minds out there in control and machine learning.
33980	39900	Today our guest is Anu Anaswamy, Director of the Active and Adaptive Control Laboratory
39900	44340	and Senior Scientist at the Massachusetts Institute of Technology in the Department
44340	46180	of Mechanical Engineering.
46180	47340	Welcome to the show Anu.
47340	48340	It's my pleasure.
48340	49620	Thanks for having me.
49620	53360	Just before I forget, quick thanks to our sponsors as well to the National Center of
53360	58480	Competence in Research on Dependable Ubiquitous Automation as well as the International Federation
58480	60060	of Automatic Control.
60060	68340	Anu, just to break the ice, what do the first 60 minutes of your day look like?
68340	74340	Ah, well, emails I think.
74340	81260	There's always something very interesting and informative and surprises that sort of
81260	82860	set the day.
82860	89040	And you know, with everybody working around the clock on controls research, colleagues
89040	95280	in Europe have been up for, say for instance, six hours before me and they tell me what's
95280	100120	been going on and that sets the day and, you know, there are then discussions and meetings
100120	101120	and all that.
101120	105680	And so that's basically every 60 minutes of my day start with.
105680	110120	Are you the kind of person that likes, say, to do, I don't know, physical exercise or
110300	112820	meditation or anything like that?
112820	115980	Yeah, I do do them, but later in the day.
115980	121580	But I'd like to start, you know, have my cup of coffee and just jump into work.
121580	125940	And of course, these days, there's always Wordle that starts the day.
125940	126940	Who isn't doing that?
126940	127940	Right.
127940	129180	And then, of course, email.
129180	131220	And that's how my day begins.
131220	132220	Yes.
132220	133220	Yeah.
133220	138340	So maybe, you know, shifting towards the topic of today, which hopefully will be adaptive
138360	145240	control, which is an area of expertise of yours and also its history, I would like to
145240	149360	maybe ask you what has drawn you to control in the first place?
149360	155240	So I know that reading your biography, I saw that you have not just one, but two undergraduate
155240	156240	degrees.
156240	157240	Is that right?
157240	158240	That is correct.
158240	159240	Okay.
159240	164520	And so, yeah, I was curious, given that you have this broad span, what has drawn you to
164520	165520	control?
165520	166520	Okay.
166520	167520	Yeah, no, I'd be very happy to answer that.
167700	173060	So, as you mentioned, I have two undergraduate degrees, and the first one was in math.
173060	180580	And what I found towards the end of that education is that I wanted to really move towards a
180580	182700	more applied aspect of math.
182700	187260	So this was all fine, and I loved doing what I was doing there, but I wanted to know what
187260	188520	it was all for.
188520	191980	So that drew me to my second degree, which was in engineering.
191980	195340	And there was a very specific program where only graduates were admitted.
195360	200360	So it was sort of like a graduate program almost, except that it was more abridged than
200360	207160	the usual undergraduate degree in engineering in India, which is where I come from.
207160	209080	Was five years at that time.
209080	212800	And so this one was more abbreviated in three years, because you've taken all of your courses
212800	215280	already, and that was in electrical engineering.
215280	221400	And so, but even there, what I found was here were all these different courses that mentioned
221400	224320	as to how the universe worked, which was great.
224340	228780	And then was this controls course, which said, no, no, this is basically how you can modify
228780	229780	the universe.
229780	232700	And I thought, wow, that's really cool.
232700	236740	And I got into that more, and the rest is history, I guess.
236740	241900	So I've been working in that same area, I've never left school.
241900	246100	And I still feel that every day I have something to learn.
246100	250660	And then, you know, like I said earlier, what happens in the first 60 minutes, I can't wait
250680	256560	to see what the day brings in terms of new opportunities, new challenges and controls,
256560	259760	research and new solutions.
259760	261160	And yeah.
261160	267440	And but from India, and then you moved to the US to Boston.
267440	270680	So what has brought you on the other side, I would say?
270680	274280	So I applied to graduate school.
274280	279460	And so there were obviously lots of opportunities in the United States.
279460	285340	And it so happened that I met who would become my future advisor, Professor Narendra, who's
285340	287100	also originally from India.
287100	291820	And it so happened, serendipitously, that he was visiting his parents, who happened
291820	294940	to be in the same city that I was from.
294940	296820	And so, you know, I talked to him.
296820	300980	And again, I found even during the, what, 30 minutes of conversation that we might had
300980	303020	that I was learning so much.
303020	305920	And so it was very clear to me that that's where I'd like to go.
305920	310240	And so when Yale University offered me admission, I just took that.
310240	314260	And so, so before Boston, that's New Haven, Connecticut.
314260	318480	And that's where I did my PhD in adaptive control.
318480	319480	Okay.
319480	320480	Yeah.
320480	326720	So this is actually a good assist for me to ask you, what is adaptive control or even
326720	327800	what is adaptation?
327800	333180	So before we delve into this topic, I think I should mention that, well, you wrote one
333180	335940	of the Bibles of adaptive control.
335940	341300	And I do suggest to everyone in the audience to check out the first chapter of the book
341300	347380	Stable Adaptive Systems by Anu and Professor Narendra, because there is a really fantastic
347380	351220	section about how to even define adaptation.
351220	354500	And it seemed absolutely non-obvious when the whole field started.
354500	357300	So maybe you can tell us a bit more about that.
357300	358300	Absolutely.
358420	364420	So adaptation is exactly what the English word means, it's, you know, as it is defined
364420	371100	in biology, advantageous confirmation of an organism to changes in its environment.
371100	375380	So interestingly enough, and I don't know if this was quite your question, but let me
375380	378860	answer if it's a different question, then apologies.
378860	386100	So in adaptation, that concept is the one that caught the imagination of a lot of flight
386100	388820	control engineers and admirals.
388820	396060	And so what they really wanted to do was to design systems, design controllers that figured
396060	397420	on the fly.
397420	403020	And again, the emphasis is on the fly, meaning in real time, as to how to adjust its structure
403020	408340	so that it adapted to changes in the environment and corrected itself and behaved.
408340	415900	So even before theory, adaptive control theory came into being, adaptive control practice
415900	417940	was already there.
417940	422580	So it's one of those interesting cases where practice was ahead of theory.
422580	430500	And so there was this one specific hypersonics program called X-15, where the different control
430500	436100	loops that they had, they chose to make one of them adaptive.
436100	442140	And they actually had several successful flights where the notion of adaptation was basically
442220	449020	in the form of control gains in the feedback loop that basically toggled between two different
449020	450300	values.
450300	452980	And they did that on the basis of what they were measuring.
452980	459620	So in some sense, an exact manifestation of advantageous changes in the organism in response
459620	461580	to changes in the environment.
461580	465860	And they had several successful flights that basically did that.
465860	469220	But then I'm sure we will get more into what happened next.
469380	470100	Absolutely.
470100	476220	That was really the idea behind adaptive control.
476220	484500	And the symposia that were held on adaptive systems at that time tried to capture that
484500	487060	essence in the definition of an adaptive system.
487060	493340	So and then came lots of different efforts in trying to come to a very crisp and useful
493340	496820	definition of adaptation and adaptive control.
496820	500700	And that's what we tried to capture in that introduction.
500700	502500	And one thing left to another.
502500	506020	And then it sort of came to what we know as adaptive control now.
506020	507500	But we can get into that later.
507500	508140	Absolutely.
508140	509820	So I'm glad you mentioned that.
509820	514220	I mean, I guess the main motivation for the development of adaptive control and now we're
514220	519420	talking about pretty much the 60s, I would say, or even before that, of course, we can
519420	524180	trace it back to Norbert Wiener and we can even go probably even backwards.
524220	531540	But I guess the 60s, between the 60s and the 65, is what is called the brave era of adaptive
531540	537540	control. And really, it's fascinating to see how many concepts have been developed just
537540	540020	in that five years span.
540020	541500	So I don't know.
541500	545660	Do you have any thoughts about the developments specifically in that time range?
547540	548700	So, yes.
548700	555220	So I mentioned the symposium, and that was a time when people were talking about and
555220	558940	even implementing adaptive control in flight control.
558940	563980	And around the same time is when the concept of state was being defined.
563980	569060	And, you know, the seminal papers by Kallman, Miranda and Ho came at that time.
569060	574020	And dynamic systems and control systems started to get codified around that around that
574020	574980	time as well.
575140	581660	And so people were beginning to understand how to implement the notions of feedback
581660	586620	control and the methods by Black and Bode and Nyquist and understanding closed loop
586620	591540	control system design using by analyzing forward loop and so on.
591540	597420	So it's interesting to see, you know, that the history of feedback control is almost or
597420	602660	rather the history of adaptive control systems has been as long as at least as long as
602660	609300	the history of control systems, because it's very easy, just like feedback is such a
609300	616620	fundamental and conceptually simple idea to understand and to get motivated by.
616620	618100	So is adaptation.
618100	622860	And so, in fact, you could argue that, you know, as you think about it at a very
622860	629380	philosophical level, the idea of a feedback control system is not that far from the idea
629380	630700	of an adaptive control system.
630700	638140	So I would say those many of those fundamentals started to get defined around that time.
638140	641620	But then I think we probably go towards the early 70s.
641620	644460	If you want, I can get into into that.
644460	649820	Yeah. So I would like to maybe add a few things about this brave era and then we can
649820	652340	definitely move on to the 70s.
652340	657700	So what I personally found fascinating was that there were incredibly influential people
657700	659860	working in this specific time range.
659860	667060	So between the let's say until the 1965, that we're focusing on adaptive systems.
667060	672620	So we're talking about people of the caliber of not only Kalman and Bellman, but also
672620	678820	Simon, who got a Nobel Memorial Prize in economic sciences in 78 for works on dynamic
678820	681300	programming under uncertainty.
681300	687020	And it is around this time that also the concept of dual control theory is being
687020	690140	developed by Feldbaum in Soviet Union.
690140	696860	And also Whittaker, I guess, is around this time that the famous MIT rule is developed.
696860	702820	Maybe you can tell us something about that rule and also what led to, I don't know,
702820	705180	the future developments in the 70s.
705180	710940	Sure, sure. So let's go back to what we talked about as the concept of adaptation,
710940	715140	right? Advantageous confirmation of an organism.
715140	719700	So bring it to the context of a dynamic system.
719700	725100	So here you have a dynamic system, which is the actual, say, aircraft or robot or process
725100	726700	controller or what have you.
726700	730740	And you are monitoring how it's performing.
730740	735340	And then a controller is set in and set in place in closed loop.
735340	736660	And then you design the controller.
736660	739340	So that's what every feedback control system does.
739380	745340	So now the advantageous confirmation here in the context of an adaptive control system
745340	754420	is basically one where you are advantageously adjusting the control parameters in that
754420	759020	control system. So imagine if you had a PID controller, then you're adjusting the PID
759020	764940	gains because what you did at 10,000 feet might be very different from what happens at
764940	767020	30,000 feet and so on.
767020	771660	And so something like a hypersonics flight, which basically covers a large flight
771660	776100	envelope, you do need to have that flexibility in adjusting yourself.
776100	777700	So what do you do then?
777700	782020	What is the response from the environment that you observe?
782020	785300	Then you look at some sort of a performance quantity.
785300	789500	So what we call these days as loss function.
789500	794380	And so you then try to adjust your gains in a way so that you minimize that loss
794380	795380	function.
795380	797300	And so what do you do in order to do that?
797300	799340	You look at something called the gradient.
799340	804260	OK, all right, let's adjust the gains so that when I look at the gradient of this loss
804260	809100	function, then that gives me the indication as to what direction should I adjust.
809100	810700	Is it down or is it up?
810700	811780	And by how much?
811780	813980	And I designed it step size and so on.
813980	818420	So all of those things were basically captured in the MIT rule.
818460	825500	And so who, I mean, yeah, so who basically proposed that particular concept.
825500	830740	So now in parallel, people were trying, beginning to understand about stability
830740	836940	theory, about how to design control systems for systems with nonlinear dynamics.
836940	839780	And so the whole notion of Lyapunov's direct method.
839780	844660	And again, Kalman wrote the seminal paper of how to use that in the design of
844660	845820	nonlinear control systems.
845820	852740	So what people found out soon in the 70s was that this MIT rule, while it's great in
852740	856260	many cases, it sometimes big falls short.
856260	861580	And that is captured by basically tools from stability theory, which says that these
861580	866580	gradient rules are things that do not actually not only not help you, but sometimes
866580	870940	really hurt you because it can actually produce some instabilities if there is a
870940	876180	latency between those performance functions you're measuring and the parameters.
876180	879300	And some of those counter examples basically were brought in.
879300	886340	And so that basically led to adaptive control theory, where you really need to look at
886340	891100	two different kinds of measures and errors in the system.
891100	895140	One is this loss function that you can actually measure, but the other is the
895140	898180	parameters that you're trying to learn and adjust.
898180	904140	And you need to worry about what kind of latencies basically are present between the
904140	906460	time you measure and the time you adjust.
906460	911700	And not all problems can be tackled by just using the gradient alone.
911700	917500	So that basically was sort of the foundation of adaptive control theory.
917500	919940	That's a fantastic way also.
919940	926580	I mean, we talk about a fantastic way to move towards a transition between this brave
926620	931740	era and the era of the 70s, where you mentioned that there is a prominent role of
931740	934980	Lyapunov stability in adaptive control.
934980	939660	We also talked about the fact that most of the research in the brave era was motivated
939660	941900	by supersonic flights.
941900	947900	And it is in this time that there are many successful flights, actually, that produce
947900	950820	incredible results, I would say, in avionics.
950820	954780	Maybe we can hear an excerpt of a video that is taken from those years.
954820	955820	Of course.
955820	956820	Yeah.
984820	988820	The crew cameraman in one of the chase planes gets difficult and dramatic coverage of the
988820	990820	smoothly executed landing.
997820	1003820	Crossfield is uninjured, but the X-15, one of three in the X-15 research program, sustains
1003820	1006820	minor repairable damage.
1006820	1011140	Crossfield checks his bird, which prior to this incident had made several successful
1011140	1014180	glide and powered flights.
1014580	1018780	Soon the X-15 will be released from contractor demonstrations, and research flights will
1018780	1024180	begin by the National Aeronautics and Space Administration and the United States Air Force.
1028180	1034300	So this excerpt testifies the success of adaptive control, I would say, in practice in the field
1034300	1036020	of avionics.
1036020	1043020	The problem is that in 1967, unfortunately, things didn't unfold so well in the test of
1043020	1047100	a flight that Michael Adams was conducting for NASA, I believe.
1047100	1048100	That's correct.
1048100	1053140	He was testing the X-15-3 airplane.
1053140	1057020	And yeah, unfortunately, things didn't go so well in that scenario.
1057020	1063500	Michael Adams is known as the first American space mission fatality by the American convention.
1063500	1069060	He was also the first qualified astronaut because he flew above 50 miles for some period
1069100	1074100	of time before, unfortunately, his aircraft broke apart.
1074100	1075500	And maybe we can dig into that.
1075500	1080580	There is a delightful paper on the Control Systems magazine that you wrote about this
1080580	1081580	accident.
1081580	1082620	And I don't know.
1082620	1089260	So what happened and what were the problems from the point of view of adaptive control?
1089260	1095500	So I would certainly defer the details of what happened to the paper.
1095500	1098700	So we do get into that in detail.
1098780	1105340	But in a sense, what really happened was that there was a one of the there were several
1105340	1111020	control loops that they had, one of which was had this adaptive capability where there
1111020	1119260	was a control gain that toggled between two different values based on the content of the
1119260	1123940	frequency content of a performance measure that they were looking at.
1123940	1128780	And if depending upon the frequency content, it was either a smaller value or a larger
1128780	1130460	value, I forget which.
1130460	1132540	And that was the algorithm.
1132540	1135300	So you see, in a sense, it's a very simple concept.
1135300	1138060	I mean, the concept of adaptation is very simple.
1138060	1141860	You want something and based on what you what you want, you adjust something.
1141860	1147820	Now, you don't really if you if you're not aware of the complexity of what that means
1147820	1149940	to the system, then you can get into trouble.
1149940	1153460	And that's exactly what happened, because you see what you're doing is you're measuring
1153500	1156060	something and then you're adjusting the parameter.
1156460	1162020	Now, interestingly enough, I think this I should direct the discussion to Feldbaum's
1162020	1167860	dual control. Now, what should that parameter be for a given environmental situation?
1167860	1172740	So in order to really understand that and learn the parameters, you need to go into
1172740	1175460	estimation. And now that takes infinite time.
1175740	1181220	Now, in order to really make sure that your performance converges to the right value,
1181220	1182420	that takes infinite time.
1182420	1187820	That's control. Now, if you're trying to do both simultaneously, then you can get into
1187820	1193100	trouble because you're trying to adjust the gains and based on the error and the error
1193100	1194580	will depend upon the gains.
1194900	1197740	And so there is a loop circularity here.
1197740	1203580	And that's exactly what happened, because it turns out that what the situation was, was
1203580	1209420	not something that really fell neatly into either use this value A1 or A2, but something
1209460	1214780	else. And that's something that was whatever that new value was, was not learned by the
1214780	1220300	controller. And because it didn't really learn that value properly, it led into basically
1220460	1223820	instability because what you have now is a nonlinear control system.
1224260	1231780	And that had a behavior which led to the closed loop system having unbounded solutions.
1232540	1238660	So again, here was one where the control practice was way ahead of control theory.
1238860	1243980	And the awareness that what you really have is a nonlinear control system and it has to
1243980	1247060	be designed carefully was not there then.
1247140	1249780	And that's basically what we dug into in the paper.
1249820	1254780	We said, OK, let's now look at adaptive control because, you know, fast forward to what,
1254780	1257340	2010 from 1967.
1257660	1262980	Now we have this understanding of how you should define, design adaptive control
1262980	1268980	systems, how you can deal with this concept of dual control, where you have this
1269260	1273540	conflict between infinite time for estimation and infinite time for control.
1273940	1280020	And you basically break that by introducing appropriate control structures that can make
1280020	1285020	sure that your performance is well behaved and you have that under control before
1285100	1287340	learning, before learning.
1287700	1293340	So you do control first and then with hindsight, you learn the parameters.
1293620	1297420	That basically is, in a sense, the foundation of adaptive control theory.
1297740	1304700	It determines a solution to a dynamic system which has uncertainties in real time
1305020	1309220	without having fully learned what the nonlinear system is.
1309580	1315540	But what it does is it basically, even with imperfect learning, figures out what the
1315540	1320180	control system ought to do and so that you can then have the performance in check.
1320740	1326420	And so what we did in that paper is to basically lay that out and have a correct,
1326940	1328980	provably correct adaptive controller.
1329300	1333820	And then we compared it with what was actually implemented in the MH96, which is a
1333820	1336540	Minneapolis Honeywell 96 controller.
1336660	1340620	That was the name of that adaptive controller that they had in that fatal flight.
1341260	1345100	And then we said, OK, let's start to try and compare apples with apples.
1345140	1351540	And so we started to have a configuration where they looked identical except for, say,
1351740	1354380	the change in the way in which the parameters were adapted.
1354820	1359460	And so what we showed was that it was basically the way in which the parameters
1359460	1361580	were adjusted was incorrect.
1361580	1365980	And had they really, the awareness of what the overall control system is, had they
1365980	1371500	done this adjustment according to this rule, then that flight would not have crashed.
1371740	1376700	So it was a very satisfying experience because it was one of those things where we said,
1376700	1378820	OK, this is basically what must have happened.
1378820	1380420	And we were able to replicate that.
1380660	1384420	And also we could play a what if scenario.
1384420	1389180	If they had the awareness, this is basically what what they should have done, then
1389180	1390460	Michael Adams would be here.
1391300	1394420	I mean, you touched on so many interesting points.
1395020	1399620	First of all, I want to make sure that the audience knows that there will be links in
1399620	1402780	the description of this episode to all of the papers that we mentioned.
1403580	1409940	We're also basing also our story today on a beautiful article written by Anu and
1409940	1412580	Professor Fratkov on the history of adaptive control.
1412580	1415020	There will be a link to that paper as well.
1415060	1420180	There is also an upcoming paper, if I understand correctly, on the interplay between
1420180	1422180	adaptive control and reinforcement learning.
1422940	1429100	Yes, it'll appear in the annual reviews in Control Robotics and Automation Systems.
1429100	1432740	And yeah, the title is exactly that adaptive control and intersections with
1432740	1433580	reinforcement learning.
1433580	1435660	There will be a link also to this paper as well.
1435660	1441780	Of course, in discussing before we touched on, I would say, some very important
1441780	1446980	points. So the first one that you were mentioning was dual control and essentially
1446980	1452660	this tension between learning and controlling, which today is what we call the
1452660	1456660	tradeoff between exploration versus exploitation.
1456980	1461860	And also, I guess another thing that we should probably mention is that as a result
1461860	1468620	of this crash, I guess funding was cut short for a short period of time for what
1468620	1470140	concerns adaptive control.
1470140	1470940	Is that correct?
1470940	1479020	Yeah, so certainly people had to regroup and in the specific area of flight control,
1479460	1484020	there was a pause and efforts to really understand what happened, efforts to
1484020	1489540	understand control theory, efforts to understand a multivariable control theory.
1489740	1492300	And so many of those things were set in motion.
1492300	1499180	And even this whole effort to connect fundamental tenets of stability theory of
1499180	1503300	nonlinear differential equations with adaptive control, because, you know, the
1503300	1508260	recognition that what you really are doing when you start to adjust parameters of a
1508260	1513580	controller in real time makes the whole problem one of a nonlinear time varying
1513580	1517660	system, a system that is intentionally nonlinear.
1517660	1520300	So then how do you design those nonlinearities?
1520300	1524860	And so that's where there was a very elegant connection between adaptive control
1524860	1531060	design and Lyapunov theory, because Lyapunov theory gives you that guideline as to
1531060	1535580	how to design the controller such that you make something which is a positive
1535580	1537820	definite function into a Lyapunov function.
1538060	1540460	So some of those foundations were in place.
1540460	1545700	The other very elegant result is it's not something that people talk about a whole
1545700	1550580	lot these days, but again, in the 70s and the 80s, people explored that quite a bit,
1550580	1555980	which is a notion of hyperstability and the notion of absolute stability, which
1555980	1561260	basically is centered on passive systems and strictly passive operators.
1561540	1566580	And so the whole idea is that if you have, even though they might be nonlinear, then
1566580	1570740	if you have something which is a strictly passive operator in forward loop, then you
1570740	1576660	can have several passive operators in feedback loop and structurally the system
1576660	1578620	will be, will continue to be stable.
1578620	1580900	So that's why it was called hyperstability.
1581540	1584660	The notions of absolute stability also are connected with that.
1584660	1590660	So people like Popov and Aizerman, many of those kinds of really very elegant
1591020	1596340	stability theories of nonlinear dynamic systems were all sort of brought together.
1596540	1602460	And this interplay again between parameter adaptation and feedback control were all in
1602460	1607620	place. And, you know, so then over those two decades, the 70s and the 80s, with these
1607620	1612980	foundations in place, and then there was another thing to saying, OK, if you really
1612980	1619020	look at parametric uncertainties, then that gives you the foundation for how to set up
1619780	1620940	adaptive control systems.
1620940	1626580	But we also need to look at robustness to nonparametric uncertainties, which might be
1626580	1629140	in the form of disturbances and model dynamics.
1629420	1635420	And so I would say in the 90s, the foundations of robust adaptive control were in
1635420	1640460	place. So this led to introducing terms, which we didn't call it as regularization
1640460	1645300	then, but it's really ways of regularizing the underlying function, which is convex.
1645300	1647620	And you really need to make it strongly convex.
1647780	1649860	And that gives you the robustness.
1650100	1655020	And that led to a whole bunch of methods based on dead zone, based on what is known as
1655020	1659060	sigma modification, e-modification, parameter projection.
1659060	1664020	And all those basically led to this is how you would design a robust adaptive control
1664020	1669220	system. And so with that now, I say, you know, we should come full circle.
1669420	1675860	And now coming into the 21st century, there's been actually several successful
1675860	1684100	demonstrations of advanced flight vehicles with adaptive control, which are actually
1684100	1687260	in production. And many of these things have been designed by Boeing.
1689020	1690380	This is something that I didn't know.
1690780	1693860	I mean, you touched again on so many interesting aspects.
1693860	1697740	I would like to dissect them a little bit more, all of them, just because it's such a
1697740	1703460	fascinating story. So again, maybe like moving on from this accident in the 70s, you
1703460	1706660	mentioned that Lyapunov stability took over somehow.
1706660	1712540	This is also the time just after 1967 is really the time of also the developments that
1712540	1714820	led to going on to the moon, essentially.
1715260	1721500	And so in between, let's say, the 70s and the 80s, stability really played a role.
1721500	1724780	Lyapunov stability really played a role in adaptive control.
1724780	1730860	And as you were mentioning, in moving forward towards the 80s, once you have a Lyapunov,
1731100	1736740	let's say, set up, then it is immediate to ask also the question of robustness of these
1736740	1742460	methods. Something else that I should mention also before, you know, essentially digging
1742460	1748740	into this 70s and 80s period is that hyperstability and all of these concepts of
1748740	1751820	absolute stability as well were coming from the Soviet Union.
1752660	1757980	And I guess this was also the result of the competition between the US and the Soviets.
1757980	1759220	I'm not sure about that.
1759780	1760900	Yeah, you know, yeah.
1761180	1765940	In fact, when we were writing this paper, Sasha Freitkopf and I were talking about
1765940	1773100	exactly that, that there's been just so many rich developments, both in the Soviet
1773100	1775660	Union and the and I guess the Western world.
1775980	1780340	And many of those things actually happened independently and in parallel.
1780340	1782260	And in some cases there was a confluence.
1782540	1787340	So the other interesting place where a fundamental tool that was developed that's
1787340	1792940	again used very much in adaptive control is what we call as the Kalman-Yakubovich
1792940	1797020	lemma. And so right there in the name, you can see this sort of parallel development
1797020	1802340	because separately Kalman and Yakubovich independently came up with this, which is, I
1802340	1809020	think, one of the really beautiful results because it connects what happens in
1809620	1814500	analysis in time domain with what happens in frequency domain.
1814780	1819980	And there are not that many results that basically provide this connection between
1819980	1824060	these two very different representations of dynamic systems.
1824500	1829940	And so what they showed basically, and it's one of the central pillars of adaptive
1829940	1837020	control, because it talks about what kind of performance functions can you use and
1837020	1842620	adjust the parameters so that even when you don't have access to all of the states in
1842620	1847060	the dynamic systems, even when the system is partially observable, you still are
1847060	1850580	guaranteed to have the right adaptation laws.
1851380	1856820	And so it turns out that the connection between the input-output property of the
1856820	1861420	dynamic system is basically connected with the existence of a Lyapunov function.
1861420	1865260	So on the one hand, this input-output stability property is the one in frequency
1865260	1871620	domain. You can think of it as what kinds of characteristics should that obey in the
1871620	1876700	frequency domain to the kind of operator that you need to have in time domain that
1876980	1880340	allows a positive definite function to become a Lyapunov function.
1880740	1886980	And that, too, is something that happened in the 70s and 80s and was a cornerstone in
1886980	1888460	the development of adaptive control.
1889140	1895420	And I would say that the paradigms around those times were essentially two in
1895420	1900820	adaptive control, model-reference adaptive control, possibly, and self-tuning control.
1900820	1903940	Can you tell us a bit about the difference of these two paradigms?
1903940	1911100	Of course, yeah. So you can approach the whole problem by saying, OK, my focus is
1911100	1913820	really that I want to control the system.
1914460	1920300	And so at the end of the day, I really don't need to know how a system behaves.
1920380	1925620	I just need to figure out what I need to do in order to get the performance I want.
1926020	1930300	So model-reference adaptive control pursued that kind of what we would call as a
1930300	1932340	direct adaptive control strategy.
1932940	1938140	Now, on the other hand, if you say, OK, here is a dynamic system, I know how to
1938140	1942660	control it. But then for whatever reason, something changed in the environment.
1942660	1944860	And so my parameters have changed.
1945060	1946260	So now what do I do?
1947140	1952100	You can look at it completely from the point of view of estimation.
1952540	1957780	So let's first identify the parameters and then design the controller.
1958340	1964180	And so this is an explicit estimation, but you can call it as an indirect adaptive
1964180	1968900	control because first you identify the parameters, then you identify the
1968900	1975860	controllers. So if you take the notion of separation principle, which is very
1975860	1981780	elegant and it says, you know what, you don't necessarily need to have observer
1981780	1986140	design and controller design to, you know, we don't have to worry about the fact
1986140	1988940	that they are two different steps.
1989260	1992860	You can actually separate it and have both of them function in parallel and
1992860	1994220	everything would work out fine.
1994220	1999140	So the idea was then that, hey, I have this cost function and this cost function
1999140	2002700	is a regular linear quadratic, you know, it's a quadratic cost.
2003060	2005540	And so I will optimize this cost.
2005580	2009900	I will try to come up with a regulator that basically self-tunes itself and
2009980	2011300	optimizes this cost.
2011700	2016420	So and I do that by saying, OK, I can estimate the parameters and then basically
2016420	2021460	use the estimates in the cost function and have that be minimized.
2021660	2026420	So that was the philosophy taken in the self-tuning regulators.
2026780	2029420	So and those were the two parallel streams.
2029420	2034500	And it turned out that if you're going to ensure that even as you're estimating
2034580	2040340	the cost function is something that remains well behaved, you had to impose
2040340	2043060	a certain structure to the problem.
2043140	2047820	And it turned out that some of the assumptions that were made were basically
2047820	2052020	exactly the same things that you needed to do in order to have the model
2052020	2053900	reference adaptive controller at B's table.
2053900	2057540	And so there were a lot of papers written again, I think, towards the end of
2057540	2064140	the 80s that talked about a unified theory and the similarities between STR
2064140	2065620	and MRAC and so on.
2065940	2070220	But you see, it again goes back to the same thing that we talked about earlier
2070220	2073140	in our conversation, which is this dual control.
2074460	2078900	Since estimation and control are duals of each other, you really need to have
2079180	2085100	the right structures for the controller so that even without full estimation,
2085100	2086500	you can make the controller work.
2086500	2091100	And at the same time, you also allow those structures to lead to learning of
2091100	2095500	the parameters, to estimation of the parameters, so that eventually when this
2095500	2099900	all really is done, after control is completed, after regulation is completed,
2100260	2105620	you can use what is known as persistent excitation properties of excitation of
2105620	2107980	the external signals and learn the parameters.
2108180	2111260	So that was the story behind STR and MRAC.
2112580	2116420	Thanks for this super nice overview of the two approaches.
2116740	2121420	Actually, this gives me a nice access to move from the 80s towards the 90s.
2121460	2126860	This is also the time where I believe you had your PhD as well and where you landed
2126860	2132180	a super nice paper, essentially, that awarded you the George Axelby Prize, one
2132180	2134740	of the most important prizes in control theory.
2135500	2139020	The title of the paper is Robust Adaptive Control in the Presence of Bounded
2139020	2143300	Disturbances. And I just wanted to talk about this because you mentioned the notion
2143300	2144700	of persistence of excitation.
2144700	2149060	And in that paper, you actually show that that plays a fundamental role in adaptive
2149060	2149820	control, right?
2150140	2150540	Yes.
2150980	2153460	So what is the message of the paper?
2153820	2160020	Right. So we talked about what adaptation is, right?
2160180	2164420	Advantageous confirmation of an organism now in response to changes in the
2164420	2167140	environment. So that's very important.
2167340	2171420	So what is it that you say is your performance function?
2171860	2176660	So adaptation and even the manifestation of that in an adaptive control system is a
2176660	2177740	very simple thing.
2177740	2182300	It's a very â€” think of it as a very simple-minded entity, because what it's doing
2182300	2186900	is, hey, here is the performance, here's the loss function, and here is the
2186900	2190100	parameter. Adjust the parameter in the direction of the gradient.
2190140	2191780	That minimizes that loss function.
2192580	2198460	So if you use this framework, then it turns out that you can do very well in
2198460	2202860	controlling the system and ultimately even estimating the system with persistent
2202860	2210580	excitation, provided there is a certain kind of a structure in the environment.
2211140	2215740	Now, if this environment is pristine and is well-behaved and ideal and the only
2215740	2219220	uncertainty is parametric in nature, then what we are talking about would be
2219220	2224420	correct. But you are only observing a performance quantity, right?
2224460	2225380	A loss function.
2225660	2230380	What if, unbeknownst to you, there were other forces at work, other non-parametric
2230460	2234100	effects that basically was affecting the performance, and you didn't know that?
2234500	2241020	So if that happens, then essentially you are trying to adjust the parameters in a
2241020	2246500	direction that might make that performance well-behaved, but you might end up
2246900	2248340	destroying something else.
2248500	2253300	And that basically was what people were observing could happen in adaptive control
2253300	2256620	systems. You can explain that in many different ways.
2256620	2260460	I mentioned convexity and making it regularized and making it strongly convex.
2260460	2261540	That's one way of looking at it.
2261540	2264260	And the other way of looking at it is here is a convex function.
2264700	2270300	Then instead of doing regularization, because it introduces other artifacts into
2270300	2274620	the picture, what if I make it strongly convex by using the notion of persistent
2274620	2278900	excitation? So that turns out is another way of really looking at the problem.
2278980	2284020	So then it turns out that even when there are disturbances, this performance
2284020	2287980	function that you're observing, this loss function that you're observing, can be
2287980	2290500	utilized in order to keep things in check.
2291220	2296540	The paper that, if you go back and read that paper written in 86, it really doesn't
2296540	2299620	have any of the language that I'm using right now, but that's just another way of
2299620	2305820	looking at it as to how the relation between persistent excitation and robustness
2305820	2308380	manifests itself. You can think of it in another way.
2308820	2314340	Nonlinear systems or differential equations are extraordinarily rich compared to
2314340	2315620	linear differential equations.
2315820	2322020	The notions that we have of what happens for the unforced system and what happens
2322020	2326420	in the presence of external forcing inputs is very different between a linear
2326420	2327820	system and a nonlinear system.
2327820	2330540	And that basically is what is mentioned in the paper.
2330980	2336300	If you take a system that is, so there is no external input and you've got a nice
2336460	2338980	system that's uniformly asymptotically stable, right?
2338980	2342500	The origin is uniformly asymptotically stable, meaning you shake it, everything
2342500	2343620	will go back to the origin.
2344060	2347700	Now you introduce exogenous inputs into the picture.
2347900	2351540	We know from linear systems that if you have a situation like that, bounded input
2351540	2352860	will produce a bounded output.
2353580	2355340	Not so for nonlinear systems.
2355420	2361060	There is a very nice paper by Varaya, De Sovere and Varaya, I think.
2361460	2363260	Actually, I have to go back and check the authors.
2363420	2366540	Certainly it's by De Sovere, maybe the co-author is not Varaya, but someone else
2367220	2371780	who basically showed this very nice counter example where you have a uniformly
2371780	2374180	asymptotically stable system.
2374540	2378420	You put in a bounded input, not only does the output does not remain bounded, it
2378420	2379180	actually blows up.
2379660	2384980	So we were able to come up with a counter example very similar to that in the
2384980	2389340	context of an adaptive control system, which basically showed that if you just
2389340	2393300	had the simple gradient rule type of thing, and then you introduce a
2393300	2397540	disturbance, you can actually prove, you can actually come up with a positive
2397540	2401500	definite function and show that there is a bounded, there is a region, not bounded
2401500	2404380	region, where if you start there, you will stay there forever.
2404380	2405860	And it's an open invariant region.
2405860	2407940	And so the trajectory, it actually blows up.
2408340	2412940	So what it says is that things may not actually, it's not easy to show stability,
2412940	2414860	but it actually becomes unstable.
2415460	2420220	Fortunately, there was also a happy ending to that paper, which says that this
2420220	2422860	might happen if you don't have enough persistent excitation.
2423140	2427020	So not only do you need persistent excitation, but you need enough of it.
2427220	2429820	So sort of a signal to noise ratio type of condition.
2430140	2433660	And if that is satisfied, then you get bounded input, bounded output for
2433860	2438020	nonlinear systems, which is why that paper, I think, is very special.
2438860	2444220	Very quick comment about this, this fact that you mentioned on the level, if you
2444220	2448180	want, of persistence of excitation, because from my very humble perspective, it
2448180	2453180	seems that these notions are now coming back in vogue in these times, at least at
2453620	2455380	major conferences in control.
2456020	2461500	But yeah, as you mentioned, from the 80s to the 90s, we start moving our horizon, if
2461500	2466140	you want, in adaptive control towards issues of robustness and nonlinear systems,
2466580	2471980	essentially. So that's the way I read the history, at least of adaptive control.
2472540	2478260	So I would like maybe to shift towards those years and maybe even with a look
2478260	2480300	towards our current times.
2480660	2487380	So what happened, let's say, between the 90s towards the 2000s and 2010s, maybe?
2488420	2492900	Oh, there's, you know, it's hard to sort of single out any specific sort of
2492900	2497140	direction. So just like, you know, in general, what happened in the rest of the
2497140	2503700	control systems branches, adaptive control tools started looking at nonlinear
2503700	2509380	systems, different kinds of nonlinearities, multivariable systems, distributed
2509380	2514780	adaptive controllers, looking at what happens when there are time delays and what
2514780	2519780	happens when you're trying to implement adaptive control in cyber-physical systems
2519820	2526660	and what's the right way to allocate the computation to different kinds of
2527180	2529900	components in a real-time embedded system.
2530740	2536580	And of course, you know, applications, what exactly is the kind of uncertainties
2537340	2540820	that are typically present in applications?
2540820	2545860	For instance, in a flight controller, you say, OK, here is a system dynamics, even
2545860	2549020	though, let's say, XR equals AX plus BU, A and B are unknown.
2549460	2552540	Let's parse that a little bit more carefully.
2552860	2556100	What exactly is unknown in a dynamic system?
2556380	2561180	Because it's not as if you know nothing about A and B and then you start designing
2561180	2563220	K. There's a lot of information.
2563580	2568420	And so one of the things that sort of, you know, came into, that people had better
2568420	2573740	understanding of as time went on, for instance, you know, wind tunnel tests are
2573740	2579740	things that are very carefully employed before designing a flight control system.
2579980	2583860	So there's a lot of information in the dynamics.
2583860	2588460	So based on, you know, aerodynamics, understanding of the equations of motion,
2588460	2595100	conservation equations, and I'm putting it in a very simplified way, A is not really
2595100	2597540	unknown. There's a lot of information in A.
2597900	2601460	Now, on the other hand, B matrix, that's a very different story.
2601780	2605740	It's not often that you know everything about it because it has to do with the way
2605740	2609820	in which control surfaces interact with the aerodynamics.
2610100	2614860	And not only that, control surfaces, you know, have many different components to it.
2614860	2619020	From the time you actually have the information coming from your controller and
2619020	2624340	then goes into the appropriate computational structures and then goes into this thing
2624340	2628460	called the actuator and then the actuator basically provides, say, for instance, the
2628460	2631780	control moments and forces, there's a lot that goes on.
2631980	2635580	And in that whole chain of events, there can be a lot of uncertainty.
2635580	2637780	So sometimes it's not that A is unknown.
2637980	2643140	There are specific aspects to B, B times U, that basically can have uncertainty.
2643140	2647700	So then you see, here you have this very generic theory, but then you have to
2647700	2651100	systematically break it down and figure out how it should be applied.
2651100	2655460	So many of those developments also happened as the years went by.
2655460	2659940	So and then how do you actually, you know, scale the whole problem up?
2659940	2663740	So one of the things that papers that we wrote was on a multivariable control
2663740	2668860	system, which was for a very flexible aircraft, which had something like, oh, I
2668860	2676620	don't know, 700 state variables and 33 control inputs and 300 or so outputs.
2676860	2680580	And so, you know, that's then it had several parameters that we were adjusting
2680580	2683060	and we showed that in real time you could do all of those things.
2683220	2687540	So, you know, many of these kinds of developments, I would say, are probably
2687540	2691460	what occupied the attention and is still occupying the attention of researchers
2691780	2693260	in the adaptive control community.
2694020	2699540	And maybe not to, of course, it will not be possible to cover everything in the
2699540	2701940	span of just one hour or a little more.
2703020	2708380	So we'll definitely do some injustice to some researchers in adaptive control.
2708780	2713340	But something that I really want to touch on is the connection between adaptive
2713340	2718460	control and essentially reinforcement learning or modern machine learning.
2718940	2723740	I found in reading this beautiful history paper that you wrote together with
2723740	2729100	Professor Fraktov, that there was an article by Richard Sutton, Andrew Bartow
2729100	2731660	and Ronald Williams on the Control Systems Magazine.
2732020	2736300	So literally speaking to a control audience where the title is literally
2736820	2739980	reinforcement learning is direct adaptive optimal control.
2740580	2745900	So I found it incredibly funny because they're now regarded as pioneers in the
2745900	2747220	field of reinforcement learning.
2747260	2752860	And they were telling us that what they're doing is direct adaptive optimal control.
2753820	2754020	Yeah.
2754020	2759660	So essentially in 2016, we all know that AlphaGo made a splash by beating Lee Sedol,
2759660	2761460	the champion on the game of Go.
2761900	2765660	And therefore there was a huge resurgence in interest, if you want, on
2765780	2766660	reinforcement learning.
2767380	2768860	What is the interplay now?
2769740	2770780	What is the status?
2771660	2772060	Right.
2772140	2779740	Oh, that's a very hard question to answer in the time that we have.
2780300	2787100	Again, just like the one I would certainly like to defer the listener to the recent
2787100	2793100	article that I mentioned that will appear in the annual reviews, Controls, Robotics
2793100	2794980	and Automation for details.
2795380	2800500	But, you know, the two fields, reinforcement learning and adaptive control, have
2800660	2807060	evolved differently with different tools and more importantly, different objectives.
2807780	2814260	And the problems formulation statement in the two fields, they also vary.
2814380	2816300	So what is adaptive control saying?
2816300	2820420	Adaptive control is saying that I have a dynamic system.
2820580	2823740	And right now, right now, there is an uncertainty.
2823780	2827540	Or, you know, imagine again, let's consider a flight platform, right?
2827900	2829020	A quadrotor.
2829380	2830140	It's a drone.
2830340	2832300	It's flying and it's in mid-flight.
2832940	2834300	And then something goes wrong.
2834420	2835500	It's in mid-flight.
2835580	2838140	And then right now, in real time, something goes wrong.
2838900	2846700	You don't have time to do experiments and do a lot of simulations.
2847100	2850660	And, oh, what if I were to use this policy, then what would it do?
2850780	2852220	You just don't have the time.
2853100	2859460	And so you directly have to adapt and you have to figure out on the fly, what kind
2859460	2863740	of thrust do I give to those motors in order to have it still do its thing,
2863740	2866820	whatever it might be, hover, follow a particular flight path.
2867340	2872060	So the emphasis is on coming up with a solution in real time.
2872540	2877740	So because of that, adaptive control is geared towards what
2877740	2880060	happened and what is happening.
2880060	2882700	So it looks at the past and the present.
2883540	2888700	Now, when you go into reinforcement learning, the trajectory there evolved
2888700	2890900	from a point of view of optimality.
2891300	2896460	So even let's take that, the game, the chess or a goal, you have to figure out
2896460	2902420	what your policy is that needs to happen now and in the future.
2902460	2908340	So you're looking at the present and the future, and you're trying to be optimal
2908380	2910740	in terms of what the policy is that you're going to take so that
2910740	2911940	you can beat your opponent.
2912420	2917020	Now, you can see that distinctly, they have two different points of view.
2918060	2921420	Past and present is really what you're looking at in adaptive control, simply
2921420	2923100	because of the problem statement.
2923140	2927300	And again, present and future is what you're looking at simply
2927300	2928940	because of the problem statement.
2929220	2933660	So necessarily they deployed different disparate tools in
2933660	2935420	order to realize their objective.
2936100	2940180	However, both of them have a common feature, which is that both of them are
2940180	2944780	trying to deal with problems that have uncertainties in them.
2945060	2949260	But it's just that when you go in and start unpacking it and go into the
2949260	2953380	details, the statements that are being made and the tools that need to be
2953380	2955380	employed start becoming different.
2955940	2963180	And so this is why when you start to apply RL to problems in dynamic systems,
2963180	2968820	which have uncertainties, I think one needs to be careful in figuring out what
2968820	2974460	exactly are the different kinds of things that are under your disposal.
2975340	2981780	If indeed you have time to make the decisions of exploration, then you have
2981780	2985700	time before you start figuring out when you start your exploitation.
2986180	2988380	Exploration here is parameter learning.
2988380	2990180	Exploitation here is control.
2990180	2993300	I mean, though, if you go into the details, I'm sure there are different
2993300	2996580	shades and nuances, but for the sake of discussion, suppose you do that.
2996580	3000340	Then if you're in real time, you don't have time to explore.
3000820	3003540	You really have to control first before you can learn.
3003540	3005740	So then control comes before learning.
3006300	3010420	So those are the kinds of things where adaptive control and reinforcement
3010420	3014900	learning differ and have different kinds of strengths and weaknesses.
3015460	3020940	There's no question that there is a lot of tools that we can do in machine
3020940	3025300	learning that help us deal with unstructured environments, large data
3025300	3027540	sets, huge number of agents.
3027740	3033460	So many of those lessons and successes that have been illustrated in algorithms,
3033940	3038620	we should start to figure out how we can combine that with tools that
3038620	3039820	are used in adaptive control.
3039820	3044780	From the same point of view, adaptive control basically has lots of dos and
3044780	3048500	don'ts for very good reasons, like, you know, this whole concept that we keep
3048500	3051340	talking about of duality between estimation and control.
3051580	3053820	Sometimes you have to put control before learning.
3053820	3057380	You do control first and then you learn with hindsight.
3058020	3063700	So you have to make sure that even when you have, there's sometimes you don't
3063700	3066900	have enough information to have perfect learning.
3066900	3070420	So in that case, you cannot do the indirect control.
3070420	3073100	You cannot fully learn the parameters before you do control.
3073340	3078220	And there's another thing about, you know, the title direct, adaptive, optimal
3078220	3081180	control, that's very difficult to do.
3081300	3085180	Again, because of what I said, which is what is difficult to do, adaptive
3085300	3087540	and optimal at the same time.
3087940	3090340	The reason is exactly because of what I said earlier.
3090780	3095220	You, you are now looking at the past and the present, and you need to fix that
3095220	3097620	first before you can start looking into the future.
3098020	3101260	So I firmly believe, and that's one of the things that I think is mentioned in
3101260	3107700	the paper, that is this sort of adapt, learn, optimize triad that I think we
3107700	3108580	need to think about.
3108620	3112020	So first you adapt, then you learn with hindsight.
3112060	3114820	And then now that you've learned, you go ahead and optimize.
3115180	3118500	And that kind of a sequence sometimes is inevitable.
3119260	3120540	That's fantastic point of view.
3120540	3121180	Fantastic.
3121780	3126860	Um, essentially in the last few moments, you also addressed one of the questions
3126860	3131540	that I wanted to ask you, which was what can the two fields teach to one another?
3131540	3132580	So I'll ask you another one.
3133060	3136820	And that's, what are you most excited about for the years to come?
3137020	3142180	Uh, how do you envision say emerging worlds like those of machine learning
3142180	3148100	where now we're really heading towards, uh, from translating speech into actions
3148100	3152940	or speech into images and the world of, uh, adaptive control.
3153340	3154380	Uh, what, what do you see?
3154580	3156860	Oh, I think we've just scratched the surface.
3156860	3158540	There's just so much to do.
3158860	3163060	And I hope that the younger, younger generation will continue to do that
3163380	3167860	because I, I don't know how much more time I'll, I'll have myself to continue
3167860	3169620	to, you know, chip away at this.
3170020	3176340	I mean, computationally the world has changed so much, even, you know, over
3176340	3181980	the last, uh, 20 years, what we used to think of as, uh, methods that are, oh
3181980	3186900	my God, that's going to be impossible to do are now not just possible.
3186980	3187980	It's a cakewalk.
3188460	3195100	So that kind of a, sort of a breakdown of the, the, the blinders that we used to put
3195100	3197260	for ourselves, Oh, this is computationally.
3197340	3197740	Okay.
3197740	3198860	But this one, Oh, come on.
3198860	3203140	That's never going to be possible is not, is that boundary is changing so much.
3203460	3207700	I mean, still, I think there are some challenges in terms of, I mean, like for
3207700	3211900	instance, why is adaptive MPC not here yet?
3212060	3216820	Because even that as competent, uh, even with the computational resources, still,
3217180	3221100	I don't think we are there to figure out how you can do the adaptation
3221260	3223420	and optimization at the same time.
3223620	3228220	So trying to figure out how you can leverage the kind of computational
3228220	3233340	resources that you have in figuring out what needs to happen offline.
3233660	3236860	And what needs to happen online is I think the challenge.
3237260	3240420	How do you make sure that you address the sim to real gap?
3240860	3245340	How do you make sure that you leverage all of the things that you learned
3245420	3250580	offline and keep that, uh, transport them into an online construct?
3250980	3255700	This interplay is, I think, becoming very complex.
3255780	3261580	And that is, I think the boundary that we have to navigate and, uh, figure
3261580	3263900	it out and tease apart as we go forward.
3263940	3265620	I think there's so much to do there.
3265900	3270060	And again, one of the biggest things that has to happen is more dialogue
3270060	3272940	and more conversations and more collaborations between the two
3272940	3274580	communities, which is beginning to happen.
3275060	3278980	So not necessarily just more computation, but also more theory, more dialogue.
3280900	3281260	Okay.
3281300	3285580	Um, maybe, you know, moving towards the end of our conversation
3285580	3289700	there's a couple of questions that I tend to ask to everyone that features
3289700	3293660	on the show, one of them is about advice to future generations.
3293780	3298420	So if there is anything that you would have liked to know before starting
3298420	3302380	your career, was there anything that you would advise, say to current
3302380	3304060	students or even future students?
3304500	3309580	Um, I think you need to figure out how you can be extremely good at one
3309580	3311780	thing and very good at many things.
3312300	3313540	It's not easy to do.
3314060	3318340	You have to have a mainstay that where, you know, and that's what, if you think
3318340	3321780	about, if you're a doctoral student, that's exactly what a PhD is, right?
3321780	3324780	That you are going to be the expert.
3325340	3330180	Um, or I mean, not just one of the experts in that particular area and
3330180	3332580	you're intimately familiar with that, right?
3332580	3333580	That's what I mean by that.
3333580	3340340	But I think the, the specialty is becoming, it needs to happen
3340420	3343060	even along with many other things.
3343340	3348700	And so the breakdown between what you're doing in your area and it's, it's
3348700	3354140	interrelation with the other domains is becoming a lot more complex.
3354140	3358820	And so compared to, I think what it used to be maybe 20, 30 years ago,
3359300	3364380	the, the awareness and the understanding of how to converse with other
3364740	3370780	transdisciplinary partners becoming more and more important, um, you know,
3370900	3372980	controls is changing a lot.
3373100	3378500	It's no longer a feedback control of a single device or a single system.
3378780	3382700	It's no longer control of a large scale system is no longer control of
3382700	3384420	a large scale engineer systems.
3384420	3390780	It's really things that control is present and needed in a societal scale.
3391140	3395340	So, which means that you really start to, you need to start thinking about
3395780	3399940	what does it mean, this concept and this very broad canvas.
3400020	3404980	How do you apply that in the context of say, for instance, energy justice,
3404980	3409580	which is a totally different domain, but still there is a notion of here
3409580	3413620	is a system, here's a performance, here's ways you monitor it and develop
3413620	3416500	metrics, and here's how you mitigate something, right?
3416780	3421780	So in order to do all of those things, it seems to me that in addition to being
3421780	3426340	very good, excellent at one thing, you really need to do at least one thing
3426380	3429660	where you're completely out of your comfort zone.
3430460	3435060	And, you know, I think you should do that activity where you're so scared.
3435100	3438820	Like you, I know nothing about it, but I think it's very important to immerse
3438900	3441820	ourselves in that endeavor and you learn that thing.
3442180	3447140	And so that I think gives you the ability to, to really understand
3447140	3450700	controls and in its essence and in a very broad way.
3450900	3453580	I mean, for instance, I know you didn't quite ask this question,
3453580	3455220	but let me answer that anyway.
3455700	3459220	In our lab, there are sort of two thrusts in my, you know, the active
3459220	3460700	adaptive control lab at MIT.
3460740	3465620	One is to do develop control in a very deep sense and look at adaptive
3465620	3468220	control, you know, and its intersections with machine learning.
3468540	3473140	The other thrust is in trying to implement control in a very broad
3473140	3478420	sense and to look at ways in which the whole notion of how you collect
3478420	3483100	information and implement decisions in a large scale system, say, for instance,
3483100	3488820	in power grids or in transportation or in other sort of endeavors that you
3488820	3492180	wouldn't normally think of in terms of what a control is, you know, in a
3492180	3494580	non-engineered sense in a societal scale system.
3494860	3499700	So I think having this kind of two pronged attack, I think is very useful.
3500420	3501700	That's fantastic.
3501700	3506620	Actually, apologies for not touching on the huge endeavor also that you're
3506620	3508700	having in the field of smart grids.
3508740	3511340	That's another major line of research of yours.
3511340	3515300	And actually I'll put a link to a couple of papers in the description, just for
3515300	3518380	people who are interested in this topic and in ANUS research.
3519620	3524900	Just to finish on the topic of future generations, I'm curious whether do you
3524900	3529780	have some kind of secret sauce for when you feel stuck or, I mean, it's something
3529780	3534060	that happens a lot for PhD students and in general to any researcher, I would say.
3534500	3537700	So what is your approach to that feeling?
3538180	3545620	Yeah, no, I mean, research is all about figuring out how to even realize that
3545620	3549100	you're stuck and, you know, to get unstuck.
3550460	3556260	One of the things I learned from my advisor, Professor Narendra, is how to have
3556260	3563860	the intellectual courage to completely scrap what you're doing and start from
3563860	3564740	with a clean slate.
3565140	3568340	Don't try to tweak things and say, OK, all right, maybe you should.
3568340	3568900	No, no, no, no.
3569060	3573980	Just pull back and have the courage to just completely chuck everything that you
3573980	3578300	might have been doing either for the past week or a past month or even a past
3578300	3581260	year and say, start from scratch.
3581620	3583340	OK, what is it that you're trying to do?
3583660	3590620	So starting with a fresh slate, blank slate, clean slate, and really regroup.
3590620	3592980	And OK, what is that problem?
3592980	3597900	And to zoom out and ask questions at a very high level and again start zooming
3597900	3600180	in helps enormously.
3600660	3605500	But for to do that, you should have the courage to chuck what you're doing because
3605500	3608660	it's like, oh, my God, I've put so much effort into it and I have all this
3608660	3609700	information and knowledge.
3609700	3610340	Yes, you do.
3610620	3612660	But believe me, it will help you.
3612980	3616620	But don't be straightjacketed with what you're facing right now.
3616780	3622140	I found and that's something I learned from Professor Narendra and that has served
3622140	3624140	me again and again extremely well.
3624580	3628940	Well, you're serving me a fantastic assist for another question that I ask to
3628940	3631420	everyone else that features on your show.
3631420	3635420	And that's who were the most influential figures in your careers?
3635420	3637940	If you had to name three, who would they be?
3638700	3642460	Definitely, I would start with Professor Narendra.
3642700	3649140	I have learned so much from him how to be a researcher, how to figure out how to
3649140	3653100	pick problems and how never to really give up.
3653100	3659820	And that enthusiasm and that optimism is something that I learned from him.
3660220	3664060	Other than that, I don't know if there is, I would say it's directly because of
3664060	3666740	interaction with any specific individual.
3666740	3672180	But, you know, all of Kalman's work have been, you know, enormously
3672180	3675420	inspirational and sort of mind boggling.
3675420	3676300	Where did this come?
3676300	3678980	I mean, like I was talking about Kalman Yakovlevich's lemma, right?
3678980	3680180	Where did that come from?
3680180	3684220	How did they even think to sort of connect some very two disparate things
3684220	3688100	from input-output property to a Lyapunov function?
3688100	3690300	I have learned a lot from that.
3690300	3696540	And the other, again, works of that, and I began to know about Pravin Varaya
3696540	3699780	only and started interacting with them much, much later.
3700140	3706100	But again, his papers, too, I found have been enormously educational and
3706100	3711700	inspirational in terms of how you can, and there is something that is
3711700	3716060	attributed to him in terms of what they call is a folk theorem about
3716060	3717860	optimization in power grids.
3718140	3723540	And I find that to be a seminal work that sort of brings in elements of
3723540	3729300	analysis into something that really was groundbreaking in the context of
3729300	3731660	constraint optimization in power grids.
3731940	3734900	So I would mention, I guess, those three individuals.
3734900	3735180	Yeah.
3736220	3737100	Thanks for this.
3737140	3741260	In closing, maybe the last question I want to ask you is out of curiosity,
3741260	3742620	on a more personal level.
3742940	3748900	Do you have any like favorite pastime or, and I don't know, do you like reading?
3748900	3753460	Do you like any specific type of exercise or anything like that?
3753540	3755220	Oh yeah, no, I like to read a lot.
3755220	3758740	I'm more partial to fiction than nonfiction.
3759180	3764820	So I always have at least one book on iPad to read and one physical book to read.
3764820	3768140	So, you know, about anything and everything, I mean, I'm part of three
3768140	3772660	different book clubs and, and, you have any three books to recommend to the
3772660	3774900	audience, like your favorite books ever?
3775060	3780380	Um, well, uh, the book Thief, um, uh, Cutting for a Stone, those are older.
3780380	3783420	And the one, the most recent one I read was Cloud Cuckoo Land, which is
3783420	3790540	absolutely fantastic, all actually very incisive portrayals of humanity
3790540	3791900	and interrelationships.
3792220	3792420	Yeah.
3793420	3795780	Well, Anu, it's been a pleasure to have you on the show.
3795780	3797940	It's been really a fantastic ride.
3798220	3801700	Um, thank you for being here and thanks for taking the time to join us.
3802020	3803140	It's been my pleasure.
3803260	3804020	Absolute pleasure.
3804060	3805100	Thank you for having me here.
3811500	3812420	Thank you for listening.
3812820	3814060	I hope you liked the show today.
3814940	3818700	If you enjoyed the podcast, please consider giving us five stars on Apple
3818740	3824260	Podcasts, follow us on Spotify, support on Patreon or PayPal, and connect
3824260	3826260	with us on social media platforms.
3827380	3828180	See you next time.
