1
00:00:00,000 --> 00:00:10,480
Hello and welcome to In Control, the first podcast on control theory.

2
00:00:10,480 --> 00:00:21,240
Here we discuss the science of feedback, decision making, artificial intelligence and much more.

3
00:00:21,240 --> 00:00:25,040
I'm your host Alberto Padoan, live from our recording studio in Lausanne.

4
00:00:25,040 --> 00:00:29,540
Again we're here in the beautiful French speaking side of Switzerland for a nice event which

5
00:00:29,540 --> 00:00:33,980
brought together some of the most brilliant minds out there in control and machine learning.

6
00:00:33,980 --> 00:00:39,900
Today our guest is Anu Anaswamy, Director of the Active and Adaptive Control Laboratory

7
00:00:39,900 --> 00:00:44,340
and Senior Scientist at the Massachusetts Institute of Technology in the Department

8
00:00:44,340 --> 00:00:46,180
of Mechanical Engineering.

9
00:00:46,180 --> 00:00:47,340
Welcome to the show Anu.

10
00:00:47,340 --> 00:00:48,340
It's my pleasure.

11
00:00:48,340 --> 00:00:49,620
Thanks for having me.

12
00:00:49,620 --> 00:00:53,360
Just before I forget, quick thanks to our sponsors as well to the National Center of

13
00:00:53,360 --> 00:00:58,480
Competence in Research on Dependable Ubiquitous Automation as well as the International Federation

14
00:00:58,480 --> 00:01:00,060
of Automatic Control.

15
00:01:00,060 --> 00:01:08,340
Anu, just to break the ice, what do the first 60 minutes of your day look like?

16
00:01:08,340 --> 00:01:14,340
Ah, well, emails I think.

17
00:01:14,340 --> 00:01:21,260
There's always something very interesting and informative and surprises that sort of

18
00:01:21,260 --> 00:01:22,860
set the day.

19
00:01:22,860 --> 00:01:29,040
And you know, with everybody working around the clock on controls research, colleagues

20
00:01:29,040 --> 00:01:35,280
in Europe have been up for, say for instance, six hours before me and they tell me what's

21
00:01:35,280 --> 00:01:40,120
been going on and that sets the day and, you know, there are then discussions and meetings

22
00:01:40,120 --> 00:01:41,120
and all that.

23
00:01:41,120 --> 00:01:45,680
And so that's basically every 60 minutes of my day start with.

24
00:01:45,680 --> 00:01:50,120
Are you the kind of person that likes, say, to do, I don't know, physical exercise or

25
00:01:50,300 --> 00:01:52,820
meditation or anything like that?

26
00:01:52,820 --> 00:01:55,980
Yeah, I do do them, but later in the day.

27
00:01:55,980 --> 00:02:01,580
But I'd like to start, you know, have my cup of coffee and just jump into work.

28
00:02:01,580 --> 00:02:05,940
And of course, these days, there's always Wordle that starts the day.

29
00:02:05,940 --> 00:02:06,940
Who isn't doing that?

30
00:02:06,940 --> 00:02:07,940
Right.

31
00:02:07,940 --> 00:02:09,180
And then, of course, email.

32
00:02:09,180 --> 00:02:11,220
And that's how my day begins.

33
00:02:11,220 --> 00:02:12,220
Yes.

34
00:02:12,220 --> 00:02:13,220
Yeah.

35
00:02:13,220 --> 00:02:18,340
So maybe, you know, shifting towards the topic of today, which hopefully will be adaptive

36
00:02:18,360 --> 00:02:25,240
control, which is an area of expertise of yours and also its history, I would like to

37
00:02:25,240 --> 00:02:29,360
maybe ask you what has drawn you to control in the first place?

38
00:02:29,360 --> 00:02:35,240
So I know that reading your biography, I saw that you have not just one, but two undergraduate

39
00:02:35,240 --> 00:02:36,240
degrees.

40
00:02:36,240 --> 00:02:37,240
Is that right?

41
00:02:37,240 --> 00:02:38,240
That is correct.

42
00:02:38,240 --> 00:02:39,240
Okay.

43
00:02:39,240 --> 00:02:44,520
And so, yeah, I was curious, given that you have this broad span, what has drawn you to

44
00:02:44,520 --> 00:02:45,520
control?

45
00:02:45,520 --> 00:02:46,520
Okay.

46
00:02:46,520 --> 00:02:47,520
Yeah, no, I'd be very happy to answer that.

47
00:02:47,700 --> 00:02:53,060
So, as you mentioned, I have two undergraduate degrees, and the first one was in math.

48
00:02:53,060 --> 00:03:00,580
And what I found towards the end of that education is that I wanted to really move towards a

49
00:03:00,580 --> 00:03:02,700
more applied aspect of math.

50
00:03:02,700 --> 00:03:07,260
So this was all fine, and I loved doing what I was doing there, but I wanted to know what

51
00:03:07,260 --> 00:03:08,520
it was all for.

52
00:03:08,520 --> 00:03:11,980
So that drew me to my second degree, which was in engineering.

53
00:03:11,980 --> 00:03:15,340
And there was a very specific program where only graduates were admitted.

54
00:03:15,360 --> 00:03:20,360
So it was sort of like a graduate program almost, except that it was more abridged than

55
00:03:20,360 --> 00:03:27,160
the usual undergraduate degree in engineering in India, which is where I come from.

56
00:03:27,160 --> 00:03:29,080
Was five years at that time.

57
00:03:29,080 --> 00:03:32,800
And so this one was more abbreviated in three years, because you've taken all of your courses

58
00:03:32,800 --> 00:03:35,280
already, and that was in electrical engineering.

59
00:03:35,280 --> 00:03:41,400
And so, but even there, what I found was here were all these different courses that mentioned

60
00:03:41,400 --> 00:03:44,320
as to how the universe worked, which was great.

61
00:03:44,340 --> 00:03:48,780
And then was this controls course, which said, no, no, this is basically how you can modify

62
00:03:48,780 --> 00:03:49,780
the universe.

63
00:03:49,780 --> 00:03:52,700
And I thought, wow, that's really cool.

64
00:03:52,700 --> 00:03:56,740
And I got into that more, and the rest is history, I guess.

65
00:03:56,740 --> 00:04:01,900
So I've been working in that same area, I've never left school.

66
00:04:01,900 --> 00:04:06,100
And I still feel that every day I have something to learn.

67
00:04:06,100 --> 00:04:10,660
And then, you know, like I said earlier, what happens in the first 60 minutes, I can't wait

68
00:04:10,680 --> 00:04:16,560
to see what the day brings in terms of new opportunities, new challenges and controls,

69
00:04:16,560 --> 00:04:19,760
research and new solutions.

70
00:04:19,760 --> 00:04:21,160
And yeah.

71
00:04:21,160 --> 00:04:27,440
And but from India, and then you moved to the US to Boston.

72
00:04:27,440 --> 00:04:30,680
So what has brought you on the other side, I would say?

73
00:04:30,680 --> 00:04:34,280
So I applied to graduate school.

74
00:04:34,280 --> 00:04:39,460
And so there were obviously lots of opportunities in the United States.

75
00:04:39,460 --> 00:04:45,340
And it so happened that I met who would become my future advisor, Professor Narendra, who's

76
00:04:45,340 --> 00:04:47,100
also originally from India.

77
00:04:47,100 --> 00:04:51,820
And it so happened, serendipitously, that he was visiting his parents, who happened

78
00:04:51,820 --> 00:04:54,940
to be in the same city that I was from.

79
00:04:54,940 --> 00:04:56,820
And so, you know, I talked to him.

80
00:04:56,820 --> 00:05:00,980
And again, I found even during the, what, 30 minutes of conversation that we might had

81
00:05:00,980 --> 00:05:03,020
that I was learning so much.

82
00:05:03,020 --> 00:05:05,920
And so it was very clear to me that that's where I'd like to go.

83
00:05:05,920 --> 00:05:10,240
And so when Yale University offered me admission, I just took that.

84
00:05:10,240 --> 00:05:14,260
And so, so before Boston, that's New Haven, Connecticut.

85
00:05:14,260 --> 00:05:18,480
And that's where I did my PhD in adaptive control.

86
00:05:18,480 --> 00:05:19,480
Okay.

87
00:05:19,480 --> 00:05:20,480
Yeah.

88
00:05:20,480 --> 00:05:26,720
So this is actually a good assist for me to ask you, what is adaptive control or even

89
00:05:26,720 --> 00:05:27,800
what is adaptation?

90
00:05:27,800 --> 00:05:33,180
So before we delve into this topic, I think I should mention that, well, you wrote one

91
00:05:33,180 --> 00:05:35,940
of the Bibles of adaptive control.

92
00:05:35,940 --> 00:05:41,300
And I do suggest to everyone in the audience to check out the first chapter of the book

93
00:05:41,300 --> 00:05:47,380
Stable Adaptive Systems by Anu and Professor Narendra, because there is a really fantastic

94
00:05:47,380 --> 00:05:51,220
section about how to even define adaptation.

95
00:05:51,220 --> 00:05:54,500
And it seemed absolutely non-obvious when the whole field started.

96
00:05:54,500 --> 00:05:57,300
So maybe you can tell us a bit more about that.

97
00:05:57,300 --> 00:05:58,300
Absolutely.

98
00:05:58,420 --> 00:06:04,420
So adaptation is exactly what the English word means, it's, you know, as it is defined

99
00:06:04,420 --> 00:06:11,100
in biology, advantageous confirmation of an organism to changes in its environment.

100
00:06:11,100 --> 00:06:15,380
So interestingly enough, and I don't know if this was quite your question, but let me

101
00:06:15,380 --> 00:06:18,860
answer if it's a different question, then apologies.

102
00:06:18,860 --> 00:06:26,100
So in adaptation, that concept is the one that caught the imagination of a lot of flight

103
00:06:26,100 --> 00:06:28,820
control engineers and admirals.

104
00:06:28,820 --> 00:06:36,060
And so what they really wanted to do was to design systems, design controllers that figured

105
00:06:36,060 --> 00:06:37,420
on the fly.

106
00:06:37,420 --> 00:06:43,020
And again, the emphasis is on the fly, meaning in real time, as to how to adjust its structure

107
00:06:43,020 --> 00:06:48,340
so that it adapted to changes in the environment and corrected itself and behaved.

108
00:06:48,340 --> 00:06:55,900
So even before theory, adaptive control theory came into being, adaptive control practice

109
00:06:55,900 --> 00:06:57,940
was already there.

110
00:06:57,940 --> 00:07:02,580
So it's one of those interesting cases where practice was ahead of theory.

111
00:07:02,580 --> 00:07:10,500
And so there was this one specific hypersonics program called X-15, where the different control

112
00:07:10,500 --> 00:07:16,100
loops that they had, they chose to make one of them adaptive.

113
00:07:16,100 --> 00:07:22,140
And they actually had several successful flights where the notion of adaptation was basically

114
00:07:22,220 --> 00:07:29,020
in the form of control gains in the feedback loop that basically toggled between two different

115
00:07:29,020 --> 00:07:30,300
values.

116
00:07:30,300 --> 00:07:32,980
And they did that on the basis of what they were measuring.

117
00:07:32,980 --> 00:07:39,620
So in some sense, an exact manifestation of advantageous changes in the organism in response

118
00:07:39,620 --> 00:07:41,580
to changes in the environment.

119
00:07:41,580 --> 00:07:45,860
And they had several successful flights that basically did that.

120
00:07:45,860 --> 00:07:49,220
But then I'm sure we will get more into what happened next.

121
00:07:49,380 --> 00:07:50,100
Absolutely.

122
00:07:50,100 --> 00:07:56,220
That was really the idea behind adaptive control.

123
00:07:56,220 --> 00:08:04,500
And the symposia that were held on adaptive systems at that time tried to capture that

124
00:08:04,500 --> 00:08:07,060
essence in the definition of an adaptive system.

125
00:08:07,060 --> 00:08:13,340
So and then came lots of different efforts in trying to come to a very crisp and useful

126
00:08:13,340 --> 00:08:16,820
definition of adaptation and adaptive control.

127
00:08:16,820 --> 00:08:20,700
And that's what we tried to capture in that introduction.

128
00:08:20,700 --> 00:08:22,500
And one thing left to another.

129
00:08:22,500 --> 00:08:26,020
And then it sort of came to what we know as adaptive control now.

130
00:08:26,020 --> 00:08:27,500
But we can get into that later.

131
00:08:27,500 --> 00:08:28,140
Absolutely.

132
00:08:28,140 --> 00:08:29,820
So I'm glad you mentioned that.

133
00:08:29,820 --> 00:08:34,220
I mean, I guess the main motivation for the development of adaptive control and now we're

134
00:08:34,220 --> 00:08:39,420
talking about pretty much the 60s, I would say, or even before that, of course, we can

135
00:08:39,420 --> 00:08:44,180
trace it back to Norbert Wiener and we can even go probably even backwards.

136
00:08:44,220 --> 00:08:51,540
But I guess the 60s, between the 60s and the 65, is what is called the brave era of adaptive

137
00:08:51,540 --> 00:08:57,540
control. And really, it's fascinating to see how many concepts have been developed just

138
00:08:57,540 --> 00:09:00,020
in that five years span.

139
00:09:00,020 --> 00:09:01,500
So I don't know.

140
00:09:01,500 --> 00:09:05,660
Do you have any thoughts about the developments specifically in that time range?

141
00:09:07,540 --> 00:09:08,700
So, yes.

142
00:09:08,700 --> 00:09:15,220
So I mentioned the symposium, and that was a time when people were talking about and

143
00:09:15,220 --> 00:09:18,940
even implementing adaptive control in flight control.

144
00:09:18,940 --> 00:09:23,980
And around the same time is when the concept of state was being defined.

145
00:09:23,980 --> 00:09:29,060
And, you know, the seminal papers by Kallman, Miranda and Ho came at that time.

146
00:09:29,060 --> 00:09:34,020
And dynamic systems and control systems started to get codified around that around that

147
00:09:34,020 --> 00:09:34,980
time as well.

148
00:09:35,140 --> 00:09:41,660
And so people were beginning to understand how to implement the notions of feedback

149
00:09:41,660 --> 00:09:46,620
control and the methods by Black and Bode and Nyquist and understanding closed loop

150
00:09:46,620 --> 00:09:51,540
control system design using by analyzing forward loop and so on.

151
00:09:51,540 --> 00:09:57,420
So it's interesting to see, you know, that the history of feedback control is almost or

152
00:09:57,420 --> 00:10:02,660
rather the history of adaptive control systems has been as long as at least as long as

153
00:10:02,660 --> 00:10:09,300
the history of control systems, because it's very easy, just like feedback is such a

154
00:10:09,300 --> 00:10:16,620
fundamental and conceptually simple idea to understand and to get motivated by.

155
00:10:16,620 --> 00:10:18,100
So is adaptation.

156
00:10:18,100 --> 00:10:22,860
And so, in fact, you could argue that, you know, as you think about it at a very

157
00:10:22,860 --> 00:10:29,380
philosophical level, the idea of a feedback control system is not that far from the idea

158
00:10:29,380 --> 00:10:30,700
of an adaptive control system.

159
00:10:30,700 --> 00:10:38,140
So I would say those many of those fundamentals started to get defined around that time.

160
00:10:38,140 --> 00:10:41,620
But then I think we probably go towards the early 70s.

161
00:10:41,620 --> 00:10:44,460
If you want, I can get into into that.

162
00:10:44,460 --> 00:10:49,820
Yeah. So I would like to maybe add a few things about this brave era and then we can

163
00:10:49,820 --> 00:10:52,340
definitely move on to the 70s.

164
00:10:52,340 --> 00:10:57,700
So what I personally found fascinating was that there were incredibly influential people

165
00:10:57,700 --> 00:10:59,860
working in this specific time range.

166
00:10:59,860 --> 00:11:07,060
So between the let's say until the 1965, that we're focusing on adaptive systems.

167
00:11:07,060 --> 00:11:12,620
So we're talking about people of the caliber of not only Kalman and Bellman, but also

168
00:11:12,620 --> 00:11:18,820
Simon, who got a Nobel Memorial Prize in economic sciences in 78 for works on dynamic

169
00:11:18,820 --> 00:11:21,300
programming under uncertainty.

170
00:11:21,300 --> 00:11:27,020
And it is around this time that also the concept of dual control theory is being

171
00:11:27,020 --> 00:11:30,140
developed by Feldbaum in Soviet Union.

172
00:11:30,140 --> 00:11:36,860
And also Whittaker, I guess, is around this time that the famous MIT rule is developed.

173
00:11:36,860 --> 00:11:42,820
Maybe you can tell us something about that rule and also what led to, I don't know,

174
00:11:42,820 --> 00:11:45,180
the future developments in the 70s.

175
00:11:45,180 --> 00:11:50,940
Sure, sure. So let's go back to what we talked about as the concept of adaptation,

176
00:11:50,940 --> 00:11:55,140
right? Advantageous confirmation of an organism.

177
00:11:55,140 --> 00:11:59,700
So bring it to the context of a dynamic system.

178
00:11:59,700 --> 00:12:05,100
So here you have a dynamic system, which is the actual, say, aircraft or robot or process

179
00:12:05,100 --> 00:12:06,700
controller or what have you.

180
00:12:06,700 --> 00:12:10,740
And you are monitoring how it's performing.

181
00:12:10,740 --> 00:12:15,340
And then a controller is set in and set in place in closed loop.

182
00:12:15,340 --> 00:12:16,660
And then you design the controller.

183
00:12:16,660 --> 00:12:19,340
So that's what every feedback control system does.

184
00:12:19,380 --> 00:12:25,340
So now the advantageous confirmation here in the context of an adaptive control system

185
00:12:25,340 --> 00:12:34,420
is basically one where you are advantageously adjusting the control parameters in that

186
00:12:34,420 --> 00:12:39,020
control system. So imagine if you had a PID controller, then you're adjusting the PID

187
00:12:39,020 --> 00:12:44,940
gains because what you did at 10,000 feet might be very different from what happens at

188
00:12:44,940 --> 00:12:47,020
30,000 feet and so on.

189
00:12:47,020 --> 00:12:51,660
And so something like a hypersonics flight, which basically covers a large flight

190
00:12:51,660 --> 00:12:56,100
envelope, you do need to have that flexibility in adjusting yourself.

191
00:12:56,100 --> 00:12:57,700
So what do you do then?

192
00:12:57,700 --> 00:13:02,020
What is the response from the environment that you observe?

193
00:13:02,020 --> 00:13:05,300
Then you look at some sort of a performance quantity.

194
00:13:05,300 --> 00:13:09,500
So what we call these days as loss function.

195
00:13:09,500 --> 00:13:14,380
And so you then try to adjust your gains in a way so that you minimize that loss

196
00:13:14,380 --> 00:13:15,380
function.

197
00:13:15,380 --> 00:13:17,300
And so what do you do in order to do that?

198
00:13:17,300 --> 00:13:19,340
You look at something called the gradient.

199
00:13:19,340 --> 00:13:24,260
OK, all right, let's adjust the gains so that when I look at the gradient of this loss

200
00:13:24,260 --> 00:13:29,100
function, then that gives me the indication as to what direction should I adjust.

201
00:13:29,100 --> 00:13:30,700
Is it down or is it up?

202
00:13:30,700 --> 00:13:31,780
And by how much?

203
00:13:31,780 --> 00:13:33,980
And I designed it step size and so on.

204
00:13:33,980 --> 00:13:38,420
So all of those things were basically captured in the MIT rule.

205
00:13:38,460 --> 00:13:45,500
And so who, I mean, yeah, so who basically proposed that particular concept.

206
00:13:45,500 --> 00:13:50,740
So now in parallel, people were trying, beginning to understand about stability

207
00:13:50,740 --> 00:13:56,940
theory, about how to design control systems for systems with nonlinear dynamics.

208
00:13:56,940 --> 00:13:59,780
And so the whole notion of Lyapunov's direct method.

209
00:13:59,780 --> 00:14:04,660
And again, Kalman wrote the seminal paper of how to use that in the design of

210
00:14:04,660 --> 00:14:05,820
nonlinear control systems.

211
00:14:05,820 --> 00:14:12,740
So what people found out soon in the 70s was that this MIT rule, while it's great in

212
00:14:12,740 --> 00:14:16,260
many cases, it sometimes big falls short.

213
00:14:16,260 --> 00:14:21,580
And that is captured by basically tools from stability theory, which says that these

214
00:14:21,580 --> 00:14:26,580
gradient rules are things that do not actually not only not help you, but sometimes

215
00:14:26,580 --> 00:14:30,940
really hurt you because it can actually produce some instabilities if there is a

216
00:14:30,940 --> 00:14:36,180
latency between those performance functions you're measuring and the parameters.

217
00:14:36,180 --> 00:14:39,300
And some of those counter examples basically were brought in.

218
00:14:39,300 --> 00:14:46,340
And so that basically led to adaptive control theory, where you really need to look at

219
00:14:46,340 --> 00:14:51,100
two different kinds of measures and errors in the system.

220
00:14:51,100 --> 00:14:55,140
One is this loss function that you can actually measure, but the other is the

221
00:14:55,140 --> 00:14:58,180
parameters that you're trying to learn and adjust.

222
00:14:58,180 --> 00:15:04,140
And you need to worry about what kind of latencies basically are present between the

223
00:15:04,140 --> 00:15:06,460
time you measure and the time you adjust.

224
00:15:06,460 --> 00:15:11,700
And not all problems can be tackled by just using the gradient alone.

225
00:15:11,700 --> 00:15:17,500
So that basically was sort of the foundation of adaptive control theory.

226
00:15:17,500 --> 00:15:19,940
That's a fantastic way also.

227
00:15:19,940 --> 00:15:26,580
I mean, we talk about a fantastic way to move towards a transition between this brave

228
00:15:26,620 --> 00:15:31,740
era and the era of the 70s, where you mentioned that there is a prominent role of

229
00:15:31,740 --> 00:15:34,980
Lyapunov stability in adaptive control.

230
00:15:34,980 --> 00:15:39,660
We also talked about the fact that most of the research in the brave era was motivated

231
00:15:39,660 --> 00:15:41,900
by supersonic flights.

232
00:15:41,900 --> 00:15:47,900
And it is in this time that there are many successful flights, actually, that produce

233
00:15:47,900 --> 00:15:50,820
incredible results, I would say, in avionics.

234
00:15:50,820 --> 00:15:54,780
Maybe we can hear an excerpt of a video that is taken from those years.

235
00:15:54,820 --> 00:15:55,820
Of course.

236
00:15:55,820 --> 00:15:56,820
Yeah.

237
00:16:24,820 --> 00:16:28,820
The crew cameraman in one of the chase planes gets difficult and dramatic coverage of the

238
00:16:28,820 --> 00:16:30,820
smoothly executed landing.

239
00:16:37,820 --> 00:16:43,820
Crossfield is uninjured, but the X-15, one of three in the X-15 research program, sustains

240
00:16:43,820 --> 00:16:46,820
minor repairable damage.

241
00:16:46,820 --> 00:16:51,140
Crossfield checks his bird, which prior to this incident had made several successful

242
00:16:51,140 --> 00:16:54,180
glide and powered flights.

243
00:16:54,580 --> 00:16:58,780
Soon the X-15 will be released from contractor demonstrations, and research flights will

244
00:16:58,780 --> 00:17:04,180
begin by the National Aeronautics and Space Administration and the United States Air Force.

245
00:17:08,180 --> 00:17:14,300
So this excerpt testifies the success of adaptive control, I would say, in practice in the field

246
00:17:14,300 --> 00:17:16,020
of avionics.

247
00:17:16,020 --> 00:17:23,020
The problem is that in 1967, unfortunately, things didn't unfold so well in the test of

248
00:17:23,020 --> 00:17:27,100
a flight that Michael Adams was conducting for NASA, I believe.

249
00:17:27,100 --> 00:17:28,100
That's correct.

250
00:17:28,100 --> 00:17:33,140
He was testing the X-15-3 airplane.

251
00:17:33,140 --> 00:17:37,020
And yeah, unfortunately, things didn't go so well in that scenario.

252
00:17:37,020 --> 00:17:43,500
Michael Adams is known as the first American space mission fatality by the American convention.

253
00:17:43,500 --> 00:17:49,060
He was also the first qualified astronaut because he flew above 50 miles for some period

254
00:17:49,100 --> 00:17:54,100
of time before, unfortunately, his aircraft broke apart.

255
00:17:54,100 --> 00:17:55,500
And maybe we can dig into that.

256
00:17:55,500 --> 00:18:00,580
There is a delightful paper on the Control Systems magazine that you wrote about this

257
00:18:00,580 --> 00:18:01,580
accident.

258
00:18:01,580 --> 00:18:02,620
And I don't know.

259
00:18:02,620 --> 00:18:09,260
So what happened and what were the problems from the point of view of adaptive control?

260
00:18:09,260 --> 00:18:15,500
So I would certainly defer the details of what happened to the paper.

261
00:18:15,500 --> 00:18:18,700
So we do get into that in detail.

262
00:18:18,780 --> 00:18:25,340
But in a sense, what really happened was that there was a one of the there were several

263
00:18:25,340 --> 00:18:31,020
control loops that they had, one of which was had this adaptive capability where there

264
00:18:31,020 --> 00:18:39,260
was a control gain that toggled between two different values based on the content of the

265
00:18:39,260 --> 00:18:43,940
frequency content of a performance measure that they were looking at.

266
00:18:43,940 --> 00:18:48,780
And if depending upon the frequency content, it was either a smaller value or a larger

267
00:18:48,780 --> 00:18:50,460
value, I forget which.

268
00:18:50,460 --> 00:18:52,540
And that was the algorithm.

269
00:18:52,540 --> 00:18:55,300
So you see, in a sense, it's a very simple concept.

270
00:18:55,300 --> 00:18:58,060
I mean, the concept of adaptation is very simple.

271
00:18:58,060 --> 00:19:01,860
You want something and based on what you what you want, you adjust something.

272
00:19:01,860 --> 00:19:07,820
Now, you don't really if you if you're not aware of the complexity of what that means

273
00:19:07,820 --> 00:19:09,940
to the system, then you can get into trouble.

274
00:19:09,940 --> 00:19:13,460
And that's exactly what happened, because you see what you're doing is you're measuring

275
00:19:13,500 --> 00:19:16,060
something and then you're adjusting the parameter.

276
00:19:16,460 --> 00:19:22,020
Now, interestingly enough, I think this I should direct the discussion to Feldbaum's

277
00:19:22,020 --> 00:19:27,860
dual control. Now, what should that parameter be for a given environmental situation?

278
00:19:27,860 --> 00:19:32,740
So in order to really understand that and learn the parameters, you need to go into

279
00:19:32,740 --> 00:19:35,460
estimation. And now that takes infinite time.

280
00:19:35,740 --> 00:19:41,220
Now, in order to really make sure that your performance converges to the right value,

281
00:19:41,220 --> 00:19:42,420
that takes infinite time.

282
00:19:42,420 --> 00:19:47,820
That's control. Now, if you're trying to do both simultaneously, then you can get into

283
00:19:47,820 --> 00:19:53,100
trouble because you're trying to adjust the gains and based on the error and the error

284
00:19:53,100 --> 00:19:54,580
will depend upon the gains.

285
00:19:54,900 --> 00:19:57,740
And so there is a loop circularity here.

286
00:19:57,740 --> 00:20:03,580
And that's exactly what happened, because it turns out that what the situation was, was

287
00:20:03,580 --> 00:20:09,420
not something that really fell neatly into either use this value A1 or A2, but something

288
00:20:09,460 --> 00:20:14,780
else. And that's something that was whatever that new value was, was not learned by the

289
00:20:14,780 --> 00:20:20,300
controller. And because it didn't really learn that value properly, it led into basically

290
00:20:20,460 --> 00:20:23,820
instability because what you have now is a nonlinear control system.

291
00:20:24,260 --> 00:20:31,780
And that had a behavior which led to the closed loop system having unbounded solutions.

292
00:20:32,540 --> 00:20:38,660
So again, here was one where the control practice was way ahead of control theory.

293
00:20:38,860 --> 00:20:43,980
And the awareness that what you really have is a nonlinear control system and it has to

294
00:20:43,980 --> 00:20:47,060
be designed carefully was not there then.

295
00:20:47,140 --> 00:20:49,780
And that's basically what we dug into in the paper.

296
00:20:49,820 --> 00:20:54,780
We said, OK, let's now look at adaptive control because, you know, fast forward to what,

297
00:20:54,780 --> 00:20:57,340
2010 from 1967.

298
00:20:57,660 --> 00:21:02,980
Now we have this understanding of how you should define, design adaptive control

299
00:21:02,980 --> 00:21:08,980
systems, how you can deal with this concept of dual control, where you have this

300
00:21:09,260 --> 00:21:13,540
conflict between infinite time for estimation and infinite time for control.

301
00:21:13,940 --> 00:21:20,020
And you basically break that by introducing appropriate control structures that can make

302
00:21:20,020 --> 00:21:25,020
sure that your performance is well behaved and you have that under control before

303
00:21:25,100 --> 00:21:27,340
learning, before learning.

304
00:21:27,700 --> 00:21:33,340
So you do control first and then with hindsight, you learn the parameters.

305
00:21:33,620 --> 00:21:37,420
That basically is, in a sense, the foundation of adaptive control theory.

306
00:21:37,740 --> 00:21:44,700
It determines a solution to a dynamic system which has uncertainties in real time

307
00:21:45,020 --> 00:21:49,220
without having fully learned what the nonlinear system is.

308
00:21:49,580 --> 00:21:55,540
But what it does is it basically, even with imperfect learning, figures out what the

309
00:21:55,540 --> 00:22:00,180
control system ought to do and so that you can then have the performance in check.

310
00:22:00,740 --> 00:22:06,420
And so what we did in that paper is to basically lay that out and have a correct,

311
00:22:06,940 --> 00:22:08,980
provably correct adaptive controller.

312
00:22:09,300 --> 00:22:13,820
And then we compared it with what was actually implemented in the MH96, which is a

313
00:22:13,820 --> 00:22:16,540
Minneapolis Honeywell 96 controller.

314
00:22:16,660 --> 00:22:20,620
That was the name of that adaptive controller that they had in that fatal flight.

315
00:22:21,260 --> 00:22:25,100
And then we said, OK, let's start to try and compare apples with apples.

316
00:22:25,140 --> 00:22:31,540
And so we started to have a configuration where they looked identical except for, say,

317
00:22:31,740 --> 00:22:34,380
the change in the way in which the parameters were adapted.

318
00:22:34,820 --> 00:22:39,460
And so what we showed was that it was basically the way in which the parameters

319
00:22:39,460 --> 00:22:41,580
were adjusted was incorrect.

320
00:22:41,580 --> 00:22:45,980
And had they really, the awareness of what the overall control system is, had they

321
00:22:45,980 --> 00:22:51,500
done this adjustment according to this rule, then that flight would not have crashed.

322
00:22:51,740 --> 00:22:56,700
So it was a very satisfying experience because it was one of those things where we said,

323
00:22:56,700 --> 00:22:58,820
OK, this is basically what must have happened.

324
00:22:58,820 --> 00:23:00,420
And we were able to replicate that.

325
00:23:00,660 --> 00:23:04,420
And also we could play a what if scenario.

326
00:23:04,420 --> 00:23:09,180
If they had the awareness, this is basically what what they should have done, then

327
00:23:09,180 --> 00:23:10,460
Michael Adams would be here.

328
00:23:11,300 --> 00:23:14,420
I mean, you touched on so many interesting points.

329
00:23:15,020 --> 00:23:19,620
First of all, I want to make sure that the audience knows that there will be links in

330
00:23:19,620 --> 00:23:22,780
the description of this episode to all of the papers that we mentioned.

331
00:23:23,580 --> 00:23:29,940
We're also basing also our story today on a beautiful article written by Anu and

332
00:23:29,940 --> 00:23:32,580
Professor Fratkov on the history of adaptive control.

333
00:23:32,580 --> 00:23:35,020
There will be a link to that paper as well.

334
00:23:35,060 --> 00:23:40,180
There is also an upcoming paper, if I understand correctly, on the interplay between

335
00:23:40,180 --> 00:23:42,180
adaptive control and reinforcement learning.

336
00:23:42,940 --> 00:23:49,100
Yes, it'll appear in the annual reviews in Control Robotics and Automation Systems.

337
00:23:49,100 --> 00:23:52,740
And yeah, the title is exactly that adaptive control and intersections with

338
00:23:52,740 --> 00:23:53,580
reinforcement learning.

339
00:23:53,580 --> 00:23:55,660
There will be a link also to this paper as well.

340
00:23:55,660 --> 00:24:01,780
Of course, in discussing before we touched on, I would say, some very important

341
00:24:01,780 --> 00:24:06,980
points. So the first one that you were mentioning was dual control and essentially

342
00:24:06,980 --> 00:24:12,660
this tension between learning and controlling, which today is what we call the

343
00:24:12,660 --> 00:24:16,660
tradeoff between exploration versus exploitation.

344
00:24:16,980 --> 00:24:21,860
And also, I guess another thing that we should probably mention is that as a result

345
00:24:21,860 --> 00:24:28,620
of this crash, I guess funding was cut short for a short period of time for what

346
00:24:28,620 --> 00:24:30,140
concerns adaptive control.

347
00:24:30,140 --> 00:24:30,940
Is that correct?

348
00:24:30,940 --> 00:24:39,020
Yeah, so certainly people had to regroup and in the specific area of flight control,

349
00:24:39,460 --> 00:24:44,020
there was a pause and efforts to really understand what happened, efforts to

350
00:24:44,020 --> 00:24:49,540
understand control theory, efforts to understand a multivariable control theory.

351
00:24:49,740 --> 00:24:52,300
And so many of those things were set in motion.

352
00:24:52,300 --> 00:24:59,180
And even this whole effort to connect fundamental tenets of stability theory of

353
00:24:59,180 --> 00:25:03,300
nonlinear differential equations with adaptive control, because, you know, the

354
00:25:03,300 --> 00:25:08,260
recognition that what you really are doing when you start to adjust parameters of a

355
00:25:08,260 --> 00:25:13,580
controller in real time makes the whole problem one of a nonlinear time varying

356
00:25:13,580 --> 00:25:17,660
system, a system that is intentionally nonlinear.

357
00:25:17,660 --> 00:25:20,300
So then how do you design those nonlinearities?

358
00:25:20,300 --> 00:25:24,860
And so that's where there was a very elegant connection between adaptive control

359
00:25:24,860 --> 00:25:31,060
design and Lyapunov theory, because Lyapunov theory gives you that guideline as to

360
00:25:31,060 --> 00:25:35,580
how to design the controller such that you make something which is a positive

361
00:25:35,580 --> 00:25:37,820
definite function into a Lyapunov function.

362
00:25:38,060 --> 00:25:40,460
So some of those foundations were in place.

363
00:25:40,460 --> 00:25:45,700
The other very elegant result is it's not something that people talk about a whole

364
00:25:45,700 --> 00:25:50,580
lot these days, but again, in the 70s and the 80s, people explored that quite a bit,

365
00:25:50,580 --> 00:25:55,980
which is a notion of hyperstability and the notion of absolute stability, which

366
00:25:55,980 --> 00:26:01,260
basically is centered on passive systems and strictly passive operators.

367
00:26:01,540 --> 00:26:06,580
And so the whole idea is that if you have, even though they might be nonlinear, then

368
00:26:06,580 --> 00:26:10,740
if you have something which is a strictly passive operator in forward loop, then you

369
00:26:10,740 --> 00:26:16,660
can have several passive operators in feedback loop and structurally the system

370
00:26:16,660 --> 00:26:18,620
will be, will continue to be stable.

371
00:26:18,620 --> 00:26:20,900
So that's why it was called hyperstability.

372
00:26:21,540 --> 00:26:24,660
The notions of absolute stability also are connected with that.

373
00:26:24,660 --> 00:26:30,660
So people like Popov and Aizerman, many of those kinds of really very elegant

374
00:26:31,020 --> 00:26:36,340
stability theories of nonlinear dynamic systems were all sort of brought together.

375
00:26:36,540 --> 00:26:42,460
And this interplay again between parameter adaptation and feedback control were all in

376
00:26:42,460 --> 00:26:47,620
place. And, you know, so then over those two decades, the 70s and the 80s, with these

377
00:26:47,620 --> 00:26:52,980
foundations in place, and then there was another thing to saying, OK, if you really

378
00:26:52,980 --> 00:26:59,020
look at parametric uncertainties, then that gives you the foundation for how to set up

379
00:26:59,780 --> 00:27:00,940
adaptive control systems.

380
00:27:00,940 --> 00:27:06,580
But we also need to look at robustness to nonparametric uncertainties, which might be

381
00:27:06,580 --> 00:27:09,140
in the form of disturbances and model dynamics.

382
00:27:09,420 --> 00:27:15,420
And so I would say in the 90s, the foundations of robust adaptive control were in

383
00:27:15,420 --> 00:27:20,460
place. So this led to introducing terms, which we didn't call it as regularization

384
00:27:20,460 --> 00:27:25,300
then, but it's really ways of regularizing the underlying function, which is convex.

385
00:27:25,300 --> 00:27:27,620
And you really need to make it strongly convex.

386
00:27:27,780 --> 00:27:29,860
And that gives you the robustness.

387
00:27:30,100 --> 00:27:35,020
And that led to a whole bunch of methods based on dead zone, based on what is known as

388
00:27:35,020 --> 00:27:39,060
sigma modification, e-modification, parameter projection.

389
00:27:39,060 --> 00:27:44,020
And all those basically led to this is how you would design a robust adaptive control

390
00:27:44,020 --> 00:27:49,220
system. And so with that now, I say, you know, we should come full circle.

391
00:27:49,420 --> 00:27:55,860
And now coming into the 21st century, there's been actually several successful

392
00:27:55,860 --> 00:28:04,100
demonstrations of advanced flight vehicles with adaptive control, which are actually

393
00:28:04,100 --> 00:28:07,260
in production. And many of these things have been designed by Boeing.

394
00:28:09,020 --> 00:28:10,380
This is something that I didn't know.

395
00:28:10,780 --> 00:28:13,860
I mean, you touched again on so many interesting aspects.

396
00:28:13,860 --> 00:28:17,740
I would like to dissect them a little bit more, all of them, just because it's such a

397
00:28:17,740 --> 00:28:23,460
fascinating story. So again, maybe like moving on from this accident in the 70s, you

398
00:28:23,460 --> 00:28:26,660
mentioned that Lyapunov stability took over somehow.

399
00:28:26,660 --> 00:28:32,540
This is also the time just after 1967 is really the time of also the developments that

400
00:28:32,540 --> 00:28:34,820
led to going on to the moon, essentially.

401
00:28:35,260 --> 00:28:41,500
And so in between, let's say, the 70s and the 80s, stability really played a role.

402
00:28:41,500 --> 00:28:44,780
Lyapunov stability really played a role in adaptive control.

403
00:28:44,780 --> 00:28:50,860
And as you were mentioning, in moving forward towards the 80s, once you have a Lyapunov,

404
00:28:51,100 --> 00:28:56,740
let's say, set up, then it is immediate to ask also the question of robustness of these

405
00:28:56,740 --> 00:29:02,460
methods. Something else that I should mention also before, you know, essentially digging

406
00:29:02,460 --> 00:29:08,740
into this 70s and 80s period is that hyperstability and all of these concepts of

407
00:29:08,740 --> 00:29:11,820
absolute stability as well were coming from the Soviet Union.

408
00:29:12,660 --> 00:29:17,980
And I guess this was also the result of the competition between the US and the Soviets.

409
00:29:17,980 --> 00:29:19,220
I'm not sure about that.

410
00:29:19,780 --> 00:29:20,900
Yeah, you know, yeah.

411
00:29:21,180 --> 00:29:25,940
In fact, when we were writing this paper, Sasha Freitkopf and I were talking about

412
00:29:25,940 --> 00:29:33,100
exactly that, that there's been just so many rich developments, both in the Soviet

413
00:29:33,100 --> 00:29:35,660
Union and the and I guess the Western world.

414
00:29:35,980 --> 00:29:40,340
And many of those things actually happened independently and in parallel.

415
00:29:40,340 --> 00:29:42,260
And in some cases there was a confluence.

416
00:29:42,540 --> 00:29:47,340
So the other interesting place where a fundamental tool that was developed that's

417
00:29:47,340 --> 00:29:52,940
again used very much in adaptive control is what we call as the Kalman-Yakubovich

418
00:29:52,940 --> 00:29:57,020
lemma. And so right there in the name, you can see this sort of parallel development

419
00:29:57,020 --> 00:30:02,340
because separately Kalman and Yakubovich independently came up with this, which is, I

420
00:30:02,340 --> 00:30:09,020
think, one of the really beautiful results because it connects what happens in

421
00:30:09,620 --> 00:30:14,500
analysis in time domain with what happens in frequency domain.

422
00:30:14,780 --> 00:30:19,980
And there are not that many results that basically provide this connection between

423
00:30:19,980 --> 00:30:24,060
these two very different representations of dynamic systems.

424
00:30:24,500 --> 00:30:29,940
And so what they showed basically, and it's one of the central pillars of adaptive

425
00:30:29,940 --> 00:30:37,020
control, because it talks about what kind of performance functions can you use and

426
00:30:37,020 --> 00:30:42,620
adjust the parameters so that even when you don't have access to all of the states in

427
00:30:42,620 --> 00:30:47,060
the dynamic systems, even when the system is partially observable, you still are

428
00:30:47,060 --> 00:30:50,580
guaranteed to have the right adaptation laws.

429
00:30:51,380 --> 00:30:56,820
And so it turns out that the connection between the input-output property of the

430
00:30:56,820 --> 00:31:01,420
dynamic system is basically connected with the existence of a Lyapunov function.

431
00:31:01,420 --> 00:31:05,260
So on the one hand, this input-output stability property is the one in frequency

432
00:31:05,260 --> 00:31:11,620
domain. You can think of it as what kinds of characteristics should that obey in the

433
00:31:11,620 --> 00:31:16,700
frequency domain to the kind of operator that you need to have in time domain that

434
00:31:16,980 --> 00:31:20,340
allows a positive definite function to become a Lyapunov function.

435
00:31:20,740 --> 00:31:26,980
And that, too, is something that happened in the 70s and 80s and was a cornerstone in

436
00:31:26,980 --> 00:31:28,460
the development of adaptive control.

437
00:31:29,140 --> 00:31:35,420
And I would say that the paradigms around those times were essentially two in

438
00:31:35,420 --> 00:31:40,820
adaptive control, model-reference adaptive control, possibly, and self-tuning control.

439
00:31:40,820 --> 00:31:43,940
Can you tell us a bit about the difference of these two paradigms?

440
00:31:43,940 --> 00:31:51,100
Of course, yeah. So you can approach the whole problem by saying, OK, my focus is

441
00:31:51,100 --> 00:31:53,820
really that I want to control the system.

442
00:31:54,460 --> 00:32:00,300
And so at the end of the day, I really don't need to know how a system behaves.

443
00:32:00,380 --> 00:32:05,620
I just need to figure out what I need to do in order to get the performance I want.

444
00:32:06,020 --> 00:32:10,300
So model-reference adaptive control pursued that kind of what we would call as a

445
00:32:10,300 --> 00:32:12,340
direct adaptive control strategy.

446
00:32:12,940 --> 00:32:18,140
Now, on the other hand, if you say, OK, here is a dynamic system, I know how to

447
00:32:18,140 --> 00:32:22,660
control it. But then for whatever reason, something changed in the environment.

448
00:32:22,660 --> 00:32:24,860
And so my parameters have changed.

449
00:32:25,060 --> 00:32:26,260
So now what do I do?

450
00:32:27,140 --> 00:32:32,100
You can look at it completely from the point of view of estimation.

451
00:32:32,540 --> 00:32:37,780
So let's first identify the parameters and then design the controller.

452
00:32:38,340 --> 00:32:44,180
And so this is an explicit estimation, but you can call it as an indirect adaptive

453
00:32:44,180 --> 00:32:48,900
control because first you identify the parameters, then you identify the

454
00:32:48,900 --> 00:32:55,860
controllers. So if you take the notion of separation principle, which is very

455
00:32:55,860 --> 00:33:01,780
elegant and it says, you know what, you don't necessarily need to have observer

456
00:33:01,780 --> 00:33:06,140
design and controller design to, you know, we don't have to worry about the fact

457
00:33:06,140 --> 00:33:08,940
that they are two different steps.

458
00:33:09,260 --> 00:33:12,860
You can actually separate it and have both of them function in parallel and

459
00:33:12,860 --> 00:33:14,220
everything would work out fine.

460
00:33:14,220 --> 00:33:19,140
So the idea was then that, hey, I have this cost function and this cost function

461
00:33:19,140 --> 00:33:22,700
is a regular linear quadratic, you know, it's a quadratic cost.

462
00:33:23,060 --> 00:33:25,540
And so I will optimize this cost.

463
00:33:25,580 --> 00:33:29,900
I will try to come up with a regulator that basically self-tunes itself and

464
00:33:29,980 --> 00:33:31,300
optimizes this cost.

465
00:33:31,700 --> 00:33:36,420
So and I do that by saying, OK, I can estimate the parameters and then basically

466
00:33:36,420 --> 00:33:41,460
use the estimates in the cost function and have that be minimized.

467
00:33:41,660 --> 00:33:46,420
So that was the philosophy taken in the self-tuning regulators.

468
00:33:46,780 --> 00:33:49,420
So and those were the two parallel streams.

469
00:33:49,420 --> 00:33:54,500
And it turned out that if you're going to ensure that even as you're estimating

470
00:33:54,580 --> 00:34:00,340
the cost function is something that remains well behaved, you had to impose

471
00:34:00,340 --> 00:34:03,060
a certain structure to the problem.

472
00:34:03,140 --> 00:34:07,820
And it turned out that some of the assumptions that were made were basically

473
00:34:07,820 --> 00:34:12,020
exactly the same things that you needed to do in order to have the model

474
00:34:12,020 --> 00:34:13,900
reference adaptive controller at B's table.

475
00:34:13,900 --> 00:34:17,540
And so there were a lot of papers written again, I think, towards the end of

476
00:34:17,540 --> 00:34:24,140
the 80s that talked about a unified theory and the similarities between STR

477
00:34:24,140 --> 00:34:25,620
and MRAC and so on.

478
00:34:25,940 --> 00:34:30,220
But you see, it again goes back to the same thing that we talked about earlier

479
00:34:30,220 --> 00:34:33,140
in our conversation, which is this dual control.

480
00:34:34,460 --> 00:34:38,900
Since estimation and control are duals of each other, you really need to have

481
00:34:39,180 --> 00:34:45,100
the right structures for the controller so that even without full estimation,

482
00:34:45,100 --> 00:34:46,500
you can make the controller work.

483
00:34:46,500 --> 00:34:51,100
And at the same time, you also allow those structures to lead to learning of

484
00:34:51,100 --> 00:34:55,500
the parameters, to estimation of the parameters, so that eventually when this

485
00:34:55,500 --> 00:34:59,900
all really is done, after control is completed, after regulation is completed,

486
00:35:00,260 --> 00:35:05,620
you can use what is known as persistent excitation properties of excitation of

487
00:35:05,620 --> 00:35:07,980
the external signals and learn the parameters.

488
00:35:08,180 --> 00:35:11,260
So that was the story behind STR and MRAC.

489
00:35:12,580 --> 00:35:16,420
Thanks for this super nice overview of the two approaches.

490
00:35:16,740 --> 00:35:21,420
Actually, this gives me a nice access to move from the 80s towards the 90s.

491
00:35:21,460 --> 00:35:26,860
This is also the time where I believe you had your PhD as well and where you landed

492
00:35:26,860 --> 00:35:32,180
a super nice paper, essentially, that awarded you the George Axelby Prize, one

493
00:35:32,180 --> 00:35:34,740
of the most important prizes in control theory.

494
00:35:35,500 --> 00:35:39,020
The title of the paper is Robust Adaptive Control in the Presence of Bounded

495
00:35:39,020 --> 00:35:43,300
Disturbances. And I just wanted to talk about this because you mentioned the notion

496
00:35:43,300 --> 00:35:44,700
of persistence of excitation.

497
00:35:44,700 --> 00:35:49,060
And in that paper, you actually show that that plays a fundamental role in adaptive

498
00:35:49,060 --> 00:35:49,820
control, right?

499
00:35:50,140 --> 00:35:50,540
Yes.

500
00:35:50,980 --> 00:35:53,460
So what is the message of the paper?

501
00:35:53,820 --> 00:36:00,020
Right. So we talked about what adaptation is, right?

502
00:36:00,180 --> 00:36:04,420
Advantageous confirmation of an organism now in response to changes in the

503
00:36:04,420 --> 00:36:07,140
environment. So that's very important.

504
00:36:07,340 --> 00:36:11,420
So what is it that you say is your performance function?

505
00:36:11,860 --> 00:36:16,660
So adaptation and even the manifestation of that in an adaptive control system is a

506
00:36:16,660 --> 00:36:17,740
very simple thing.

507
00:36:17,740 --> 00:36:22,300
It's a very — think of it as a very simple-minded entity, because what it's doing

508
00:36:22,300 --> 00:36:26,900
is, hey, here is the performance, here's the loss function, and here is the

509
00:36:26,900 --> 00:36:30,100
parameter. Adjust the parameter in the direction of the gradient.

510
00:36:30,140 --> 00:36:31,780
That minimizes that loss function.

511
00:36:32,580 --> 00:36:38,460
So if you use this framework, then it turns out that you can do very well in

512
00:36:38,460 --> 00:36:42,860
controlling the system and ultimately even estimating the system with persistent

513
00:36:42,860 --> 00:36:50,580
excitation, provided there is a certain kind of a structure in the environment.

514
00:36:51,140 --> 00:36:55,740
Now, if this environment is pristine and is well-behaved and ideal and the only

515
00:36:55,740 --> 00:36:59,220
uncertainty is parametric in nature, then what we are talking about would be

516
00:36:59,220 --> 00:37:04,420
correct. But you are only observing a performance quantity, right?

517
00:37:04,460 --> 00:37:05,380
A loss function.

518
00:37:05,660 --> 00:37:10,380
What if, unbeknownst to you, there were other forces at work, other non-parametric

519
00:37:10,460 --> 00:37:14,100
effects that basically was affecting the performance, and you didn't know that?

520
00:37:14,500 --> 00:37:21,020
So if that happens, then essentially you are trying to adjust the parameters in a

521
00:37:21,020 --> 00:37:26,500
direction that might make that performance well-behaved, but you might end up

522
00:37:26,900 --> 00:37:28,340
destroying something else.

523
00:37:28,500 --> 00:37:33,300
And that basically was what people were observing could happen in adaptive control

524
00:37:33,300 --> 00:37:36,620
systems. You can explain that in many different ways.

525
00:37:36,620 --> 00:37:40,460
I mentioned convexity and making it regularized and making it strongly convex.

526
00:37:40,460 --> 00:37:41,540
That's one way of looking at it.

527
00:37:41,540 --> 00:37:44,260
And the other way of looking at it is here is a convex function.

528
00:37:44,700 --> 00:37:50,300
Then instead of doing regularization, because it introduces other artifacts into

529
00:37:50,300 --> 00:37:54,620
the picture, what if I make it strongly convex by using the notion of persistent

530
00:37:54,620 --> 00:37:58,900
excitation? So that turns out is another way of really looking at the problem.

531
00:37:58,980 --> 00:38:04,020
So then it turns out that even when there are disturbances, this performance

532
00:38:04,020 --> 00:38:07,980
function that you're observing, this loss function that you're observing, can be

533
00:38:07,980 --> 00:38:10,500
utilized in order to keep things in check.

534
00:38:11,220 --> 00:38:16,540
The paper that, if you go back and read that paper written in 86, it really doesn't

535
00:38:16,540 --> 00:38:19,620
have any of the language that I'm using right now, but that's just another way of

536
00:38:19,620 --> 00:38:25,820
looking at it as to how the relation between persistent excitation and robustness

537
00:38:25,820 --> 00:38:28,380
manifests itself. You can think of it in another way.

538
00:38:28,820 --> 00:38:34,340
Nonlinear systems or differential equations are extraordinarily rich compared to

539
00:38:34,340 --> 00:38:35,620
linear differential equations.

540
00:38:35,820 --> 00:38:42,020
The notions that we have of what happens for the unforced system and what happens

541
00:38:42,020 --> 00:38:46,420
in the presence of external forcing inputs is very different between a linear

542
00:38:46,420 --> 00:38:47,820
system and a nonlinear system.

543
00:38:47,820 --> 00:38:50,540
And that basically is what is mentioned in the paper.

544
00:38:50,980 --> 00:38:56,300
If you take a system that is, so there is no external input and you've got a nice

545
00:38:56,460 --> 00:38:58,980
system that's uniformly asymptotically stable, right?

546
00:38:58,980 --> 00:39:02,500
The origin is uniformly asymptotically stable, meaning you shake it, everything

547
00:39:02,500 --> 00:39:03,620
will go back to the origin.

548
00:39:04,060 --> 00:39:07,700
Now you introduce exogenous inputs into the picture.

549
00:39:07,900 --> 00:39:11,540
We know from linear systems that if you have a situation like that, bounded input

550
00:39:11,540 --> 00:39:12,860
will produce a bounded output.

551
00:39:13,580 --> 00:39:15,340
Not so for nonlinear systems.

552
00:39:15,420 --> 00:39:21,060
There is a very nice paper by Varaya, De Sovere and Varaya, I think.

553
00:39:21,460 --> 00:39:23,260
Actually, I have to go back and check the authors.

554
00:39:23,420 --> 00:39:26,540
Certainly it's by De Sovere, maybe the co-author is not Varaya, but someone else

555
00:39:27,220 --> 00:39:31,780
who basically showed this very nice counter example where you have a uniformly

556
00:39:31,780 --> 00:39:34,180
asymptotically stable system.

557
00:39:34,540 --> 00:39:38,420
You put in a bounded input, not only does the output does not remain bounded, it

558
00:39:38,420 --> 00:39:39,180
actually blows up.

559
00:39:39,660 --> 00:39:44,980
So we were able to come up with a counter example very similar to that in the

560
00:39:44,980 --> 00:39:49,340
context of an adaptive control system, which basically showed that if you just

561
00:39:49,340 --> 00:39:53,300
had the simple gradient rule type of thing, and then you introduce a

562
00:39:53,300 --> 00:39:57,540
disturbance, you can actually prove, you can actually come up with a positive

563
00:39:57,540 --> 00:40:01,500
definite function and show that there is a bounded, there is a region, not bounded

564
00:40:01,500 --> 00:40:04,380
region, where if you start there, you will stay there forever.

565
00:40:04,380 --> 00:40:05,860
And it's an open invariant region.

566
00:40:05,860 --> 00:40:07,940
And so the trajectory, it actually blows up.

567
00:40:08,340 --> 00:40:12,940
So what it says is that things may not actually, it's not easy to show stability,

568
00:40:12,940 --> 00:40:14,860
but it actually becomes unstable.

569
00:40:15,460 --> 00:40:20,220
Fortunately, there was also a happy ending to that paper, which says that this

570
00:40:20,220 --> 00:40:22,860
might happen if you don't have enough persistent excitation.

571
00:40:23,140 --> 00:40:27,020
So not only do you need persistent excitation, but you need enough of it.

572
00:40:27,220 --> 00:40:29,820
So sort of a signal to noise ratio type of condition.

573
00:40:30,140 --> 00:40:33,660
And if that is satisfied, then you get bounded input, bounded output for

574
00:40:33,860 --> 00:40:38,020
nonlinear systems, which is why that paper, I think, is very special.

575
00:40:38,860 --> 00:40:44,220
Very quick comment about this, this fact that you mentioned on the level, if you

576
00:40:44,220 --> 00:40:48,180
want, of persistence of excitation, because from my very humble perspective, it

577
00:40:48,180 --> 00:40:53,180
seems that these notions are now coming back in vogue in these times, at least at

578
00:40:53,620 --> 00:40:55,380
major conferences in control.

579
00:40:56,020 --> 00:41:01,500
But yeah, as you mentioned, from the 80s to the 90s, we start moving our horizon, if

580
00:41:01,500 --> 00:41:06,140
you want, in adaptive control towards issues of robustness and nonlinear systems,

581
00:41:06,580 --> 00:41:11,980
essentially. So that's the way I read the history, at least of adaptive control.

582
00:41:12,540 --> 00:41:18,260
So I would like maybe to shift towards those years and maybe even with a look

583
00:41:18,260 --> 00:41:20,300
towards our current times.

584
00:41:20,660 --> 00:41:27,380
So what happened, let's say, between the 90s towards the 2000s and 2010s, maybe?

585
00:41:28,420 --> 00:41:32,900
Oh, there's, you know, it's hard to sort of single out any specific sort of

586
00:41:32,900 --> 00:41:37,140
direction. So just like, you know, in general, what happened in the rest of the

587
00:41:37,140 --> 00:41:43,700
control systems branches, adaptive control tools started looking at nonlinear

588
00:41:43,700 --> 00:41:49,380
systems, different kinds of nonlinearities, multivariable systems, distributed

589
00:41:49,380 --> 00:41:54,780
adaptive controllers, looking at what happens when there are time delays and what

590
00:41:54,780 --> 00:41:59,780
happens when you're trying to implement adaptive control in cyber-physical systems

591
00:41:59,820 --> 00:42:06,660
and what's the right way to allocate the computation to different kinds of

592
00:42:07,180 --> 00:42:09,900
components in a real-time embedded system.

593
00:42:10,740 --> 00:42:16,580
And of course, you know, applications, what exactly is the kind of uncertainties

594
00:42:17,340 --> 00:42:20,820
that are typically present in applications?

595
00:42:20,820 --> 00:42:25,860
For instance, in a flight controller, you say, OK, here is a system dynamics, even

596
00:42:25,860 --> 00:42:29,020
though, let's say, XR equals AX plus BU, A and B are unknown.

597
00:42:29,460 --> 00:42:32,540
Let's parse that a little bit more carefully.

598
00:42:32,860 --> 00:42:36,100
What exactly is unknown in a dynamic system?

599
00:42:36,380 --> 00:42:41,180
Because it's not as if you know nothing about A and B and then you start designing

600
00:42:41,180 --> 00:42:43,220
K. There's a lot of information.

601
00:42:43,580 --> 00:42:48,420
And so one of the things that sort of, you know, came into, that people had better

602
00:42:48,420 --> 00:42:53,740
understanding of as time went on, for instance, you know, wind tunnel tests are

603
00:42:53,740 --> 00:42:59,740
things that are very carefully employed before designing a flight control system.

604
00:42:59,980 --> 00:43:03,860
So there's a lot of information in the dynamics.

605
00:43:03,860 --> 00:43:08,460
So based on, you know, aerodynamics, understanding of the equations of motion,

606
00:43:08,460 --> 00:43:15,100
conservation equations, and I'm putting it in a very simplified way, A is not really

607
00:43:15,100 --> 00:43:17,540
unknown. There's a lot of information in A.

608
00:43:17,900 --> 00:43:21,460
Now, on the other hand, B matrix, that's a very different story.

609
00:43:21,780 --> 00:43:25,740
It's not often that you know everything about it because it has to do with the way

610
00:43:25,740 --> 00:43:29,820
in which control surfaces interact with the aerodynamics.

611
00:43:30,100 --> 00:43:34,860
And not only that, control surfaces, you know, have many different components to it.

612
00:43:34,860 --> 00:43:39,020
From the time you actually have the information coming from your controller and

613
00:43:39,020 --> 00:43:44,340
then goes into the appropriate computational structures and then goes into this thing

614
00:43:44,340 --> 00:43:48,460
called the actuator and then the actuator basically provides, say, for instance, the

615
00:43:48,460 --> 00:43:51,780
control moments and forces, there's a lot that goes on.

616
00:43:51,980 --> 00:43:55,580
And in that whole chain of events, there can be a lot of uncertainty.

617
00:43:55,580 --> 00:43:57,780
So sometimes it's not that A is unknown.

618
00:43:57,980 --> 00:44:03,140
There are specific aspects to B, B times U, that basically can have uncertainty.

619
00:44:03,140 --> 00:44:07,700
So then you see, here you have this very generic theory, but then you have to

620
00:44:07,700 --> 00:44:11,100
systematically break it down and figure out how it should be applied.

621
00:44:11,100 --> 00:44:15,460
So many of those developments also happened as the years went by.

622
00:44:15,460 --> 00:44:19,940
So and then how do you actually, you know, scale the whole problem up?

623
00:44:19,940 --> 00:44:23,740
So one of the things that papers that we wrote was on a multivariable control

624
00:44:23,740 --> 00:44:28,860
system, which was for a very flexible aircraft, which had something like, oh, I

625
00:44:28,860 --> 00:44:36,620
don't know, 700 state variables and 33 control inputs and 300 or so outputs.

626
00:44:36,860 --> 00:44:40,580
And so, you know, that's then it had several parameters that we were adjusting

627
00:44:40,580 --> 00:44:43,060
and we showed that in real time you could do all of those things.

628
00:44:43,220 --> 00:44:47,540
So, you know, many of these kinds of developments, I would say, are probably

629
00:44:47,540 --> 00:44:51,460
what occupied the attention and is still occupying the attention of researchers

630
00:44:51,780 --> 00:44:53,260
in the adaptive control community.

631
00:44:54,020 --> 00:44:59,540
And maybe not to, of course, it will not be possible to cover everything in the

632
00:44:59,540 --> 00:45:01,940
span of just one hour or a little more.

633
00:45:03,020 --> 00:45:08,380
So we'll definitely do some injustice to some researchers in adaptive control.

634
00:45:08,780 --> 00:45:13,340
But something that I really want to touch on is the connection between adaptive

635
00:45:13,340 --> 00:45:18,460
control and essentially reinforcement learning or modern machine learning.

636
00:45:18,940 --> 00:45:23,740
I found in reading this beautiful history paper that you wrote together with

637
00:45:23,740 --> 00:45:29,100
Professor Fraktov, that there was an article by Richard Sutton, Andrew Bartow

638
00:45:29,100 --> 00:45:31,660
and Ronald Williams on the Control Systems Magazine.

639
00:45:32,020 --> 00:45:36,300
So literally speaking to a control audience where the title is literally

640
00:45:36,820 --> 00:45:39,980
reinforcement learning is direct adaptive optimal control.

641
00:45:40,580 --> 00:45:45,900
So I found it incredibly funny because they're now regarded as pioneers in the

642
00:45:45,900 --> 00:45:47,220
field of reinforcement learning.

643
00:45:47,260 --> 00:45:52,860
And they were telling us that what they're doing is direct adaptive optimal control.

644
00:45:53,820 --> 00:45:54,020
Yeah.

645
00:45:54,020 --> 00:45:59,660
So essentially in 2016, we all know that AlphaGo made a splash by beating Lee Sedol,

646
00:45:59,660 --> 00:46:01,460
the champion on the game of Go.

647
00:46:01,900 --> 00:46:05,660
And therefore there was a huge resurgence in interest, if you want, on

648
00:46:05,780 --> 00:46:06,660
reinforcement learning.

649
00:46:07,380 --> 00:46:08,860
What is the interplay now?

650
00:46:09,740 --> 00:46:10,780
What is the status?

651
00:46:11,660 --> 00:46:12,060
Right.

652
00:46:12,140 --> 00:46:19,740
Oh, that's a very hard question to answer in the time that we have.

653
00:46:20,300 --> 00:46:27,100
Again, just like the one I would certainly like to defer the listener to the recent

654
00:46:27,100 --> 00:46:33,100
article that I mentioned that will appear in the annual reviews, Controls, Robotics

655
00:46:33,100 --> 00:46:34,980
and Automation for details.

656
00:46:35,380 --> 00:46:40,500
But, you know, the two fields, reinforcement learning and adaptive control, have

657
00:46:40,660 --> 00:46:47,060
evolved differently with different tools and more importantly, different objectives.

658
00:46:47,780 --> 00:46:54,260
And the problems formulation statement in the two fields, they also vary.

659
00:46:54,380 --> 00:46:56,300
So what is adaptive control saying?

660
00:46:56,300 --> 00:47:00,420
Adaptive control is saying that I have a dynamic system.

661
00:47:00,580 --> 00:47:03,740
And right now, right now, there is an uncertainty.

662
00:47:03,780 --> 00:47:07,540
Or, you know, imagine again, let's consider a flight platform, right?

663
00:47:07,900 --> 00:47:09,020
A quadrotor.

664
00:47:09,380 --> 00:47:10,140
It's a drone.

665
00:47:10,340 --> 00:47:12,300
It's flying and it's in mid-flight.

666
00:47:12,940 --> 00:47:14,300
And then something goes wrong.

667
00:47:14,420 --> 00:47:15,500
It's in mid-flight.

668
00:47:15,580 --> 00:47:18,140
And then right now, in real time, something goes wrong.

669
00:47:18,900 --> 00:47:26,700
You don't have time to do experiments and do a lot of simulations.

670
00:47:27,100 --> 00:47:30,660
And, oh, what if I were to use this policy, then what would it do?

671
00:47:30,780 --> 00:47:32,220
You just don't have the time.

672
00:47:33,100 --> 00:47:39,460
And so you directly have to adapt and you have to figure out on the fly, what kind

673
00:47:39,460 --> 00:47:43,740
of thrust do I give to those motors in order to have it still do its thing,

674
00:47:43,740 --> 00:47:46,820
whatever it might be, hover, follow a particular flight path.

675
00:47:47,340 --> 00:47:52,060
So the emphasis is on coming up with a solution in real time.

676
00:47:52,540 --> 00:47:57,740
So because of that, adaptive control is geared towards what

677
00:47:57,740 --> 00:48:00,060
happened and what is happening.

678
00:48:00,060 --> 00:48:02,700
So it looks at the past and the present.

679
00:48:03,540 --> 00:48:08,700
Now, when you go into reinforcement learning, the trajectory there evolved

680
00:48:08,700 --> 00:48:10,900
from a point of view of optimality.

681
00:48:11,300 --> 00:48:16,460
So even let's take that, the game, the chess or a goal, you have to figure out

682
00:48:16,460 --> 00:48:22,420
what your policy is that needs to happen now and in the future.

683
00:48:22,460 --> 00:48:28,340
So you're looking at the present and the future, and you're trying to be optimal

684
00:48:28,380 --> 00:48:30,740
in terms of what the policy is that you're going to take so that

685
00:48:30,740 --> 00:48:31,940
you can beat your opponent.

686
00:48:32,420 --> 00:48:37,020
Now, you can see that distinctly, they have two different points of view.

687
00:48:38,060 --> 00:48:41,420
Past and present is really what you're looking at in adaptive control, simply

688
00:48:41,420 --> 00:48:43,100
because of the problem statement.

689
00:48:43,140 --> 00:48:47,300
And again, present and future is what you're looking at simply

690
00:48:47,300 --> 00:48:48,940
because of the problem statement.

691
00:48:49,220 --> 00:48:53,660
So necessarily they deployed different disparate tools in

692
00:48:53,660 --> 00:48:55,420
order to realize their objective.

693
00:48:56,100 --> 00:49:00,180
However, both of them have a common feature, which is that both of them are

694
00:49:00,180 --> 00:49:04,780
trying to deal with problems that have uncertainties in them.

695
00:49:05,060 --> 00:49:09,260
But it's just that when you go in and start unpacking it and go into the

696
00:49:09,260 --> 00:49:13,380
details, the statements that are being made and the tools that need to be

697
00:49:13,380 --> 00:49:15,380
employed start becoming different.

698
00:49:15,940 --> 00:49:23,180
And so this is why when you start to apply RL to problems in dynamic systems,

699
00:49:23,180 --> 00:49:28,820
which have uncertainties, I think one needs to be careful in figuring out what

700
00:49:28,820 --> 00:49:34,460
exactly are the different kinds of things that are under your disposal.

701
00:49:35,340 --> 00:49:41,780
If indeed you have time to make the decisions of exploration, then you have

702
00:49:41,780 --> 00:49:45,700
time before you start figuring out when you start your exploitation.

703
00:49:46,180 --> 00:49:48,380
Exploration here is parameter learning.

704
00:49:48,380 --> 00:49:50,180
Exploitation here is control.

705
00:49:50,180 --> 00:49:53,300
I mean, though, if you go into the details, I'm sure there are different

706
00:49:53,300 --> 00:49:56,580
shades and nuances, but for the sake of discussion, suppose you do that.

707
00:49:56,580 --> 00:50:00,340
Then if you're in real time, you don't have time to explore.

708
00:50:00,820 --> 00:50:03,540
You really have to control first before you can learn.

709
00:50:03,540 --> 00:50:05,740
So then control comes before learning.

710
00:50:06,300 --> 00:50:10,420
So those are the kinds of things where adaptive control and reinforcement

711
00:50:10,420 --> 00:50:14,900
learning differ and have different kinds of strengths and weaknesses.

712
00:50:15,460 --> 00:50:20,940
There's no question that there is a lot of tools that we can do in machine

713
00:50:20,940 --> 00:50:25,300
learning that help us deal with unstructured environments, large data

714
00:50:25,300 --> 00:50:27,540
sets, huge number of agents.

715
00:50:27,740 --> 00:50:33,460
So many of those lessons and successes that have been illustrated in algorithms,

716
00:50:33,940 --> 00:50:38,620
we should start to figure out how we can combine that with tools that

717
00:50:38,620 --> 00:50:39,820
are used in adaptive control.

718
00:50:39,820 --> 00:50:44,780
From the same point of view, adaptive control basically has lots of dos and

719
00:50:44,780 --> 00:50:48,500
don'ts for very good reasons, like, you know, this whole concept that we keep

720
00:50:48,500 --> 00:50:51,340
talking about of duality between estimation and control.

721
00:50:51,580 --> 00:50:53,820
Sometimes you have to put control before learning.

722
00:50:53,820 --> 00:50:57,380
You do control first and then you learn with hindsight.

723
00:50:58,020 --> 00:51:03,700
So you have to make sure that even when you have, there's sometimes you don't

724
00:51:03,700 --> 00:51:06,900
have enough information to have perfect learning.

725
00:51:06,900 --> 00:51:10,420
So in that case, you cannot do the indirect control.

726
00:51:10,420 --> 00:51:13,100
You cannot fully learn the parameters before you do control.

727
00:51:13,340 --> 00:51:18,220
And there's another thing about, you know, the title direct, adaptive, optimal

728
00:51:18,220 --> 00:51:21,180
control, that's very difficult to do.

729
00:51:21,300 --> 00:51:25,180
Again, because of what I said, which is what is difficult to do, adaptive

730
00:51:25,300 --> 00:51:27,540
and optimal at the same time.

731
00:51:27,940 --> 00:51:30,340
The reason is exactly because of what I said earlier.

732
00:51:30,780 --> 00:51:35,220
You, you are now looking at the past and the present, and you need to fix that

733
00:51:35,220 --> 00:51:37,620
first before you can start looking into the future.

734
00:51:38,020 --> 00:51:41,260
So I firmly believe, and that's one of the things that I think is mentioned in

735
00:51:41,260 --> 00:51:47,700
the paper, that is this sort of adapt, learn, optimize triad that I think we

736
00:51:47,700 --> 00:51:48,580
need to think about.

737
00:51:48,620 --> 00:51:52,020
So first you adapt, then you learn with hindsight.

738
00:51:52,060 --> 00:51:54,820
And then now that you've learned, you go ahead and optimize.

739
00:51:55,180 --> 00:51:58,500
And that kind of a sequence sometimes is inevitable.

740
00:51:59,260 --> 00:52:00,540
That's fantastic point of view.

741
00:52:00,540 --> 00:52:01,180
Fantastic.

742
00:52:01,780 --> 00:52:06,860
Um, essentially in the last few moments, you also addressed one of the questions

743
00:52:06,860 --> 00:52:11,540
that I wanted to ask you, which was what can the two fields teach to one another?

744
00:52:11,540 --> 00:52:12,580
So I'll ask you another one.

745
00:52:13,060 --> 00:52:16,820
And that's, what are you most excited about for the years to come?

746
00:52:17,020 --> 00:52:22,180
Uh, how do you envision say emerging worlds like those of machine learning

747
00:52:22,180 --> 00:52:28,100
where now we're really heading towards, uh, from translating speech into actions

748
00:52:28,100 --> 00:52:32,940
or speech into images and the world of, uh, adaptive control.

749
00:52:33,340 --> 00:52:34,380
Uh, what, what do you see?

750
00:52:34,580 --> 00:52:36,860
Oh, I think we've just scratched the surface.

751
00:52:36,860 --> 00:52:38,540
There's just so much to do.

752
00:52:38,860 --> 00:52:43,060
And I hope that the younger, younger generation will continue to do that

753
00:52:43,380 --> 00:52:47,860
because I, I don't know how much more time I'll, I'll have myself to continue

754
00:52:47,860 --> 00:52:49,620
to, you know, chip away at this.

755
00:52:50,020 --> 00:52:56,340
I mean, computationally the world has changed so much, even, you know, over

756
00:52:56,340 --> 00:53:01,980
the last, uh, 20 years, what we used to think of as, uh, methods that are, oh

757
00:53:01,980 --> 00:53:06,900
my God, that's going to be impossible to do are now not just possible.

758
00:53:06,980 --> 00:53:07,980
It's a cakewalk.

759
00:53:08,460 --> 00:53:15,100
So that kind of a, sort of a breakdown of the, the, the blinders that we used to put

760
00:53:15,100 --> 00:53:17,260
for ourselves, Oh, this is computationally.

761
00:53:17,340 --> 00:53:17,740
Okay.

762
00:53:17,740 --> 00:53:18,860
But this one, Oh, come on.

763
00:53:18,860 --> 00:53:23,140
That's never going to be possible is not, is that boundary is changing so much.

764
00:53:23,460 --> 00:53:27,700
I mean, still, I think there are some challenges in terms of, I mean, like for

765
00:53:27,700 --> 00:53:31,900
instance, why is adaptive MPC not here yet?

766
00:53:32,060 --> 00:53:36,820
Because even that as competent, uh, even with the computational resources, still,

767
00:53:37,180 --> 00:53:41,100
I don't think we are there to figure out how you can do the adaptation

768
00:53:41,260 --> 00:53:43,420
and optimization at the same time.

769
00:53:43,620 --> 00:53:48,220
So trying to figure out how you can leverage the kind of computational

770
00:53:48,220 --> 00:53:53,340
resources that you have in figuring out what needs to happen offline.

771
00:53:53,660 --> 00:53:56,860
And what needs to happen online is I think the challenge.

772
00:53:57,260 --> 00:54:00,420
How do you make sure that you address the sim to real gap?

773
00:54:00,860 --> 00:54:05,340
How do you make sure that you leverage all of the things that you learned

774
00:54:05,420 --> 00:54:10,580
offline and keep that, uh, transport them into an online construct?

775
00:54:10,980 --> 00:54:15,700
This interplay is, I think, becoming very complex.

776
00:54:15,780 --> 00:54:21,580
And that is, I think the boundary that we have to navigate and, uh, figure

777
00:54:21,580 --> 00:54:23,900
it out and tease apart as we go forward.

778
00:54:23,940 --> 00:54:25,620
I think there's so much to do there.

779
00:54:25,900 --> 00:54:30,060
And again, one of the biggest things that has to happen is more dialogue

780
00:54:30,060 --> 00:54:32,940
and more conversations and more collaborations between the two

781
00:54:32,940 --> 00:54:34,580
communities, which is beginning to happen.

782
00:54:35,060 --> 00:54:38,980
So not necessarily just more computation, but also more theory, more dialogue.

783
00:54:40,900 --> 00:54:41,260
Okay.

784
00:54:41,300 --> 00:54:45,580
Um, maybe, you know, moving towards the end of our conversation

785
00:54:45,580 --> 00:54:49,700
there's a couple of questions that I tend to ask to everyone that features

786
00:54:49,700 --> 00:54:53,660
on the show, one of them is about advice to future generations.

787
00:54:53,780 --> 00:54:58,420
So if there is anything that you would have liked to know before starting

788
00:54:58,420 --> 00:55:02,380
your career, was there anything that you would advise, say to current

789
00:55:02,380 --> 00:55:04,060
students or even future students?

790
00:55:04,500 --> 00:55:09,580
Um, I think you need to figure out how you can be extremely good at one

791
00:55:09,580 --> 00:55:11,780
thing and very good at many things.

792
00:55:12,300 --> 00:55:13,540
It's not easy to do.

793
00:55:14,060 --> 00:55:18,340
You have to have a mainstay that where, you know, and that's what, if you think

794
00:55:18,340 --> 00:55:21,780
about, if you're a doctoral student, that's exactly what a PhD is, right?

795
00:55:21,780 --> 00:55:24,780
That you are going to be the expert.

796
00:55:25,340 --> 00:55:30,180
Um, or I mean, not just one of the experts in that particular area and

797
00:55:30,180 --> 00:55:32,580
you're intimately familiar with that, right?

798
00:55:32,580 --> 00:55:33,580
That's what I mean by that.

799
00:55:33,580 --> 00:55:40,340
But I think the, the specialty is becoming, it needs to happen

800
00:55:40,420 --> 00:55:43,060
even along with many other things.

801
00:55:43,340 --> 00:55:48,700
And so the breakdown between what you're doing in your area and it's, it's

802
00:55:48,700 --> 00:55:54,140
interrelation with the other domains is becoming a lot more complex.

803
00:55:54,140 --> 00:55:58,820
And so compared to, I think what it used to be maybe 20, 30 years ago,

804
00:55:59,300 --> 00:56:04,380
the, the awareness and the understanding of how to converse with other

805
00:56:04,740 --> 00:56:10,780
transdisciplinary partners becoming more and more important, um, you know,

806
00:56:10,900 --> 00:56:12,980
controls is changing a lot.

807
00:56:13,100 --> 00:56:18,500
It's no longer a feedback control of a single device or a single system.

808
00:56:18,780 --> 00:56:22,700
It's no longer control of a large scale system is no longer control of

809
00:56:22,700 --> 00:56:24,420
a large scale engineer systems.

810
00:56:24,420 --> 00:56:30,780
It's really things that control is present and needed in a societal scale.

811
00:56:31,140 --> 00:56:35,340
So, which means that you really start to, you need to start thinking about

812
00:56:35,780 --> 00:56:39,940
what does it mean, this concept and this very broad canvas.

813
00:56:40,020 --> 00:56:44,980
How do you apply that in the context of say, for instance, energy justice,

814
00:56:44,980 --> 00:56:49,580
which is a totally different domain, but still there is a notion of here

815
00:56:49,580 --> 00:56:53,620
is a system, here's a performance, here's ways you monitor it and develop

816
00:56:53,620 --> 00:56:56,500
metrics, and here's how you mitigate something, right?

817
00:56:56,780 --> 00:57:01,780
So in order to do all of those things, it seems to me that in addition to being

818
00:57:01,780 --> 00:57:06,340
very good, excellent at one thing, you really need to do at least one thing

819
00:57:06,380 --> 00:57:09,660
where you're completely out of your comfort zone.

820
00:57:10,460 --> 00:57:15,060
And, you know, I think you should do that activity where you're so scared.

821
00:57:15,100 --> 00:57:18,820
Like you, I know nothing about it, but I think it's very important to immerse

822
00:57:18,900 --> 00:57:21,820
ourselves in that endeavor and you learn that thing.

823
00:57:22,180 --> 00:57:27,140
And so that I think gives you the ability to, to really understand

824
00:57:27,140 --> 00:57:30,700
controls and in its essence and in a very broad way.

825
00:57:30,900 --> 00:57:33,580
I mean, for instance, I know you didn't quite ask this question,

826
00:57:33,580 --> 00:57:35,220
but let me answer that anyway.

827
00:57:35,700 --> 00:57:39,220
In our lab, there are sort of two thrusts in my, you know, the active

828
00:57:39,220 --> 00:57:40,700
adaptive control lab at MIT.

829
00:57:40,740 --> 00:57:45,620
One is to do develop control in a very deep sense and look at adaptive

830
00:57:45,620 --> 00:57:48,220
control, you know, and its intersections with machine learning.

831
00:57:48,540 --> 00:57:53,140
The other thrust is in trying to implement control in a very broad

832
00:57:53,140 --> 00:57:58,420
sense and to look at ways in which the whole notion of how you collect

833
00:57:58,420 --> 00:58:03,100
information and implement decisions in a large scale system, say, for instance,

834
00:58:03,100 --> 00:58:08,820
in power grids or in transportation or in other sort of endeavors that you

835
00:58:08,820 --> 00:58:12,180
wouldn't normally think of in terms of what a control is, you know, in a

836
00:58:12,180 --> 00:58:14,580
non-engineered sense in a societal scale system.

837
00:58:14,860 --> 00:58:19,700
So I think having this kind of two pronged attack, I think is very useful.

838
00:58:20,420 --> 00:58:21,700
That's fantastic.

839
00:58:21,700 --> 00:58:26,620
Actually, apologies for not touching on the huge endeavor also that you're

840
00:58:26,620 --> 00:58:28,700
having in the field of smart grids.

841
00:58:28,740 --> 00:58:31,340
That's another major line of research of yours.

842
00:58:31,340 --> 00:58:35,300
And actually I'll put a link to a couple of papers in the description, just for

843
00:58:35,300 --> 00:58:38,380
people who are interested in this topic and in ANUS research.

844
00:58:39,620 --> 00:58:44,900
Just to finish on the topic of future generations, I'm curious whether do you

845
00:58:44,900 --> 00:58:49,780
have some kind of secret sauce for when you feel stuck or, I mean, it's something

846
00:58:49,780 --> 00:58:54,060
that happens a lot for PhD students and in general to any researcher, I would say.

847
00:58:54,500 --> 00:58:57,700
So what is your approach to that feeling?

848
00:58:58,180 --> 00:59:05,620
Yeah, no, I mean, research is all about figuring out how to even realize that

849
00:59:05,620 --> 00:59:09,100
you're stuck and, you know, to get unstuck.

850
00:59:10,460 --> 00:59:16,260
One of the things I learned from my advisor, Professor Narendra, is how to have

851
00:59:16,260 --> 00:59:23,860
the intellectual courage to completely scrap what you're doing and start from

852
00:59:23,860 --> 00:59:24,740
with a clean slate.

853
00:59:25,140 --> 00:59:28,340
Don't try to tweak things and say, OK, all right, maybe you should.

854
00:59:28,340 --> 00:59:28,900
No, no, no, no.

855
00:59:29,060 --> 00:59:33,980
Just pull back and have the courage to just completely chuck everything that you

856
00:59:33,980 --> 00:59:38,300
might have been doing either for the past week or a past month or even a past

857
00:59:38,300 --> 00:59:41,260
year and say, start from scratch.

858
00:59:41,620 --> 00:59:43,340
OK, what is it that you're trying to do?

859
00:59:43,660 --> 00:59:50,620
So starting with a fresh slate, blank slate, clean slate, and really regroup.

860
00:59:50,620 --> 00:59:52,980
And OK, what is that problem?

861
00:59:52,980 --> 00:59:57,900
And to zoom out and ask questions at a very high level and again start zooming

862
00:59:57,900 --> 01:00:00,180
in helps enormously.

863
01:00:00,660 --> 01:00:05,500
But for to do that, you should have the courage to chuck what you're doing because

864
01:00:05,500 --> 01:00:08,660
it's like, oh, my God, I've put so much effort into it and I have all this

865
01:00:08,660 --> 01:00:09,700
information and knowledge.

866
01:00:09,700 --> 01:00:10,340
Yes, you do.

867
01:00:10,620 --> 01:00:12,660
But believe me, it will help you.

868
01:00:12,980 --> 01:00:16,620
But don't be straightjacketed with what you're facing right now.

869
01:00:16,780 --> 01:00:22,140
I found and that's something I learned from Professor Narendra and that has served

870
01:00:22,140 --> 01:00:24,140
me again and again extremely well.

871
01:00:24,580 --> 01:00:28,940
Well, you're serving me a fantastic assist for another question that I ask to

872
01:00:28,940 --> 01:00:31,420
everyone else that features on your show.

873
01:00:31,420 --> 01:00:35,420
And that's who were the most influential figures in your careers?

874
01:00:35,420 --> 01:00:37,940
If you had to name three, who would they be?

875
01:00:38,700 --> 01:00:42,460
Definitely, I would start with Professor Narendra.

876
01:00:42,700 --> 01:00:49,140
I have learned so much from him how to be a researcher, how to figure out how to

877
01:00:49,140 --> 01:00:53,100
pick problems and how never to really give up.

878
01:00:53,100 --> 01:00:59,820
And that enthusiasm and that optimism is something that I learned from him.

879
01:01:00,220 --> 01:01:04,060
Other than that, I don't know if there is, I would say it's directly because of

880
01:01:04,060 --> 01:01:06,740
interaction with any specific individual.

881
01:01:06,740 --> 01:01:12,180
But, you know, all of Kalman's work have been, you know, enormously

882
01:01:12,180 --> 01:01:15,420
inspirational and sort of mind boggling.

883
01:01:15,420 --> 01:01:16,300
Where did this come?

884
01:01:16,300 --> 01:01:18,980
I mean, like I was talking about Kalman Yakovlevich's lemma, right?

885
01:01:18,980 --> 01:01:20,180
Where did that come from?

886
01:01:20,180 --> 01:01:24,220
How did they even think to sort of connect some very two disparate things

887
01:01:24,220 --> 01:01:28,100
from input-output property to a Lyapunov function?

888
01:01:28,100 --> 01:01:30,300
I have learned a lot from that.

889
01:01:30,300 --> 01:01:36,540
And the other, again, works of that, and I began to know about Pravin Varaya

890
01:01:36,540 --> 01:01:39,780
only and started interacting with them much, much later.

891
01:01:40,140 --> 01:01:46,100
But again, his papers, too, I found have been enormously educational and

892
01:01:46,100 --> 01:01:51,700
inspirational in terms of how you can, and there is something that is

893
01:01:51,700 --> 01:01:56,060
attributed to him in terms of what they call is a folk theorem about

894
01:01:56,060 --> 01:01:57,860
optimization in power grids.

895
01:01:58,140 --> 01:02:03,540
And I find that to be a seminal work that sort of brings in elements of

896
01:02:03,540 --> 01:02:09,300
analysis into something that really was groundbreaking in the context of

897
01:02:09,300 --> 01:02:11,660
constraint optimization in power grids.

898
01:02:11,940 --> 01:02:14,900
So I would mention, I guess, those three individuals.

899
01:02:14,900 --> 01:02:15,180
Yeah.

900
01:02:16,220 --> 01:02:17,100
Thanks for this.

901
01:02:17,140 --> 01:02:21,260
In closing, maybe the last question I want to ask you is out of curiosity,

902
01:02:21,260 --> 01:02:22,620
on a more personal level.

903
01:02:22,940 --> 01:02:28,900
Do you have any like favorite pastime or, and I don't know, do you like reading?

904
01:02:28,900 --> 01:02:33,460
Do you like any specific type of exercise or anything like that?

905
01:02:33,540 --> 01:02:35,220
Oh yeah, no, I like to read a lot.

906
01:02:35,220 --> 01:02:38,740
I'm more partial to fiction than nonfiction.

907
01:02:39,180 --> 01:02:44,820
So I always have at least one book on iPad to read and one physical book to read.

908
01:02:44,820 --> 01:02:48,140
So, you know, about anything and everything, I mean, I'm part of three

909
01:02:48,140 --> 01:02:52,660
different book clubs and, and, you have any three books to recommend to the

910
01:02:52,660 --> 01:02:54,900
audience, like your favorite books ever?

911
01:02:55,060 --> 01:03:00,380
Um, well, uh, the book Thief, um, uh, Cutting for a Stone, those are older.

912
01:03:00,380 --> 01:03:03,420
And the one, the most recent one I read was Cloud Cuckoo Land, which is

913
01:03:03,420 --> 01:03:10,540
absolutely fantastic, all actually very incisive portrayals of humanity

914
01:03:10,540 --> 01:03:11,900
and interrelationships.

915
01:03:12,220 --> 01:03:12,420
Yeah.

916
01:03:13,420 --> 01:03:15,780
Well, Anu, it's been a pleasure to have you on the show.

917
01:03:15,780 --> 01:03:17,940
It's been really a fantastic ride.

918
01:03:18,220 --> 01:03:21,700
Um, thank you for being here and thanks for taking the time to join us.

919
01:03:22,020 --> 01:03:23,140
It's been my pleasure.

920
01:03:23,260 --> 01:03:24,020
Absolute pleasure.

921
01:03:24,060 --> 01:03:25,100
Thank you for having me here.

922
01:03:31,500 --> 01:03:32,420
Thank you for listening.

923
01:03:32,820 --> 01:03:34,060
I hope you liked the show today.

924
01:03:34,940 --> 01:03:38,700
If you enjoyed the podcast, please consider giving us five stars on Apple

925
01:03:38,740 --> 01:03:44,260
Podcasts, follow us on Spotify, support on Patreon or PayPal, and connect

926
01:03:44,260 --> 01:03:46,260
with us on social media platforms.

927
01:03:47,380 --> 01:03:48,180
See you next time.

