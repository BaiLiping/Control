Hello and welcome to In Control, the first podcast on control theory.
Here we discuss the science of feedback, decision making, artificial intelligence and much more.
I'm your host Alberto Padoan, live from a recording studio in Zurich.
Big thanks to our sponsor, the National Center of Competency Research on Dependable Ubiquitous
Automation and the International Federation of Automatic Control.
Our guest today is Stephen Boyd, Samsung Professor in the School of Engineering, Department of
Electrical Engineering from Stanford University.
Welcome to the show, Stephen.
Thanks Alberto.
I'm very happy to be here.
Well, Stephen, there's a million different ways that I could start this episode.
You are one of the most well-known researchers in our field.
You're ranked among the top 10 researchers in research.com in the engineering and technology
scientists ranking.
And according to Wikipedia, you are well-known for convex optimization.
But I wonder whether you still identify as a control theorist.
That's a good question.
Actually, I do.
Control was maybe not quite my first field, but it's essentially the field that I grew
up in intellectually.
So I absolutely identify as someone in control.
I do sometimes cringe at the theorist part of it, brings back bad memories and things
like that.
But control, absolutely, I do identify as a control person.
Yeah.
Because your first degree was in mathematics.
That's right.
From Harvard University.
Is that right?
That's right.
My undergraduate degree was in pure math.
And I even went off to Berkeley for a PhD.
I entered in pure math, but within a year I had transferred to EECS.
So I'm curious.
What had drawn you to control?
You know, actually, I'd like to say that I thought about these things very carefully
and looked at different fields and, you know, made a table of the pluses and minuses.
And that's a complete lie.
I did no such thing.
It was just completely accidental.
I had been in pure math, but I was getting an inkling that I wanted to do something more
applied.
And I went over to take some classes in EECS at Berkeley.
I took classes from people like, you know, Eugene Wong, Pravin Varaya, Charlie DeSore.
Now I thought this was just a random sampling of classes.
Of course, it wasn't.
These are some of the most mathematical and brilliant people in, you know, the whole area.
And I thought like, wow, this is awesome.
So I transferred to EECS in my second year of my PhD program.
Yeah.
And I think I was also reading on perhaps the Control Systems magazine, you were touring.
That's true.
And you were involved in a rock and roll band.
I'm not sure how does that blend with, you know.
Not a band.
So actually this, it does kind of explain, you know, my background, which is very weird,
I think.
Yeah.
Is that related to your passion to EECS?
It is.
You know, when I was like, let's say in high school, I did two things.
Pure math.
So I was into pure math very, very young.
I did pure math.
But I also did a very super applied electrical engineering, right?
So I worked as a stagehand at a large theater in Berkeley, and they had rock and roll shows
come in every weekend or something like that.
And maybe one result of that was, you know, by the time I graduated from high school,
I actually, I knew quite well how rock and roll shows work.
I knew exactly what everything did.
I knew, I even started recognizing people who were touring with, you know, different
bands and things like that.
So anyway, I went off to Harvard as an undergrad.
I was in pure math.
By the way, at this point in my life, I was actually fairly clueless.
I didn't really know that, for example, EE and math were related.
Right.
I mean, I know that sounds ridiculous these days, but I don't know.
Well, I was just pretty clueless also, but it was also just a lot less information out
there.
But I guess in a way you were already familiar with the concept of amplifiers, feedback and
all those things.
Yeah, I certainly did.
When I, you know, when I did electrical engineering, we certainly used math, but it wasn't sort
of like, you know, advanced or fancy kind of math.
Yeah.
Anyway, so when I went off to Harvard, I remember I wrote a letter, which of course is like
completely hilarious these days, but I wrote a letter to the head of what was then the
second largest rock and roll sound company in the U.S. called Maryland Sound Industries,
MSI.
I mean, I'm sure everybody wants to do this, but it's probably so shocked to get a letter
from a kid at Harvard that he responded.
So I went out on a test thing, you know, test drive or whatever.
I went for like maybe two, three days with not a lot of sleep.
I had the great advantage that I knew their systems perfectly because they'd come, you
know, they had something like 14 tours every summer, two or three of them would come through
the theater where I worked and I actually knew their equipment.
I knew how it worked.
It was actually quite innovative and cool to have like really kind of cool patch panels
and things.
So I knew how it worked.
So I remember they told me, they said, go wire up the left side of the stage, but don't
even think about powering it up, you know, because if I wired it up wrong, everything
would blow up or something like that.
So I went over, I knew how the system where I fixed it all, I wired it all up, came back
and they said, what are you, an idiot?
What happened?
We said to go wire.
I said, it's done.
And they said, well, that's impossible.
No one could do it that fast.
And the guy comes over and looks at it and he starts like holding his head and he says
like, oh my God, he did.
So then what happened was then rumors started spreading of me being a rock and roll sound
wunderkind.
That's what happened.
And actually, and they got better and better.
I mean, you know, someone said, yeah, he set up the entire stage.
He did an entire set change in between acts in like 90 seconds flat.
You know, it just, all sorts of crazy stories grew.
Anyway, the result was that I was hired by that company.
And I told them, look, it's, this is all wrong.
I've seen your equipment.
That's how I know how to put it together.
And they were like, anyway, the stories kept growing, actually for years they kept growing.
I worked for that company maybe for about six years on and off.
So basically I was either in school or I was essentially on the road doing rock and roll
sound.
So I guess there was your first sliding door.
You could have actually made a career in that direction, but you decided to go to Berkeley
for a PhD in control theory.
Exactly.
I remember very well when the owner of the sound company was like telling me like, dude,
I don't know about this PhD thing, but you should do this right now.
Actually, I thought, I mean, I thought about it, not too much actually, to tell you the
truth.
What was funny was I met him about 10 years ago.
So long, long time, many decades after I had stopped working for them.
And two things happened when we chatted.
It was funny.
Number one is I was thinking to myself, the stories I remember from that time, maybe I've
improved.
I probably, I did improve them.
I don't know if they're true or not.
I mean, they were probably based in truth, but anyway.
He confirmed that some of the stories that I was most suspicious of, these are my own
stories.
He confirmed they were true.
And then reminded me of even crazier stories that I had completely forgotten.
So anyway, so, so anyway, but somehow the appeal of Volterra series was more, you know,
when you put it that way, I think the answer is no.
I can tell you this.
If you're, if you're mixing house in a 15,000 seat venue, right.
And you know, on your headphones, the stage manager says, we're T minus four seconds.
And you pop your button across the, to unmute all the sub masters on the mixing console.
You know, this, this beats Volterra series.
I'm just going to say it.
I'm sorry.
It's good.
No.
And anyway, I guess when you were in Berkeley, you were surrounded by people that nowadays
are considered giants in the field.
I'm thinking of Chua, Dessour, Sastry, just to name a few.
And I was wondering, what was your experience there?
Oh, it was great.
I mean, they are the reason I switched over to EECS.
I mean, you know, they were, and in very different ways, you know, Dessour was precise and very
clear in a beautiful way.
Chua just knew so much.
It was just, you know, had an interest just all over the map and all sorts of weird areas
involving, you know, nonlinear circuits, but also all sorts of crazy stuff.
And then Sastry, Shankar Sastry was amazing.
He was this kind of young, I think I called him a child professor because he really was.
I mean, he was just a kid.
Had just an infinite amount of energy.
These three were just, you know, if you take the convex hull of these three, it's very
impressive.
Let's put it that way.
So, yeah, they had a big influence on me.
And your investigations there were, as you mentioned, fairly theoretical.
I mean, yeah, you know, in doing my homework for this podcast, I was checking your first
paper with Leon Chua, I believe, on the passivity criterion for TIN ports.
And I actually love the abstract, it was incredible, because it already gives a bit of a hint about
your future style in a way, which is quite predictive.
You say there are existing proofs of the passivity criterion for linear time invariant
distributed ports are either incorrect or too involved, requiring the use of advanced
mathematics such as distribution theory.
This paper presents a simple but completely rigorous proof using only basic, real and
complex analysis.
I think that's wonderful already.
That's great.
Now, in my defense, I will say that that was at the very beginning of my transition from
math to ECS.
I guess a lot of people think about, you know, how is, what are the good parts about math
and why should you learn some and stuff like that.
One aesthetic in math is simplicity.
I mean, you know-
Occam's razor.
Yeah.
Some people make stuff really complicated.
And, you know, there's stories, possibly even true of, you know, Russian mathematicians
who spend seven years working on a paper and someone says, why?
And he said, the proof used to be seven pages.
Now it's three quarters of a page.
Now I'm happy with it, right?
And so, you know, so there is this very clean and lean aesthetic in math.
And I think it's, it's actually guided me.
I'm very attracted to it.
I won't say I'm not.
Right.
It's, I think it's very cool.
You think that's the use of theory in practice or is there-
Oh, I think that's precisely the theory, right?
I think that's exactly the idea.
I think that, you know, I see a lot of people who imagine that theory is used in practice
like this, right?
Like I go grab a theorem from a journal and then I apply it or whatever, whatever that
means.
I don't even know what that means.
But the point is that's completely wrong, right?
I'm not aware of any theorem that's actually used in anything.
I mean, maybe in some kind of, you know, number theory or something, but it doesn't matter
for cryptography.
But other than that, I'm not aware of any.
So in my opinion, the real value of math in applied settings, control being one of them,
or at least one of them, is what it gives you is clarity of thought.
And that's extremely important in practice.
So let me explain that, right?
If I, you know, here we are in Silicon Valley and people build stuff and, you know, I could
get one team and say, you know, go build this thing.
And with a lot of high level tools now, you can bang something together that looks like
it's working.
I mean, there's kind of a UI and the app works and something happens, but there's another
style and I've seen other people do this.
It's just beautiful.
And there are people who think about it very deeply, often trained in things like math
or something abstract, and they don't do anything for a day or two, right?
After a day or two, they look up and they go, hey, you know what?
The 87 things that we've been asked to implement are actually all instances of only three different
things.
So we're going to implement that correctly.
And then, you know, blah, blah, blah, it'll all fit together.
So what happens is they'll build something.
And here's where this is practically useful.
You know, when people just hack something together to knock off 87 requirements, it's
going to be horrible code, badly structured, there's going to be all sorts of weird dependencies.
It won't be correct.
You'll never be able to actually debug it.
You definitely cannot extend it or anything like that or modify it.
Whereas when you see people who actually kind of think abstractly and actually took the
time to work out what were the correct abstractions, you get beautiful, lean code that has very
high probability being correct.
It's extensible.
And then just as a purely practical matter, the cost of ownership of that project is a
lot less.
Because, you know, it actually will, number one, it will work.
Number two, it's extensible.
It's maintainable.
It's like Linux, for example.
That's a good model of this.
Well, here, there's a lot to unpack already.
I think implicitly, you're touching also on the concept of maybe something that we're
going to talk about, the concept of disciplined convex programming, but also generally the
idea that maybe this is actually the value of human creativity in a way that of parsing
through different concepts and being able to synthesize in a way what is important and
how to categorize different ideas or I guess classes in the language of computer science.
I'm not sure.
But yeah, maybe taking a step back.
I feel like we're diverging from your PhD at Berkeley.
I just wanted to understand how that actually relates to you today in a way.
So how do we connect a person that, you know, had this crazy interest for mathematics, full
time operators, very, very theoretical concepts with the person that you are today?
So something that I would associate you to very applied concepts, very useful in a way
concepts for everyday engineering.
Yeah, it does apply.
As I said, that was sort of the beginning of my transition from pure math to EECS in
general to more practical things.
You can call it applied math.
Control was one interest.
So I think that was the very beginnings of it.
Actually, it's since then, I mean, I'm still on that journey.
And it's super interesting to me to see how people in different fields use math.
And you know, by this time in my life, I've visited many, many fields.
So I've been a sort of a visitor at many.
But I've actually spent time, you know, spent like, you know, whatever, you know, a couple
of year periods in a bunch of fields.
I mean, circuit design was one, that was very weird.
Finance is another.
And what's interesting to me are the anthropological issues.
How do people use math in practical settings?
So it's really questions like, you know, how do they think about this?
Do they use a lot of brute force computing?
It's so interesting.
And what's very interesting to me is I found out that in these different fields, which
are, you know, speak completely different dialects.
I mean, they're not completely mutually unintelligible, I can guarantee it.
What's interesting when you look at that is the same topics come up over and over again.
You know, one would be, you know, how good is your model?
And the acknowledgement that your model is not perfect, right?
You know, in let's say circuit design, you know, spice model for a process that's already
pretty mature, that's actually pretty good.
In finance, you know, the models are, or as a friend of mine says, he's super happy if
he gets the sign right, right?
So, you know, this is not Newtonian mechanics, right?
But then, you know, robustness is another one.
Like, you know, how do you design something or decide on good actions or build a good
model that's going to be robust to things being not what you thought they were?
And that comes up in every single field.
They all have interesting different ways to talk about it and think about it.
And some of the methods that are used are from one field or other might look very unsophisticated,
but in fact work very well.
So that's sort of very interesting to me to see how people do this.
I guess that's really the value in a way of traveling, at least from an intellectual perspective.
There is this quote from Mark Twain.
He says, travel is fatal to prejudice, bigotry and narrow mindedness.
And it seems like this very well resonates with what you just said.
Yeah.
So, you know, whether traveling intellectually taught you something that you didn't know before.
Absolutely.
I strongly recommend it to everyone.
Just to know a little bit about different fields.
One of the interesting things is that you really get people speaking different dialects
and you can't.
They are mutually unintelligible unless someone is there who actually speaks both dialects.
It's very hard to translate from one to the other.
And now I know when I go into a field and I listen and I'm like, these people sound
like idiots to me.
But now I know from experience that I should just calm down, you know, wait a couple of months.
Maybe some of these terms are going to start and then I'll start understanding what they're saying.
And in fact, they're not idiots.
And this has happened to me many, many times.
And it's so it's actually quite interesting.
I think it's very good for all of academia and for research.
It's super good to travel, to look at other areas.
I guess your first travel was from control itself towards the world, I guess, of computation.
Would it be fair to say?
Yeah.
Actually, I think the very first academic stuff I did was on modeling of nonlinear systems
via Volterra series.
I also dabbled in, at that time, adaptive control.
And then actually became interested in designing control systems using numerical optimization
methods.
Right.
So that's one thing I did.
I think that's the branch that grew into what I ended up really focusing on.
And, you know, what I liked about that stuff, I mean, that was a long time ago, what was
very interesting about it was that it appealed to me aesthetically because it was both theoretical,
it was using all sorts of stuff about, you know, the parametrization of stabilizing controllers.
It was using kind of theoretical stuff.
It also used computation to actually solve problems.
And then at the same time, it was actually extremely useful, right?
It actually solved real problems.
So I think that combination of things just really appealed to me.
And I mean, it still does, to be honest.
So I think it's great.
Yeah.
In fact, I mean, what I saw, you know, doing a bit of searching was that you got your PhD
in 1985.
And from 1988, what I observed is that the word computation starts to appear in your
publications and it grows from 1988 to 1992.
It goes like one, one, and then three, four per year.
So it definitely seems to resonate with you.
And at the same time, also the keyword optimization as well.
So you were moving definitely in that direction from the world of nonlinear systems and very
complicated mathematical tools, I would say.
Yeah.
And I very much like the idea that sort of, you know, some advanced mathematical things
like convex optimization, actually they are very mathematical, but they're also unbelievably
useful, which is super interesting because, you know, you normally think of this weird
axis where, you know, on one side, there's like pure theory and it's pretty useless,
right?
And then on the other side, you have something that's, you know, there's almost no theory
and it's super useful.
And of course, you do see some of that.
But what's interesting is that there are a lot of things that are both and I find that
sort of very interesting.
I think it's very cool.
I definitely wanted to talk about this topic.
Both of your most well-known publications or books rather, Linear Metrics Inequalities
in Systems and Control Theory and Convex Optimization are masterpieces in this domain.
And they both involve quite a bit of convex optimization and they do turn into something
that is incredibly useful and that's perhaps also reflected in the success, at least in
terms of citations, if we take that as a measure.
And I'm wondering, I mean, one question I would have for you is why should everybody
know a bit of convex optimization?
That's a good question.
Yeah.
Of course, it does depend on our definition of everybody because if you really mean just
everybody, then I'm not sure I'd be on board with that statement.
So if you mean anyone who does any kind of quantitative work, then I would totally agree
with the statement.
And yeah, I can say a little bit about why I think it is important for anyone who...
And that's many, many fields, right?
And there's the obvious ones like whatever, all of engineering, right?
Much of social science these days.
So maybe quite a lot of science.
So the reason is it's an incredibly important tool to actually solve optimization problems,
right?
That the usual sort of story on optimization problems is here's what I'd like to solve.
And then basically, I mean, people don't admit it when they're teaching these classes, but
the bottom line is we can't actually solve most of those problems, right?
You just can't, right?
I mean, maybe that doesn't matter.
We have heuristics that do well and if you get a good model or if you make good
predictions or if your hedge fund makes money, you're fine.
You don't need to worry about that.
But the fact is there is a group of mathematical optimization problems that we can solve numerically
via computers really, really well.
I mean, I used to go around and say things like, oh, the great advantage is you get the
global optimum.
There's no apologies.
You don't have a little star and a footnote and the footnote when you say, oh, I minimize
this and the footnote says, well, maybe or maybe I didn't or something like that, right?
So I used to do that until actually I remember I met someone who was a senior executive at
a large semiconductor firm.
So I was chatting with him and I said, look, this is the best design of this thing that
there is.
And he looked at me and said, how could you possibly know that?
How could you know?
And I realized like for a normal person, that's the correct response.
Like what hubris, right?
What would cause a person to say this is the best there is, right?
And I said, I started my usual spiel, which was like, hey, look, you know, basically,
you know, it has to do with the mathematical properties of the functions involved and I'm
blabbering on and on.
And he just puts his hand up and says, stop, stop right there.
And I was like, what is it?
And he said, look, fine, he said, but that's only the best design for this particular circuit
configuration.
And I was like, yeah, you're right.
And he said, but there's lots of others.
How do you know there's not another one?
And I said, you're right.
And then he said, now you be quiet and I'm going to tell you what's useful about convex
optimization.
So here I am being lectured by a senior circuit designer.
By the way, so, and he says to me, look, I don't care about your global stuff.
Who cares?
If you do real engineering, nothing is global.
And I didn't even know what that means.
And I said, okay, granted.
And then he says, look, here's what's useful.
When you solve these things, you don't need a starting point, number one.
Number two, you don't need to babysit the algorithm.
And he said, we've looked at a lot of these algorithms that do circuit design and stuff
like that.
They require a starting point, right?
He said, then they take off and they'll go from a good design to a quite good design.
And he said, do you know what we call a good design around here?
I'm like, no, what?
And he said, done, done.
He said, we are under unbelievable business pressure to get things out there.
And I said, well, since you have a good design, like we don't want to get another 15% of performance
out of it.
We want to tape it out.
So I listened and I realized like, oh my God, like he's totally right.
And what's interesting is how it, where it goes in control.
So in control, you know, if you embed a convex optimization solver in a control system, as
you might do an MPC or for actuator allocation, it's not a question.
It's not like the fact that you're getting global optimal, who cares?
What matters is these algorithms can be made so reliable that they can be embedded in systems
with absolutely no oversight that solve things a thousand times a second in safety, critical
things.
And they just don't fail.
That's actually the real value I would say, right?
Of this.
So, so anyway, I think there are a lot of practical values.
They're not the obvious ones that maybe I thought when I was young, let's put it that
way.
Yeah.
And I find very interesting the fact that you really interfaced with the industrial
world and really hardcore levels.
I was reading that your CVX gen, which I'm sure we're going to talk about later, has
been used in SpaceX missions recently.
And I was wondering what was your experience there?
Like thinking about the cultural difference, if you want, between the world of academia
in which you presumably live, but also the other world, the real world in a sense.
Yeah.
So that's interesting.
Actually, it wasn't used recently.
Every single one from the prototypes through, it's just in production now.
Yeah.
So, and to be completely clear about that, how much I had to do with it was very, very
little.
It was my student, Thomas Lipp and Lars Blackmore, who were the ones who really pioneered these
things.
It's wonderful to see these things realized in very sophisticated settings and also to
deliver incredible value.
You know, classical control and things like that just wasn't going to cut it for this,
So that was very gratifying.
I mean, there's been a lot of others, you know, in areas like finance and control and
energy management that it's very nice just to see people using this stuff.
I mean, I remember once I went to Tesla and some people who ran their grid scale storage
products.
It's very cool, right?
They have a giant cargo container full of batteries.
They have a Raspberry Pi and on it is running CVX Pi.
Wow.
And they told me, actually, it's very funny.
They told me their problem.
I listened.
It wasn't quite convex, but there's a street fighting trick, you know?
So I'm sitting there and they finish and I said, well, how do you solve it?
Expecting that I'm going to have to tell them this trick.
They proceed to then tell me precisely the trick and articulate it perfectly.
And I'm like, whoa, how did you guys figure that out?
And then they looked at each other.
They looked at me and they said, we took your class.
So I was like, okay, good, good.
So I was quite proud of that.
And actually it's one of those things where I said, well, so you don't need me.
That's great.
This is awesome.
And thanks for showing me this.
So I was very gratified that it happened.
Maybe talking about convex optimization and your classes and that, I mean, I'm sure also
we're going to talk about teaching later because you're the author of a legendary series on
convex optimization on YouTube and that is free access.
And there's definitely a lot to talk about there as well.
But I was trying to trace back a history of convex optimization somehow.
And of course the concepts of convexity go all the way back to, you know, Euclid, Archimedes
and optimization.
We can trace it back to Fermat, Lagrange and blah, blah, blah.
But I was wondering whether the actual start of convex optimization should be pinpointed
to linear programming, simplex algorithm, Danzig.
And then it seems like a very recent theory.
I think that's right.
The theory of convexity was codified maybe around the turn of the last century, right?
So that's when you would get, you know, but of course it had been used before that.
I mean, we still see fields where people are using essentially convex optimization and
either don't know it or don't point it out, right?
So you look at something, you go, oh, that's just a conjugate of that function, like, or
something like that.
And so the ideas were there, actually the inequalities were there.
It just got a common name, you know, around the turn of the last century.
Now, it was pretty much a theory then because computation was very limited.
But starting, you know, around mid 40s, I would say, is when things get interesting
and that coincides precisely with the development of the digital computer.
And you know, it wasn't long after, I mean, if you think about Danzig coming up with,
you know, a simplex method for linear programming, it was not that long after the development
of the first actual computers, right?
So, and I remember I actually overlapped with him at Stanford when I first came and I remember
him telling me something like that it was a huge big deal to solve like a linear program
with like 30 or 40 variables, which, you know, is laughable now, but he said that it was
a lot of effort and when they did it, they all like, you know, they went out and had
some beer to celebrate.
I mean, it was a big deal.
So it was one of the very first applications of digital computers.
But if I were going to say, you know, when does the, I mean, from a mathematical point
of view, you'd have to say, end of the 19th century, right?
But from the practical point of view, I think you'd have to say around 1950.
1950.
Yeah.
And, and I guess then the developments were the, I mean, the most important ones were
the development of the interior point methods, I guess, ellipsoid method probably.
Yeah.
Well, those are later.
Yeah.
So you actually had two traditions.
It was actually very interesting in the West, in optimization, OR, and these kinds of areas.
The tradition was you'd either work on like linear programming or nonlinear programming,
right?
And that was the distinction.
I mean, it makes perfect sense.
I mean, it was fine, you know, and it's like linear programming was easy, interesting,
you know, nonlinear was more expressive, but, you know, it was complicated and maybe you
didn't even get the solution when you apply these algorithms to it.
And I think in the Soviet Union, however, there was a big focus, this is now in the
sixties, on actually convex optimization.
And so there was a lot of work done in the sixties and seventies and eighties in the
Soviet Union.
I think we will talk about that later, where they really focused on convex optimization
and they came up with all sorts of things.
Interior point method was an interesting, super interesting method.
Of course, it's actually in practice, you know, pretty much not used and not useful.
And of course the converse of that is something like the simplex method, which in the sixties
was shown to be worst case exponential, but it didn't stop the hundreds of thousands of
people using it every day because it just worked unbelievably well in practice, right?
Interior point methods was also an interesting thing.
You know, that was a big, you know, rage in the late eighties and the nineties.
And I mean, it was crazy, but actually it turned out when people went back and looked
at the history, there were precursors of this.
I mean, this always happens.
And it turned out there was essentially a very clean interior point method that was
from the sixties by this guy Deakin.
And I remember corresponding with some of my friends who were then in Moscow at the
time.
And they said, they said something great.
They said, Deakin is hardly known in the Soviet Union and unheard of in the West.
Right.
You know, you look at these things like they were pretty good.
They were like competitive with the algorithms that people in the West were writing and writing
papers on.
And they imagined that this was like revolutionary and, you know, nothing like this has ever
been done before.
And the answer was, you're wrong.
It was done in 1967, you know, in the Soviet Union.
The interplay between the Soviet Union and, you know, the Western world, both, you know,
mathematics, but also I would say in control are so interesting.
And I think there's a fantastic summary in your book on linear matrix inequalities about
the key events also in that domain specifically, not just in convex optimization.
And there you're actually right that it is fair to say that Yakubovich is the father
of the field of LMIs and Lyapunov the grandfather of the field.
Yes.
And the new development at the stage where you write the book is the ability to directly
solve that's right.
General LMIs.
I thought that was a fantastic sentence, but it seems like Willems in his 1971 paper is
the one that actually points out there is a known appreciation that's right for LMIs
in control.
Yeah.
So that also has a very long history.
I mean, it goes to Lyapunov and it goes even into the 19th century and basically comes,
I think if you really traced it back to physics, to the concept of an invariant at first, right?
That's a quantity that doesn't change as the system evolves, right?
So, you know, if you have a closed system, it could be the total mass or the, you know,
or the total energy or the angular momentum about some axis or something, right?
And then it doesn't take much to generalize that to put an inequality there and to say,
how about a dissipated quantity?
That's a quantity that's always decreasing along trajectories of a very complex system.
And the whole point that was recognized even in the 19th century was that there were times
when you could identify something that was either an invariant or a dissipated quantity
without actually being able to solve for the trajectory, right?
So you could have a three, four body gravitational problem and say, at that point, you could
do this, I mean, numerically, which would be horrible because it'd be actual people,
you know, with, I guess, you know, hand calculators or something, but, you know, adding machines.
But what was interesting, it's super interesting, right, that you could actually, it was fully
appreciated then.
And of course, that comes up in control, right, where you'd say, I can't write down what the
trajectory of this is.
He says, but I'm about to prove to you that it's stable.
You know, in control, we don't even think about that because it's a part of control,
that idea.
But if you think about what that sounds like, I mean, if you really try to pretend you're
no longer 22 and a grad student learning this for the first time, you know, somehow the
wonder is lost.
Because you really should say, oh, my God, that's amazing, like, you can't tell me what
the solution of this differential equation, you're like, that's right, I have no idea
what's going to happen.
But I can guarantee you that the total energy is conserved or that the total energy is dissipated.
It's kind of cool, right?
I think you have to admit.
It's incredible.
And I wonder whether you think this is the most important concept?
I mean, how do you look back at the book on LMIs?
Yeah, I think that that's right.
I mean, that's the essential concept, which, you know, you can trace back to the 19th century,
you know, specifically for linear matrix inequalities, which basically looks at quadratic functions
that are these quantities that either decrease or invariant.
Usually in most interesting applications, they're dissipative, right?
They decrease.
And, you know, in the 40s, people had worked out, like, really cool ways to solve these
inequalities, right?
Very simple ones, right?
And there were graphical methods, you'd literally get out some graph paper and draw some curve.
And, you know, if it stays away from some point in the complex plane, then anyway, that
was one.
There was a connection to control figured out with things like algebraic Riccati equations.
But I think the really interesting thing, and as you say, Willems and others, you know,
had already observed this, is that in the 70s, I think there were some papers in the
Soviet Union about directly solving to find one of these, you know, dissipated quantities
or a so-called Lyapunov function by numerical methods, which is, I think, you know, it's
not a huge thing, but it's pretty cool, right?
You know, up until that point, the way you've, I mean, look, let's think about the way people
find Lyapunov functions, right?
One is you start with physics and you say, well, let's just add the kinetic energy plus
a potential energy.
And that doesn't work, you add another term or two, and then voila, it worked.
You got something, right?
I mean, another method would be from optimal control.
So you'd actually, you'd write down an optimal control problem and you'd work out, let's
say, the value function of it.
So these were the traditional ways, right, through analytical methods and other stuff.
Anyway, so it's really interesting, the idea that you can actually compute them.
And that's where I think convex optimization comes in, right?
It turns out that in a whole lot of cases, you can actually compute these Lyapunov functions
using convex optimization.
And I think that's super interesting.
By the way, I think it's under, you know, I look back at that book now and I'm a little
bit horrified.
I mean, I gave it to somebody the other day who was interested.
I said, take a copy.
But I had to warn them.
I was like, look, you know, full disclosure, you know, it's really technical and it's weird
and all that.
And it predated the term semi-definite programming.
So we have some bizarre name for it, like the eigenvalue problem.
So I just said, look, just heads up, this is not a fun book.
But yeah, but I do think actually a lot of that stuff is super useful and actually hasn't
been fully explored.
So I'm actually wondering, do you think that is the last word on the topic or do you see
a future for what is the next step?
Honestly, I've been thinking about it on and off for a couple of years, but if I were going
to do something really weird, I might go back to that and build, you know, build some beautiful
software system for people to do that kind of stuff.
I mean, there were, of course, there were things in the past that did this.
There was this thing called LMI Lab or whatever, and there was a lot of other stuff driving
it.
But, you know, but just make it so that actually you could synthesize controllers and, you
know, performance certificates this way.
I mean, you, I think at one point you asked, you know, what were the essential ideas?
There's actually another very powerful idea that's in there.
And again, like many others, it can be traced way back.
But the idea, you know, in the eighties and nineties and aughts, people were thinking
a lot about, you know, verifying performance of something and the way we all know how this
actually works in the real world.
The way it works in the real world is someone designs a controller and they put some saturation
in and then they tweak this gain and they do that and they do this and they gain schedule
something and what they fiddle around and then they simulate it with a high fidelity
simulator on a lot of stuff.
And after a while they declare, I think it works.
There it is.
Right.
And then they pass this controller over the wall to, you know, some control theorist who's,
you know, typically hiding in the back room, right back room, meaning they're in a place
where they should never come out in public.
Right.
Which I, which I think is probably the correct way to handle most control theorists.
Anyway.
So they throw the policy over the wall to this control theorist and they say, please
verify this, please validate it.
Right.
And, you know, you, it's interesting, I mean, you can try and you can do all sorts of stuff
and you know, but it turns out, I think one thing you can conclude and one way to interpret
the entirety of all the LMI stuff is to say, that's the wrong way to do it.
You don't do it sequentially.
The right way to do it is to co-design the policy or controller and the certificate or
proof of correctness.
You co-design them.
And in fact, an even cooler and more advanced view, which I think people probably knew this
in the 60s or 70s, is you design the proof of correctness first and then the controller
will fall out from it.
Right.
So if I produce a control Lyapunov function or an approximate, that's the idea behind
approximate dynamic programming.
Right.
And incredibly powerful idea, I think.
And I guess this is very much related to some of your most recent work on COCP.
Is that fair to say?
It is fair to say.
Yeah.
So COCP is Convex Optimization Control Policy.
And it's a broad term for a policy in sequential decision making.
Could be a controller, but it could also be a trading engine.
It could be all sorts of other stuff.
It could be an alarm system.
So I'm thinking of control in a very broad way here.
And it basically embeds a convex optimization problem that you solve.
Right.
And, you know, I mean, there's lots of examples of this.
I mean, in traditional control, you'd have MPC, which has been done, I think, since the
late 70s.
MPC and like chemical process control.
And it's really fascinating, right, that you actually, you solve this complicated problem
and then that tells you your current action.
And then 15 minutes later, you do it again.
It's cool.
For the audience, I should probably just add what it perhaps is MPC just for everybody
to be on the same page.
So model predictive control, it's just, I guess the main idea there is really to solve
an optimal control problem recursively, iteratively, and that turns out to be a very good idea
in practice.
Yeah.
This is the very, very short sales speech, I would say.
Yeah.
But you were saying something about convex optimization policies.
I find that concept quite interesting and in a way also revolutionary.
I was watching a keynote that you gave at L4DC in 2022, and there was a fantastic, controversial
statement there that goes like, tuned COCP, so convex optimization control policies, is
the PID controller of the 21st century.
Can you elaborate on this?
I can.
So this is one of the things that you come to appreciate in control, and it's a really
cool fact about our field, and I think we should accept it and embrace it.
I think it's really awesome.
It's this, is that incredibly simple sounding algorithms can be unbelievably effective in
practice.
You know, PID controller is one of them, right?
And it's very funny when you go to a fancy control thing and you'd be hearing a lot of
theory and some fancy new robust controller and stuff like that.
It's just kind of, it's good grounding to think every now and then about things like
PID controller, lead lag control.
So I thought your definition of MPC was very good.
I want to put it in maybe a less fancy way to say it, because I see it, actually, it's
used in many, many fields with different names, right?
So the way, at the highest level, I would say it goes like this, right?
You know, you want to take an action.
It's for sequential decision making.
So you know, you can act right now, and there's stuff that you know, and there's stuff you
don't know.
Like you don't know exactly what's going to happen in the future.
You probably have some idea, but you don't know exactly.
And so the first thing you do is you get a forecast.
And it's ridiculous.
It's a single forecast of what's going to happen in the future, right?
You say, this is the way I think energy prices and demand are going to be moving in the next
48 hours.
Like that's a prediction.
And someone says, wow, do you believe it?
And you're like, no, of course not.
It's just a forecast.
I mean, come on, right?
Okay, then you do this.
It sounds so naive.
It's unbelievable.
You then do the following.
You say, okay, well, guess what?
I'm going to create myself a plan of action, assuming my single forecast is completely
correct.
And you're like, that makes no sense.
It doesn't make, it's like, this is not going to work, right?
Okay.
And then you say, then what I'm going to do is I'm going to make a plan of action.
You take the first step in that plan of action.
And that's what I'm going to do today, or for this 15 minute period.
Then they say, well, what happens next 15?
Well, you see, I do the same thing.
I get updated forecasts, I replan.
And then, of course, there's a lot of theory around it, which is, frankly, a little bit
silly.
I mean, it is nice to know that it kind of works in some silly cases, right?
But I think the most important fact about it is something like PI and PID, when it's
done correctly, it works extremely well, thank you.
If you think about it, I mean, it's hilarious.
It's used in finance, where it's called multi-period trading or something, right?
And that's hilarious, because the entire point about finance is precisely that you do not
know the future.
You know, if I knew future returns, like, I mean, I don't know, I have friends who say
if you can get the sign right 52% of the time, you can make money, right?
So the point is, you very much don't know the future.
And yet, you know, in the right hands, there it is working in finance.
So I remember I talked to someone in supply chain.
This is how they do it.
This is what supply chain does.
I mean, of course it is, right?
You make forecasts of product demands, right?
And then you figure out, like, what stuff should you ship where and, you know, all that
kind of stuff.
And you're taking into account a lot of cool stuff, like, you know, the cost of trucking
things or transporting things from one place to another, the capacity in a warehouse, the
amount of labor you have available to do X, Y, or Z.
So it's, you know, very sophisticated.
But it's based entirely on forecasts, you know, a week, a month, or, you know, even
sometimes an hour out.
It does seem to be the most intuitive thing to do, actually.
It is.
And I remember I talked to someone who's an expert on supply chain stuff.
And I said, what do you call it when you make a forecast, then make a plan of action, pretending
that your forecast is correct, take the first step, and then repeat the whole thing one
time step later?
I said, you know, we, I said, we call, you know, I said, in my field, we call this, you
know, model predictive control, dynamic matrix control, you know, all, you know, receding
horizon control.
I said, we have lots of names for it.
What do you call it?
And he just looked, stared straight at me.
And he said, yeah, I said, like, what in supply chain?
I don't know that dialect.
What do you call it?
And he just looked at me and he said, we call that supply chain optimization.
The point, the point being, like, what else would you do, right?
Like, what else could you possibly?
So it was cool.
I also had a, had a hilarious conversation with a friend of mine who is a CFO of a company.
So we're just chit-chatting, you know, about what CFOs do.
And guess what they do?
He said, basically, by the time we finished talking, he said, that's 80% of my job.
That's what I do.
It's just, he said, he said, now I know the name for it.
It's MPC.
Yeah.
He said, look, here's what I do.
I get, I get multiple forecasts of, you know, demand for our product, costs, right?
I know we're opening a new facility in Austin next year, and that's going to cost X.
We forecast, you know, revenue, we forecast growth, you know, all sorts of stuff, like
many quarters out, like six, eight quarters out, right?
And he said, yeah, we don't believe those.
He said, in fact, we typically make three forecasts, right?
Kind of a median one, kind of a poor outcome, like, you know, low revenue and high expenses,
right?
And then, you know, when they sometimes label bliss, which is like a, you know, and yeah.
And then he said, we make a complete plan.
I present it to the board.
That's what we do.
And no one on the board believes that your revenue forecast four quarters out is going
to be right.
No one believes that.
No one.
So, but the cool part is everyone understands you do this plan, so you don't do something
now that's going to put you in a bad position in the future.
And that's really the essential idea.
That's crazy.
And it seems to apply to at any scale in a way, also like at a political scale, for example.
It does.
In many other domains.
But maybe just to go back to convex optimization control policies.
How do those relate to, let's say, MPC that we just discussed extensively and other things
that we mentioned before?
MPC, model predictive control, is simply an instance of a convex optimization control
policy.
It's a policy where you solve a problem to decide an action.
And in this case, you solve it over horizon.
There are a lot of others.
I mean, one is approximate dynamic programming is another classic example of that.
But there are lots of other things where, a lot of these things have parameters in them
that you can use to tune, right?
This is not at all unlike PID, where you have three parameters to tune.
You have a lot more than three parameters to tune in these things.
Actually, that's not true.
In some cases, you would have hyperparameters, and there might only be a few, right?
Like if you're doing finance, you might have a term hyperparameter that scales the risk
cost, or another hyperparameter that scales the transaction cost, right?
And as senior people in control told me decades ago, the right way to think of these parameters,
they were of course referring to like LQG, is they said, these are knobs that you turn
to make the controller do what you like.
And it's this identical principle here, right?
So people have made convex optimization control policies for a while.
It's growing, I think, or it appears to be.
Part of it is the relentless improvement in computers, right?
So that doesn't hurt us at all, I should say, right?
Everything's based on that.
But a lot of the tuning was done by hand.
And that's actually, if you've got three hyperparameters, why not, right?
What's interesting is even something like 10 or 20 or 30 hyperparameters is a case where
you can tune that policy to make it do what you want.
And so I think that's what a tuned COCP policy is.
And what's, I think, kind of exciting is not theoretical, because everyone knows about
all this and knows that this is the general program.
I think the most exciting part about it actually is the infrastructure and ecosystem being
built out to actually do this, right?
So we'll talk about that, I imagine.
We'll talk about CVXPi.
Definitely.
Definitely.
But to me, that's the most interesting part.
I mean, I'm just wondering, I'm going to put myself in the shoes of the audience.
And could we conceptualize COCPs as essentially parametric convex optimization programs in
the parameter being the control policy in a way?
Would that be fair to say?
Maybe not quite.
So there are two types of parameters in a convex optimization control policy.
One, it tells you the context, and that's typically like the state or the inputs.
Or if someone says, no, I changed my mind, here's your target over here, right?
That's one.
And the second are parameters that affect the policy.
Which you don't expect to change very often.
And as a matter of fact, in...
This would be the Qs and Rs, for example, in LQR.
You got it.
Exactly.
And to be honest with you, in most legitimate applications, you don't change those at all.
I mean, you know, whatever, except with a software update or whatever it is you want
to do, right?
That's the safe model.
So...
It sounds super interesting.
And I guess the ecosystem that you were referring to before has to do with the enormous amount
of software that you have produced, again, in your, I wouldn't even say double life,
but triple life or fourth life.
So your first endeavor in that direction, I guess, was CVX in 2008.
That's right.
But then it sparked into a whole, as you said, ecosystem of different types of frameworks.
So for example, CVX-Gen, CVX-Pi, you also have a Julia version as well, CVX-R, OSQP.
I'm pretty sure I didn't mention even half of them.
Is that right?
You're right.
You didn't.
It's okay, though.
It's fine.
I'm curious there.
I mean, I guess this is also the result of your interest in how to apply all the theoretical
concepts that you developed.
But also, the concept that I found most interesting there was the idea of disciplined programming,
convex programming.
Right.
Can you elaborate on what that concept means for our audience?
Oh, I can.
So, you know, I was going around being a pain in the ass to people about convex optimization,
both before the development of these tools and after.
And it would go like this.
I'd be all, I mean, I think about it now, it'd be awful.
Like I'd go somewhere and someone would say like, okay, here's my problem and I want to
do X, Y, and Z.
And I'd come up to them afterwards.
I'd say, hey, guess what?
Your problem's convex optimization problem.
And they'd say, so?
And I'd say, so it means we can solve it.
And they'd say, so how do I do that?
And the truth was, in those days, it's kind of a pain in the ass, right?
Because you have to, you know, write all, I said, well, you just get yourself a grad
student and, you know, have them write up all this horrible code and it's hard to debug
and translate it to some standard form.
Then you link it to some solver, whatever at the time, you know.
So it just wasn't that easy.
And I remember a lot of times, even when I had come up to someone and said, look, we
could just solve your problem.
A lot of those people just thought I was a crazy person, but that's another story.
But even the ones who said, yeah, I think you're right, it just, the barrier to entry
was just too high.
It just involved, you know, tons of coding and C and C++ to link something and all that
sort of stuff.
So the, you know, the idea behind discipline convex programming is, the short description
is this.
It is a system for basically normal people or relatively normal people to be able to
specify and then solve a wide, very wide variety of convex optimization problems.
Right?
So the contract is very simple.
It's this.
You the user will accept basically extreme, extreme limitations on what you can express.
Okay?
Here's what we pay you if you honor that contract.
Then what we will do is we will faithfully translate your problem to a standard form
problem and solve it globally and give you the solution.
Right?
That's the contract.
And, you know, it's actually, I mean, it's not too dissimilar from the question of trying
to verify a controller.
You might imagine that the right way to use convex optimization in the field would be
people just write their problem.
And then, you know, some computer would look at it and try to argue and figure out if it's
convex or not.
And it turns out that's actually a truly terrible idea.
The right way to do it is to say there's a very short language.
As a matter of fact, there's exactly one rule, which is crazy.
So there's just one rule.
And if you follow, if you faithfully follow this one rule, when you form your problem,
then we guarantee we can faithfully translate it and then it can be solved.
And, you know, it's very different from so-called nonlinear optimization, right?
Because in so-called nonlinear optimization, you can do anything you like.
Type in whatever you like.
But now then the solving it, the modeling is easy.
And now the solving is like an art.
And in fact, in most cases, you can't even do it.
Anyway, so the idea of DCP is we just say, here's a simple rule.
You follow this rule.
We solve your problem.
Period.
And, you know, so we built a bunch of software implementations of this.
And it's fun to watch it grow.
And it's very widely used.
It's kind of awesome.
It's incredible.
I myself was a user of many of these tools.
And I can definitely vouch for the fact that it's incredibly easy to use.
And that's perhaps where the success of these tools lies.
So I was wondering, how do you actually make somehow these frameworks?
I would imagine that it can be posed as programming language free, in a sense, because programming
keeps on changing, in the sense of programming languages keep on changing, they keep on
being updated.
But how does one actually remains robust, let's say, to these changes?
So, you know, what's interesting is this goes back to the stuff we talked about before,
which was the value in practice of theory, right?
That you could imagine just basically hacking something together that says, oh, if you see
min or max, do this, right?
If you see the square, the square root, do this transformation.
And the point is, a system like that, it would probably never work.
I mean, it might appear to work at some point, but it doesn't really.
So DCP, Discipline Convex Programming, is built from an extremely small mathematical
core, right?
And the result is that with high probability, it's actually correct.
Now what's interesting is implementing that core.
And by the way, CVX was not the first one.
I would say the first one was YALMIP, which was, you know, yet another LMI processor,
which preceded it.
It's very, very cool.
Anyway, you know, the basic idea is very simple.
When we first did this in like MATLAB, you know, quite a while ago, they had just barely
introduced object oriented things, and it didn't really work and wasn't consistent and
blah, blah, blah.
And so it was actually kind of a pain to implement it.
Of course, that was Michael Grant, who did that.
You know, so what's happened is, as languages get more and more sophisticated, it gets easier
and easier to solve.
In Julia, for example, you know, which has the advantage of being a relatively recently
developed language, the core of convex.jl, it's like 40, 50 lines.
And you're like, how could that be?
And the reason is that the language supports these very high level abstractions, right?
So to me, that's actually really cool.
The idea that, you know, you go back to like C and Fortran, and I don't know, you can do
things like, you know, multiply two numbers, you know, and then shove them back into this
memory location or something like that, right?
I mean, but what's amazing is the new languages support incredible abstraction.
That's awesome for people like us, who use math to do practical things, because it means
you can actually express like really complicated things, or things that would be complicated
in just a handful of lines of code.
And I'm curious about like the future trends that you actually foresee.
So for example, do you have any thoughts on the role of, say, AI in completing our own
programs or what is the next big thing in solving the next type of most expressive optimization
problem?
I don't know.
What are your thoughts on monitoring operators?
There are so many questions that I still have, it's incredible.
So first of all, things like, you know, a chat GPT is amazing, including the code generation
portion of it.
It's just, it's, it's actually amazing.
It's awe inspiring.
And it's super interesting, like, you know, we've played with it, and it's actually super,
what it does is it generates things that sound completely correct, and usually are completely
wrong.
So which, but it's actually, to me, it was even a little bit disturbing, because I usually,
you know, in looking at students work, I usually associate poor writing with being wrong, and
good writing with being right.
And here was very good writing, but the logic and math was just completely wrong.
So now, by the way, I don't mean that as a criticism.
It's just that, you know, when they were training this thing, and you know, that no one said
that you should have a very negative reward for asserting something that's false, right?
You know, so if it sticks to interpretations and things like that, it's great.
And I, my suspicion is within a year or two, we'll see systems, you know, large language
models that will actually do really well, and will generally speaking, not make false
arguments.
So I think it's just amazing.
It is definitely interesting also to imagine different types of uses of these tools, for
example, in other domains, like music, even.
One can imagine that we could use them for a sculpture, for example, we feed them a bunch
of images for 3D printers, and then they're going to create something totally new.
Yeah, I'm very fascinated as well.
And I'm curious, what's the role that you see there of optimization?
Because it's definitely there under the hood.
Well, certainly, it's entirely based on, you know, well, it's SGD, stochastic gradient
descent under the hood on, you know, 100 billion parameter models.
So but I know that's kind of a cheap thing.
We all know that.
We all know that that's how it works, right?
And that's not why it works, although it's a critical component of it.
So I think it'll be a very interesting, in a way, people were talking about, you know,
we build things like CVXPi, so that you can in 10 lines, you know, you'd take a little
bit of training and in 10 lines, you can describe and very sophisticated novel problems and
have it solved, right?
We have code generation tools, like CVXGen, or CVXPiGen, that's a newer version of CVXGen.
And then you'd say, okay, I like what I'm seeing in simulation, please generate me real
time code, I can dump onto my drone or whatever it is, right?
So I think it's cool to have these high level tools that will simplify a lot of what used
to be, you know, basically a lot of work.
So people I've, I mean, actually, my students and colleagues were thinking like, this would
be awesome.
Like, you just talk to this thing and say, here's what it looks like.
In fact, why don't you go fit a model to the dynamics?
And it would do it.
And then you'd say, okay, let's make a controller, show me some simulations with your controller.
And you go, no, no, no, no, I don't like it, it's too rough a ride.
And then it would, you know, add a term penalizing ride roughness, right?
And so I can imagine like crazy stuff that would be really cool.
And it would eventually just kick out, like real time code, you can run on your drone
or whatever it is, right?
I guess the interesting question then will become again, verification.
So how does one guarantee that whatever is produced is actually complying with some sort
of performance measure that we, the users specify?
And I wonder whether we should be content with probability one, or I'm not sure.
Yeah.
So I guess that's, I mean, I have a specific idea about how I think convex optimization
and for example, neural networks should play.
They both play incredibly important roles.
They both do some things super well, right?
And I can give you an example and I'll take an example from finance, right?
Here's something that is just idiotic and does not work.
Like train a neural network that goes directly from Twitter feeds to a trade list, literally
telling you what to buy and sell.
That's like idiotic.
Like, why would you do that, right?
The correct way to do it is take a neural network that basically takes in some like
very complicated data like Twitter feeds and all sorts of other stuff, and then predicts,
let's say one day and five day forward returns.
That's a perfect use of it.
That is then plugged in to a convex optimization solver that weighs the risk, the transaction
costs, the constraints, and then from those, it generates the trade list.
Nice thing about the convex optimization part is we know what it does.
It can't do anything crazy.
Whatever it does, it does for a reason.
We know how to make it robust.
We understand precisely what it does.
And in fact, it can be made so reliable that it just runs real time without any human intervention.
So you have the neural network making very sophisticated forecasts, ones that would be
very difficult to do using other methods.
And then that feeds into some, you know, MPC or something like that.
So to me, that seems like the right way for these two technologies to play together.
Maybe that is the future actually of the interplay of control with machine learning that is nowadays
the elephant in the room for us control theorists, because it seems to work so well in certain
domains that it's impossible to ignore it.
Absolutely.
Yeah.
I think maybe it's time to shift gears a little bit.
I was definitely struck by your IEEE Control Systems Award acceptance speech, which I believe
appeared on CSM, the Control Systems magazine.
And there there's a fantastic quote that I definitely have to read.
It goes as follows.
For me, teaching is research.
Teaching is storytelling.
And the story behind the research is important.
The story should be simple and compelling with substance and maybe a few subplots.
And it should bring people in, not keep people away, for example, by using some esoteric
field specific dialect or acronyms or assuming that the reader has fully absorbed all details
of the last few papers.
I think that's great.
And I'd like you to elaborate a bit on this.
Sure.
What are your thoughts on teaching?
Yeah.
So, I mean, I really don't distinguish very much between teaching and research in both
cases.
And again, it comes back to the, I guess, this training in math and this aesthetic that
what you want is intellectual economy, right?
So no one wants to hear somebody come in and say, oh, there's this method and that method.
And then you could do this.
And oh, is it Tuesday?
Okay.
We can tell you about, you know, reverse conjugate gradients and blah, blah.
It's like, you know, I think when you hear that, it tells me that this person is kind
of confused inside, right?
What you really want is to get it down to its essence.
And it's not, this is not easy work to try to figure out, you know, what are the three
concepts?
A lot of it involves intellectual triage.
You know, when you see all these fights about the curriculum, you know, in various fields,
like let's say EE for one, right?
And someone would say, well, we can't throw out that topic and we can't throw out that
topic because we taught it for a hundred years, but we have to teach these new topics.
So and then you, you end up with this kind of, you know, garbled thing.
So you really have to do the triage.
And the triage really means you're going to let some of that stuff just die anyway.
So I think once you have a very clear picture of a field or a problem, number one, then
you can teach it.
So that's the same thing, right?
You can actually look at a crowd of a couple of hundred people and explain it and have
them go, okay, yeah, I get it.
And actually it's a good thing if some of them said, really?
It's really that simple?
And then you look at them, you go, yep.
So I'm sorry to be the one to tell you it's, it really is that simple.
In this sense, do you have any advice to like, say, future instructors or future teachers
at any scale, I guess?
Yeah, I do.
I mean, for me, teaching is intensely intellectual, right?
I mean, there's a performance aspect to it, like, and that's also super important.
It has to, it actually has to do with control and feedback.
But actually designing a lecture or a course or something like that is actually intensely
intellectual, right?
What you really want is a clean story, right?
And maybe the details are complicated.
And in the right social setting, it's fine to go into the details, right?
If you're with five other people who are experts on that field and you want to talk about some
weird, you know, constraint qualification thing and compactness of the dual, you know,
by all means, please do it.
I mean, I'm assuming this is not in public, right?
So that should not be done in public.
But, you know, I think other than that, you have to figure out, like, what are the main
things you're saying, and then organize it.
And then it's actually, it's a whole lot easier to teach then, because you're teaching the
structure to the students.
You know, it all goes back to this aesthetic of simplicity, right?
I guess this is extremely well demonstrated, not only in the books that we mentioned before,
but also in one of your most recent books, Introduction to Apply Linear Algebra.
Of course, there will be a link in the description to all the books and publications that we
mentioned in the podcast.
There you really take another level of abstraction and you make a wonderful exercise for people
to digest and understand linear algebra.
For me, it was, I did read the book and it was extremely clear and very, very interesting
take also on it, because there were lots of applications coming in from all sorts of different
fields.
Was that your goal in writing the book?
Yes, that's right.
It was a fun book to write.
I mean, it came about because, you know, I don't know, about five, ten years ago, maybe
ten years ago, I have a colleague and I was just complaining to him always about how terrible
the linear algebra teaching is and how people really, I mean, you don't even really, it's
much more important than knowing, for example, you know, calculus and all this kind of stuff.
So I kept complaining.
And at one point he turns to me at lunch and he says, look, you can either continue to
the end of your life complaining about linear algebra education, he said, or you can do
something about it.
And I was like, yeah, okay.
And at that moment, he got me.
So it was actually really fun.
And it's actually, so the book, I mean, I like to think of it, you know, basically it's
an extremely elementary, very slow introduction to linear algebra.
It's all sorts of stuff we don't do.
Like people say, you don't do SVD and you're like, that's right.
We don't.
You don't do the determinant, rank, range, null space, fundamental theorem of linear
algebra.
I was like, nope, nope, not a one.
So we, it just focuses around basically least squares and what you can do with it.
And you shouldn't make fun of that because, you know, a very large fraction of entire
industries are run on methods that, you know, are glorified forms of least squares and control
is one of them, to be perfectly honest.
So I think of it as like, you know, the slow eating movement, you know, this is where you
don't run in and grab something, you know, you have a two or three hour, you know, lunch
and a four hour dinner and you, you actually savor each course, right?
So this is basically the slow linear algebra approach, right?
I guess there's also like a basic philosophy behind it.
So how many people do you want to draw in with respect to say, I want to say something
to a selected few.
That is precisely right.
So we call certain courses outreach courses.
And first I'll tell you what, here's not an outreach course, a course on the most advanced
topics in information theory, you know, the seven papers published in the last year.
Okay.
That's a perfectly good course.
It's a great course, you know, and you've got your four students in it and it's great.
Okay.
The opposite is an outreach course.
And the idea there is to design a course that brings the essence of the ideas to an incredibly
wide group, people in many different departments and fields.
And there you really have to do the intellectual triage, right?
You can't tell them everything.
So you really have to kind of think about what are the useful ideas and what are the
useful methods, right?
And so it's part of that.
And so it was a really fun exercise, you know, for me and Lieven, my coauthor to do.
Yeah.
I guess also accessibility is a concept that is very much at the heart of your endeavor.
This is also reflected by the fact that everything that you produce is open source.
Is that right?
That's right.
And you're potentially, well, one of the few that I have in mind that has all of his own
papers on his website are publicly available, including books.
And I'm just curious, what is it that motivates you to go in the direction of open source?
Well, I think it's extremely important to advancing, I mean, this is good for everyone
is to make all this material available.
I think it, you know, it advances science and advances research.
And I have gone to places, you know, where I would give a talk and I would have people
come up to me, you know, afterwards and say something like, you know, we want to especially
thank you for putting your convex optimization book online.
And they said, because we can buy it, but the price is about two months salary, right?
And so, you know, I didn't think this through carefully.
I would love to revise history and claim that I thought this through and it was a moral
decision and a, you know, rational anyway, honestly, we just fumbled into it.
But I am also very happy that that's the way I've done it.
I guess another interesting segue to this is related to publishing.
So I would be curious to hear your view about what are the right incentives in that direction
on modern publishing, let's say, and I'm curious about what are your thoughts on the social
aspect behind science as well?
Right.
There's a couple of different aspects of that question.
I mean, one is that there are these predatory publishing companies, you know, that basically
get essentially for free material from researchers and professors and, you know, this kind of
thing actually then have it reviewed for free by other professors and researchers, right?
I mean, even now the production costs are approximately zero.
Then they create these things and then price them at appalling prices, knowing that there
is some inelastic demand, like, you know, various libraries are going to get a copy.
And then in addition, I mean, this restricts the free flow of this information.
So I think, you know, that's a very bad phenomenon.
It's not going away fast enough for my taste, but I hope it does.
Now there are some really good publishers, right?
Cambridge University Press is mine and I just think they are awesome in every way.
I mean, you know, they do a lot and they add a lot.
So I think that's one aspect, the problem with it.
By the way, it's not always the for-profit publishers, right?
There are nonprofit publishers that are basically not doing good stuff for science, right?
I'm not going to name any, but there are some and, you know, they're not, okay, they're
not in control.
You know, like IEEE or something like that is on the ethical scale of publishing.
You know, they're on the positive side.
I think that's one aspect.
I think the other aspect is that now that we have the ability to make stuff so widely
available, I think it's a great idea to do it.
And I heard a talk at Stanford about this, about the effects, it was a talk in history
about the effects of the GI Bill, the General Infantry Bill.
So after World War II, there were a lot of returning soldiers in the U.S.
They didn't know what to do with them, so they sent them to college.
And this was absolutely radical, right?
Before that time, you didn't send them to college, right?
It was like, that was for people who were rich or something like that, right?
And you know, lo and behold, it turns out that all those people who would not have gone
to college, some of them were really, really smart, right?
So she went on to name how a lot of these people went on to win Nobel prizes and things
like that.
I mean, that's not a good end in itself, but still, I think it's that, right?
If you, you know, if you find some place where people don't have a lot of opportunities for
a wide variety of reasons, the idea that they can, I don't know, I love the idea that
somebody could be, right as we speak right now, I'm hoping some kids in various places
are reading the Linear Algebra book.
I just think that's awesome.
And it's not just a cool thing to do.
I think actually there'll be some really good benefits.
Some of those people are going to grow up to do really great stuff.
And hopefully they will listen also to this episode as well, and they'll be inspired.
I hope so, yeah.
So we're heading towards the end of this episode and in closing, I would like to ask you maybe
a couple of questions related to the future of convex optimization and control, or maybe
the intersection of both.
And maybe I'll have another question related to advice that I tend to ask to any guest
that features on the show to future students, future students that happen to be in control
nowadays or planning to come in the field.
What would be your best advice in general?
Yeah.
So let's see.
So the first question is about the future and like what's going on.
And I have to say that, you know, what I'm focusing on is actually pretty pedestrian,
but I think it's important.
So my focus and a lot of what our group does, I mean, we do fun stuff too, but a lot of
it is just to make sure that we build out the infrastructure that we need for very wide
groups of people to use these methods, right?
That's what we want to do.
So if you look at some other fields, they have done so well at this.
I mean, machine learning, unbelievable.
The amount of open source material that's available and incredibly high quality open
source implementations of things.
I mean, it's, I mean, anyway, my hat goes off to them.
I mean, I think they've done a spectacular job.
I personally think in optimization, we've done a less good job and in control, maybe
even worse than that.
So and a lot of it is kind of pedestrian and boring.
Like, you know, everybody knows how to implement a, you know, whatever, you know, a QP solver,
but you know, somebody has got to make one that's open source and reliable and works
and things like that.
So we do a lot of that stuff.
When you say these words, you have in mind things like TensorFlow, PyTorch or those kind
of things.
Yeah.
Oh my God.
That's so good.
I mean, you know, I think they've just done an incredibly good job.
And, you know, if you think about it, there's nothing like that in control.
Name the open source tools in control that people could use, right?
I mean, it's a simple question.
Like, I sit down with someone, I tell them what control is for like five minutes and
they go, this is awesome.
This is awesome.
I want to use this so-called control.
Like, how do I do it?
Right?
Like, tell me, you know, what Git repo do I clone?
Or, you know, what do I need to pip install?
Right?
And the answer is, there's like nothing.
I mean, there's commercial stuff, you know, which, you know, there's for profit stuff.
So, I mean, it's a little embarrassing for all feel and I'll be honest, I think it's
a little embarrassing.
And then you asked about advice.
And I would say to a student, and this is going to be very personal because it's what
I thought I wish someone had told me, you know, maybe it's also a character flaw on
my part.
But, you know, when I was young, I was very snobby and had very high standards and things
like that.
And I kind of avoided things that were messy and, you know, a lot of the applied stuff
was messy and stuff like that.
And it was only much later that I realized how rich an experience you can have when you
learn all the math, but you also learn a lot about, you know, how it's applied and how
does this field work and how does that field work.
So, my advice to young people is, you know, absolutely focus on the basics.
Absolutely do that.
But also, you know, spend a little quality time as you, I think you used the word traveling.
So, doing some intellectual traveling.
Go, just, you know, go over to the mountain to the next village and see what they're up
to.
You know, maybe if you only go one village, they'll speak a similar dialect, you can figure
out what they're doing.
And because I just think that's so enriching, you know, when you come back to know how people
in different fields use math.
I think it's super interesting.
That would be my advice.
What do you think is the best way to make this happen in a way?
Because it's something that I tend to observe in many, many students nowadays, the, the,
there is definitely this tension towards, you know, learning theory, hardcore theory
and becoming always more and more knowledgeable about that.
Right.
And in that way, you detach yourself from applications.
I think you're right that I think in some ways, some of the incentives in academia just
aren't right.
That, you know, the incentive is to write an eight page paper that is completely impenetrable,
that no one understands and so on, and, you know, is poorly written, which is actually,
it's obfuscated, maybe not intentionally, but so I think a lot of the incentives are
towards that, but I think that's the wrong incentive.
So I would, my advice would be to do something your advisor sometimes will not be on board
with.
And, and that is, you know, poke around, look at other things, right?
Take the time to write things that are clear and simple, make some open source implementations
of various things and just literally just contribute it to the world.
That'd be one of my pieces of advice.
The other thing is just hang out and talk to other people in other fields and try to
hold back on judgment until you've begun to understand their dialect.
I wish someone had given me that advice.
I think this is great advice.
Well, Steven, thanks a lot for your time.
It's been a wonderful journey to chat with you.
Thanks for accepting our invitation.
Oh, thank you so much, Alberto.
I think this is a great idea and I hope it's going to do a lot of good.
It's awesome.
Thank you for listening.
I hope you liked the show today.
If you enjoyed the podcast, please consider giving us five stars on Apple Podcasts, follow
us on Spotify, support on Patreon or PayPal, and connect with us on social media platforms.

See you next time.
Bye.
